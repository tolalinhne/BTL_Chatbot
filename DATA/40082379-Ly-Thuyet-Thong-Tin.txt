 BÀI GIẢNG MÔN HỌC
LÝ THUYẾT THÔNG TIN
                 NỘI DUNG MÔN HỌC
   Bài 1   Giới thiệu
   Bài 2   Một số khái niệm cơ bản
   Bài 3   Chuẩn bị toán học
   Bài 4   Lượng tin
   Bài 5   Entropy
   Bài 6   Mã hiệu
   Bài 7   Mã hóa tối ưu nguồn rời rạc không nhớ
   Bài 8   Mã hóa nguồn phổ quát
   Bài 9   Kênh rời rạc không nhớ, lượng tin tương hỗ

                            Trang 2
                NỘI DUNG MÔN HỌC (tt)
   Bài 10   Mã hóa chống nhiễu, định lý kênh
   Bài 11   Mã khối tuyến tính
   Bài 12   Cơ sở toán học của mã hóa chống nhiễu
   Bài 13   Mã vòng
   Bài 14   Giới thiệu về mật mã hóa
   Bài 15   Một số vấn đề nâng cao




                             Trang 3
            TÀI LIỆU THAM KHẢO
1. Information Theory - Robert B.Ash, Nhà xuất bản Dover, Inc,
   1990.
2. Introduction to Information Theory - Masud Mansuripur, Nhà
   xuất bản Prentice–Hall, Inc, 1987.
3. A Mathematical Theory of Communication - C. E. Shannon,
   Tạp chí Bell System Technical, số 27, trang 379–423 và 623–
   656, tháng 7 và tháng 10, 1948.
4. Cơ sở Lý thuyết truyền tin (tập một và hai) - Đặng Văn
   Chuyết, Nguyễn Tuấn Anh, Nhà xuất bản Giáo dục, 1998.




                          Trang 4
                   HÌNH THỨC ĐÁNH GIÁ
   Sẽ có thông báo cụ thể cho từng khóa học. Tuy nhiên,
    thường là có hình thức như bên dưới.
   Thi (80%)
        Giữa kỳ: thi viết (30%)
        Cuối kỳ: thi trắc nghiệm 50 câu / 90 phút (50%)
   Làm bài tập lớn (20%)
        Nộp bài tập lớn và báo cáo vào cuối học kỳ




                                  Trang 5
                 CÁC MÔN LIÊN QUAN
   Lý thuyết xác suất
   Kỹ thuật truyền số liệu
   Xử lý tín hiệu số




                              Trang 6
                     Bài 1 Giới thiệu
1.1 Thông tin là gì?
1.2 Vai trò của thông tin
1.3 Lý thuyết thông tin nghiên cứu những gì?
1.4 Những ứng dụng của lý thuyết thông tin
1.5 Lý thuyết thông tin – Lịch sử hình thành và quan điểm
   khoa học hiện đại




                           Trang 7
                           Thông tin là gì?
   Một vài ví dụ
        Hai người nói chuyện với nhau. Cái mà trao đổi giữa họ gọi là
         thông tin.
        Một người đang xem tivi/nghe đài/đọc báo, người đó đang nhận
         thông tin từ đài phát/báo.
        Quá trình giảng dạy trong lớp.
        Các máy tính nối mạng và trao đổi dữ liệu với nhau.
        Máy tính nạp chương trình, dữ liệu từ đĩa cứng vào RAM để
         thực thi.




                                 Trang 8
                        Thông tin là gì? (tt)
   Nhận xét
        Thông tin là cái được truyền từ đối tượng này đến đối tượng
         khác để báo một “điều” gì đó. Thông tin chỉ có ý nghĩa khi
         “điều” đó bên nhận chưa biết.
        Thông tin xuất hiện dưới nhiều dạng âm thanh, hình ảnh, ...
         Những dạng này chỉ là “vỏ bọc” vật chất chứa thông tin. “Vỏ
         bọc” là phần “xác”, thông tin là phần “hồn”.
        Ngữ nghĩa của thông tin chỉ có thể hiểu được khi bên nhận hiểu
         được cách biểu diễn ngữ nghĩa của bên phát.
        Một trong những phương tiện để diễn đạt thông tin là ngôn ngữ.
        Có hai trạng thái của thông tin: truyền và lưu trữ. Môi trường
         truyền/lưu trữ được gọi chung là môi trường chứa tin hay kênh
         tin.

                                 Trang 9
                   Vai trò của thông tin
   Các đối tượng sống luôn luôn có nhu cầu hiểu về thế giới xung
    quanh, để thích nghi và tồn tại. Đây là một quá trình quan sát,
    tiếp nhận, trao đổi và xử lý thông tin từ môi trường xung quanh.
   Thông tin trở thành một nhu cầu cơ bản, một điều kiện cần cho
    sự tồn tại và phát triển.
   Khi KHKT, XH ngày càng phát triển, thông tin càng thể hiện
    được vai trò quan trọng của nó đối với chúng ta.
   Ví dụ, hành động xuất phát từ suy nghĩ, nếu suy nghĩ đúng, thì
    hành động mới đúng. Suy nghĩ lại chịu ảnh hưởng từ các nguồn
    thông tin được tiếp nhận. Vì vậy thông tin có thể chi phối đến
    suy nghĩ và kết quả là hành động của con người.


                             Trang 10
            LTTT nghiên cứu những vấn đề gì?
        Ở góc độ khoa học kỹ thuật, LTTT nghiên cứu nhằm tạo ra một
         “cơ sở hạ tầng” tốt cho việc truyền thông tin chính xác, nhanh
         chóng và an toàn; lưu trữ thông tin một cách hiệu quả.
        Ở các góc độ nghiên cứu khác LTTT nghiên cứu các vấn đề về
         cách tổ chức, biểu diễn và truyền đạt thông tin, và tổng quát là
         các vấn đề về xử lý thông tin.
   Ba lĩnh vực nghiên cứu cơ bản của môn học
        Mã hoá chống nhiễu
        Mã hoá tối ưu (hay nén dữ liệu)
        Mật mã hoá




                                  Trang 11
        Những ứng dụng của LT thông tin
   Cuộc cách mạng thông tin đang xảy ra, sự phát triển mạnh mẽ
    của các phương tiện mới về truyền thông, lưu trữ thông tin làm
    thay đổi ngày càng sâu sắc xã hội chúng ta.
   LTTT đóng một vai trò quyết định trong sự phát triển này bằng
    cách cung cấp cơ sở lý thuyết và một cái nhìn triết học sâu sắc
    đối với những bài toán mới và thách thức mà chúng ta chạm
    trán – hôm nay và mai sau.
   Những ứng dụng phổ biến của LTTT là truyền thông và xử lý
    thông tin bao gồm: truyền thông, nén, bảo mật, lưu trữ, ...
   Các ý tưởng của LTTT đã được áp dụng trong nhiều lĩnh vực
    như vật lý, ngôn ngữ học, sinh vật học, khoa học máy tính, tâm
    lý học, hóa học

                             Trang 12
     Những ứng dụng của LT thông tin (tt)
   Mối quan hệ giữa LTTT và thống kê đã được tìm thấy, các
    phương pháp mới về phân tích thống kê dựa trên LTTT đã được
    đề nghị.
   Ứng dụng vào quản lý kinh tế. Ví dụ, lý thuyết đầu tư tối ưu
    xuất hiện đồng thời với lý thuyết mã hóa nguồn tối ưu.
   Ứng dụng vào ngôn ngữ học.




                           Trang 13
                    Lịch sử hình thành
   Cuộc cách mạng lớn nhất về cách nhìn thế giới khoa học là
    chuyển hướng từ thuyết quyết định Laplacian đến bức tranh
    xác suất của tự nhiên.
   Thế giới chúng ta đang sống trong đó chủ yếu là xác suất. Kiến
    thức của chúng ta cũng là một dạng xác suất.
   LTTT nổi lên sau khi cơ học thống kê và lượng tử đã phát triển,
    và nó chia xẻ với vật lý thống kê các khái niệm cơ bản về
    entropy.
   Theo lịch sử, các khái niệm cơ bản của LTTT như entropy,
    thông tin tương hỗ được hình thành từ việc nghiên cứu các hệ
    thống mật mã hơn là từ việc nghiên cứu các kênh truyền thông.
   Về mặt toán học, LTTT là một nhánh của lý thuyết xác suất và
    các quá trình ngẫu nhiên (stochastical process).

                             Trang 14
                 Lịch sử hình thành (tt)
   Quan trọng và có ý nghĩa nhất là quan hệ liên kết giữa LTTT và
    vật lý thống kê.
   Trong một thời gian dài trước khi LTTT được hình thành, L.
    Boltzman và sau đó là L.Szilard đã đánh đồng ý nghĩa của
    thông tin với khái niệm nhiệt động học của entropy. Một mặt
    khác, D. Gabor chỉ ra rằng “lý thuyết truyền thông phải được
    xem như một nhánh của vật lý”.
   C. E. Shannon là cha đẻ của LTTT.




                            Trang 15
           Bài 2 Một số khái niệm cơ bản
2.1 Thông tin (Information)
2.2 Mô hình của các quá trình truyền tin
2.3 Các loại hệ thống truyền tin – Liên tục và rời rạc
2.4 Rời rạc hoá




                            Trang 16
                           Thông tin
   Thông tin là một khái niệm trừu tượng, phi vật chất và rất khó
    được định nghĩa chính xác. Hai định nghĩa về thông tin.
   Thông tin là sự cảm hiểu của con người về thế giới xung quanh
    thông qua sự tiếp xúc với nó.
   Thông tin là một hệ thống những tin báo và mệnh lệnh giúp loại
    trừ sự không chắc chắn (uncertainty) trong trạng thái của nơi
    nhận tin. Nói ngắn gọn, thông tin là cái mà loại trừ sự không
    chắc chắn.
   Định nghĩa đầu chưa nói lên được bản chất của thông tin. Định
    nghĩa thứ hai nói rõ hơn về bản chất của thông tin và được dùng
    để định lượng thông tin trong kỹ thuật.


                            Trang 17
                        Thông tin (tt)
   Thông tin là một hiện tượng vật lý, nó thường tồn tại và được
    truyền đi dưới một dạng vật chất nào đó.
   Những dạng vật chất dùng để mang thông tin được gọi là tín
    hiệu.
   Lý thuyết tín hiệu nghiên cứu các dạng tín hiệu và cách truyền
    thông tin đi xa với chi phí thấp, một ngành mà có quan hệ gần
    gũi với LTTT.
   Thông tin là một quá trình ngẫu nhiên.
   Tín hiệu mang tin tức cũng là tín hiệu ngẫu nhiên và mô hình
    toán học của nó là các quá trình ngẫu nhiên thực hay phức.
   Và LTTT là lý thuyết ngẫu nhiên của tin tức, có nghĩa là nó xét
    đến tính bất ngờ của tin tức đối với nơi nhận tin.
                             Trang 18
           Mô hình của các quá trình truyền tin
        Khái niệm thông tin thường đi kèm với một hệ thống truyền tin.
                                          Nhiễu
          Nguồn phát                 Kênh truyền                 Nguồn nhận
   Sự truyền tin (transmission)
        Là sự dịch chuyển thông tin từ điểm này đến điểm khác trong
         một môi trường xác định.
   Nguồn tin (information source)
        Là một tập hợp các tin mà hệ thống truyền tin dùng để lập các
         bảng tin hay thông báo (message) để truyền tin.
        Bảng tin chính là dãy tin được bên phát truyền đi.
        Thông tin có thể thuộc nhiều loại như
          (1) một dãy kí tự như trong điện tín (telegraph) của các hệ thống gởi điện
              tín (teletype system);
                                       Trang 19
           Mô hình của các quá trình truyền tin (tt)
          (2) một hàm theo chỉ một biến thời gian f(t) như trong radio và điện thoại;
          (3) một hàm của thời gian và các biến khác như trong tivi trắng đen – ở
              đây thông tin có thể được nghĩ như là một hàm f(x, y, t) của toạ độ hai
              chiều và thời gian biểu diễn cường độ ánh sáng tại điểm (x, y) trên màn
              hình và thời gian t;
          (4) một vài hàm của một vài biến như trong trường hợp tivi màu – ở đây
              thông tin bao gồm ba hàm f(x, y, t), g(x, y, t), h(x, y, t) biểu diễn cường
              độ ánh sáng của các ba thành phần màu cơ bản (xanh lá cây, đỏ, xanh
              dương)
        Thông tin trước khi được truyền đi, tuỳ theo yêu cầu có thể
         được mã hoá để nén, chống nhiễu, bảo mật, ...
   Kênh tin (channel)
        Là nơi hình thành và truyền (hoặc lưu trữ) tín hiệu mang tin
         đồng thời ở đấy xảy ra các tạp nhiễu (noise) phá hủy tin tức.
        Trong LTTT kênh là một khái niệm trừu tượng đại biểu cho
         hỗn hợp tín hiệu và tạp nhiễu.
                                        Trang 20
                            Một số khái niệm (tt)
        Môi trường truyền tin thường rất đa dạng
             môi trường không khí, tin được truyền dưới dạng âm thanh và tiếng nói,
              ngoài ra cũng có thể bằng lửa hay bằng ánh sáng;
             môi trường tầng điện ly trong khí quyển nơi mà thường xuyên xảy ra sự
              truyền tin giữa các vệ tinh nhân tạo với các trạm rada ở dưới mặt đất;
             đường truyền điện thoại nơi xảy ra sự truyền tín hiệu mang tin là dòng
              điện hay đường truyền cáp quang qua biển trong đó tín hiệu mang tin là
              sóng ánh sáng v.v…
   Nhiễu (noise)
        Cho dù môi trường nào cũng có nhiễu. Nhiễu rất phong phú và
         đa dạng và thường đi kèm với môi trường truyền tin tương ứng.
             Chẳng hạn nếu truyền dưới dạng sóng điện từ mà có đi qua các vùng của
              trái đất có từ trường mạnh thì tín hiệu mang tin thường bị ảnh hưởng ít
              nhiều bởi từ trường này. Nên có thể coi từ trường này là một loại nhiễu.
             Nếu truyền dưới dạng âm thanh trong không khí thì tiếng ồn xung quanh
              có thể coi là một loại nhiễu.

                                        Trang 21
                       Một số khái niệm (tt)
        Nhiễu có nhiều loại chẳng hạn nhiễu cộng, nhiễu nhân.
        Nhiễu cộng là loại nhiễu mà tín hiệu mang tin bị tín hiệu nhiễu
         “cộng” thêm vào.
        Nhiễu nhân là loại nhiễu mà tín hiệu mang tin bị tín hiệu nhiễu
         “nhân” lên.
   Nơi nhận tin (sink)
        Là nơi tiếp nhận thông tin từ kênh truyền và cố gắng khôi phục
         lại thành thông tin ban đầu như bên phát đã phát đi.
        Tin đến được nơi nhận thường không giống như tin ban đầu vì
         có sự tác động của nhiễu. Vì vậy nơi nhận phải thực hiện việc
         phát hiện sai và sửa sai.
        Nơi nhận còn có thể phải thực hiện việc giải nén hay giải mã
         thông tin đã được mã hoá bảo mật nếu như bên phát đã thực
         hiện việc nén hay bảo mật thông tin trước khi truyền

                                  Trang 22
             Các loại hệ thống truyền tin
   Các nguồn tin thường thấy trong tự nhiên được gọi là các nguồn
    tin nguyên thuỷ. Đây là các nguồn tin chưa qua bất kỳ một phép
    biến đổi nhân tạo nào.
   Các tín hiệu âm thanh, hình ảnh được phát ra từ các nguồn tin
    nguyên thuỷ này thường là các hàm liên tục theo thời gian và
    theo mức, nghĩa là có thể biểu diễn một thông tin nào đó dưới
    dạng một hàm s(t) tồn tại trong một quãng thời gian T và lấy
    các trị bất kỳ trong một phạm vi (smin, smax) nào đó.
            s(t)
            smax


            smin
                                                   t
                            Trang 23
             Các loại hệ thống truyền tin (tt)
   Các nguồn như vậy được gọi là các nguồn liên tục (continuous
    source), các tin được gọi là tin liên tục (continuous information)
    và kênh tin được gọi là kênh liên tục (continuous channel).
   Tuy nhiên vẫn có những nguồn nguyên thuỷ là rời rạc
        Bảng chữ cái của một ngôn ngữ.
        Các tin trong hệ thống điện tín, các lệnh điều khiển trong một hệ thống
         điều khiển, ...
   Trong trường hợp này các nguồn được gọi là nguồn rời rạc
    (discrete source), các tin được gọi là tin rời rạc (discrete
    information) và kênh tin được gọi là kênh rời rạc (discrete
    channel).
   Sự phân biệt về bản chất của tính rời rạc và tính liên tục là số
    lượng tin của nguồn trong trường hợp rời rạc là hữu hạn còn
    trong trường hợp liên tục là không đếm được.


                                    Trang 24
                               Rời rạc hóa
        Các hệ thống liên tục có nhiều nhược điểm của như cồng kềnh,
         không hiệu quả, và chi phí cao.
        Các hệ thống truyền tin rời rạc có nhiều ưu điểm hơn, khắc
         phục được những nhược điểm trên của các hệ thống liên tục và
         đặc biệt đang ngày càng được phát triển và hoàn thiện dần
         những sức mạnh và ưu điểm của nó.
        Rời rạc hoá thường bao gồm hai loại: Rời rạc hoá theo trục thời
         gian, còn được gọi là lấy mẫu (sampling) và rời rạc hoá theo
         biên độ, còn được gọi là lượng tử hoá (quantize).
   Lấy mẫu (Sampling)
        Lấy mẫu một hàm là trích ra từ hàm ban đầu các mẫu được lấy
         tại những thời điểm xác định.
        Vấn đề là làm thế nào để sự thay thế hàm ban đầu bằng các mẫu
         này là một sự thay thế tương đương, điều này đã được giải
         quyết bằng định lý lấy mẫu nổi tiếng của Shannon.
                                  Trang 25
                           Rời rạc hóa (tt)
   Định lý lấy mẫu của Shannon
        Một hàm s(t) có phổ hữu hạn, không có thành phần tần số lớn
         hơn ωmax (= 2πfmax) có thể được thay thế bằng các mẫu của nó
         được lấy tại những thời điểm cách nhau một khoảng Δt ≤
         π/ωmax, hay nói cách khác tần số lấy mẫu F ≥ 2fmax.

              s(t)
              smax


               smin
                                                       t


                                 Trang 26
                             Rời rạc hóa (tt)
   Lượng tử hoá (Quantize)
        Biên độ của các tín hiệu thường là một miền liên tục (smin, smax).
         Lượng tử hoá là phân chia miền này thành một số mức nhất
         định, chẳng hạn là smin = s0, s1, ..., sn = smax và qui các giá trị
         biên độ không trùng với các mức này về mức gần với nó nhất.
        Việc lượng tử hoá sẽ biến đổi hàm s(t) ban đầu thành một hàm
         s’(t) có dạng hình bậc thang. Sự khác nhau giữa s(t) và s’(t)
         được gọi là sai số lượng tử. Sai số lượng tử càng nhỏ thì s’(t)
         biểu diễn càng chính xác s(t).
                 s(t)
                 smax


                smin
                                                            t
                                   Trang 27
                              Nguồn rời rạc
        Nguồn tin liên tục sau khi được lấy mẫu và lượng tử hoá sẽ trở
         thành nguồn rời rạc.
        Chúng ta học chủ yếu các nguồn rời rạc.
   Nguồn rời rạc
        Một nguồn rời rạc là một bảng chữ cái A gồm m kí hiệu, A =
         {a1, a2, ..., am}, với những xác suất xuất hiện p(ai), i = 1, .., m.
        Định nghĩa không diễn tả mối quan hệ giữa tin trước và sau
         trong một bản tin, nên đây được gọi là một nguồn rời rạc không
         nhớ (discrete memoryless source).
   Bảng tin của một nguồn tin rời rạc không nhớ
        Là một dãy (có thể vô hạn) các kí hiệu liên tiếp từ bảng chữ cái
         của nguồn tin, x = (... a–2a–1a0a1a2...)
        Trong thực tế bảng tin có bắt đầu và kết thúc cho nên bảng tin
         là một dãy hữu hạn các kí hiệu, x* = (a1a2 …an)
                                   Trang 28
          Bài 3 Chuẩn bị toán học

3.1 Xác suất (Probability)
3.2 Bất đẳng thức Chebyshev và luật yếu của số lớn
3.3 Tập lồi (Convex sets) và hàm lồi (convex
   functions), bất đẳng thức Jensen




                      Trang 29
                                  Xác suất
   Không gian mẫu (Sample space)
        Là tập (hay không gian) tất cả các kết quả có thể có của một thí
         nghiệm. Thường được kí hiệu là E hay S. Nếu không gian mẫu
         là rời rạc thì E có thể được biểu diễn bằng E = {e1, e2, ..., en}
   Sự kiện (Event), sự kiện cơ bản (elementary event)
        Mỗi tập con của E (không gian mẫu) được gọi là một sự kiện,
         đặc biệt mỗi phần tử của E được gọi là một sự kiện cơ bản.
   Ví dụ
        Trong một thí nghiệm tung đồng xu thì E = {U (úp), N (ngửa)}.
         Nếu đồng tiền là đồng nhất thì xác suất P(U) = P(N) = 1/2.
        Trong một thí nghiệm tung con xúc xắc thì E = {1, 2, 3, 4, 5,
         6}. Nếu con xúc xắc là đồng nhất thì xác suất P(1) = P(2) =
         P(3) = P(4) = P(5) = P(6) = 1/6, P(2, 5) = 1/3, P(1, 3, 5) = 1/2.


                                   Trang 30
                                Xác suất (tt)
        Lấy một văn bản tiếng Anh điển hình và nhặt một kí tự bất kỳ
         thì E = {a, b, c, ..., x, y, z} và xác suất của các kí tự được phân
         bố như sau P(a) = 0,0642 , ..., P(e) = 0,103 , ..., P(z) = 0,0005.
   Biến ngẫu nhiên rời rạc (Discrete random variable)
        Một biến ngẫu nhiên rời rạc x được định nghĩa bằng cách gán
         một số thực xi tới mỗi sự kiện cơ bản ei của không gian mẫu rời
         rạc E. Xác suất của xi được định nghĩa là xác suất của sự kiện
         cơ bản tương ứng và được kí hiệu là p(xi).
   Trị trung bình (kỳ vọng) (average, expected value),
    phương sai (variance)
        Trị trung bình và phương sai của biến ngẫu nhiên rời rạc x lần
         lượt được kí hiệu và định nghĩa như sau
        E(x) = x = ∑ x i p (x i )
                         i


                                    Trang 31
                                  Xác suất (tt)
                  = E ((x − x ) ) = ∑ (x i − x ) p(x i )
                               2                2
        Var(x)
                       ( )      2    i
                 = E x −x
                         2


         trong đó E(x2) là trị kỳ vọng của x2.
        Tổng quát, trị kỳ vọng của một hàm của x, chẳng hạn f(x), được
         định nghĩa bằng
                             E ( f (x )) = ∑ f (x i ) p(x i )
                                                i
   Xác suất đồng thời (joint probability), xác suất có điều
    kiện (conditional probability)
        Một cặp biến ngẫu nhiên (x, y) liên kết với một thí nghiệm tạo
         thành một biến ngẫu nhiên nối (joint random variable). Nếu x, y
         là rời rạc, sự phân bố xác suất nối hay xác suất đồng thời được
         định nghĩa là
                                pij = P(x = xi, y = yj)
                                         Trang 32
                           Xác suất (tt)
   Xác suất của y trong điều kiện đã biết x được gọi là xác suất có
    điều kiện và được định nghĩa là
                                        p (xi , y j )
                       p ( y j xi ) =
                                            p( xi )
    trong đó xác suất lề (marginal probability) p(xi) được giả thiết
    là khác không.
    Các xác suất lề được định nghĩa như sau:
                                        (           )


                     p(xi) = ∑ p xi , y j
                                 j

                     p(yj) =    ∑ p(x , y )
                                 i
                                            i   j




                                Trang 33
                             Ví dụ
                                  Xúc xắc
   Thí nghiệm tung đồng thời
                                       6    1/12   1/12
    một đồng xu và con xúc xắc.
   Từ kết quả trên ta thấy            5    1/18   1/24
    P(U, 5) = 1/18                     4    1/9    1/24
    P(Đồng xu = U) = 5/9               3    1/9    1/6
    P(Đồng xu = N) = 4/9               2    1/9    1/18
    P(Xúc xắc = 5) = 7/72              1    1/12   1/18
    P(Xúc xắc = 5 đã biết Đồng xu = U)       U      N Đồng xu
    =(1/18)/(5/9)=1/10




                           Trang 34
                               Xác suất (tt)
   Sự độc lập (Independence)
        Hai biến ngẫu nhiên x và y được gọi là độc lập nếu
                              p(xi, yj) = p(xi)p(yj) ∀ i, j.
        Chúng ta thấy nếu hai biến x và y độc lập thì
                                p (xi , y j ) p ( xi ) p ( y j )
                     (    )
                    p y j xi =
                                  p ( xi )
                                             =
                                                  p ( xi )
                                                                 = p(y j )
         có nghĩa là xác suất yj trong điều kiện có xi xảy ra hay không
         xảy ra đều như nhau, không thay đổi, và ngược lại.
        Cũng từ sự độc lập chúng ta suy ra một kết quả mà hay được sử
         dụng sau này
                            E(xy) = E(x) E(y) = x y


                                  Trang 35
                              Xác suất (tt)
   Sự tương quan (correlation)
        Sự tương quan C giữa hai biến x và y được định nghĩa là trị kỳ
         vọng của (x – x )(y – y):
                           C(x, y) = E((x – x )(y – y )) =
                                   = E(xy) – x y
        Trong trường hợp x và y là độc lập chúng ta suy ra C(x, y) = 0.
         Tuy nhiên điều ngược lại thì không đúng.




                                  Trang 36
Q1

                           Bất đẳng thức Chebyshev
                            và luật yếu của số lớn
        Bất đẳng thức Chebyshev
             Cho một biến ngẫu nhiên x có trị trung bình là x và phương sai
              là δ x2, bất đẳng thức Chebyshev đối với một số dương tuỳ ý δ là

                                                δ x2
                               P(|x – x | ≥ δ) ≤ 2
                                                δ
        Chứng minh
                                                       ⎧1,|x - x| ≥ δ
             Định nghĩa một hàm f(x) như sau f (x ) = ⎨
             Thì                                      ⎩0 ,|x - x| < δ
                                 P(|x – x| ≥ δ) = Σ f(xi)p(xi)



                                        Trang 37
Slide 37

Q1         Bất đẳng thức Chebyshev chỉ ra cận trên của xác suất để một đại lượng ngẫu nhiên lệch khỏi kỳ vọng toán học của nó: giả sử X là đại
           lượng ngẫu nhiên có kỳ vọng toán học là EX=a và phương sai DX=d2. Bất đẳng thức Chebyshev chỉ rõ rằng với e>0 cho trước, xác
           suất của biến cố |X-a|>=e không vượt quá d2/e2. Bất đẳng thức này được dùng để chứng minh luật số lớn.
           Quang, 12/03/2008
              Bất đẳng thức Chebyshev (tt)
                                      2
                          ⎛x−x    ⎞
                          ⎜       ⎟
                          ⎜ δ     ⎟
                          ⎝       ⎠

                  1

                          x −δ        x   x +δ   x
   Dựa trên hình chúng ta có                        2
                                         ⎛x−x⎞
                                  f(x) ≤ ⎜         ⎟
                                         ⎜ δ ⎟
   Vì vậy,                              ⎝         ⎠
                                         2
         (            )  ⎛       x−x⎞                δ 2
        P x − x ≥ δ ≤ ∑ ⎜⎜              ⎟ p (x i ) = x2
                                  δ ⎟⎠               δ
                      i ⎝
                             Trang 38
                 Luật yếu của số lớn (tt)
   Xét một thí nghiệm nhị phân trong đó các kết quả của thí
    nghiệm là 0 và 1 với các xác suất tương ứng là p0 và 1– p0.
   Thí nghiệm này được lặp lại N lần một cách độc lập, và kết quả
    trung bình được định nghĩa là yN; tức là, yN bằng tổng số các số
    1 trong N lần thí nghiệm chia cho N.
   Rõ ràng, yN là một biến ngẫu nhiên có không gian mẫu là {0,
    1/N, 2/N, ..., 1}.
   Định nghĩa x(n) là biến ngẫu nhiên tương ứng với kết quả của
    lần thí nghiệm thứ n, chúng ta có
                                        N
                              1
                         yN =
                              N
                                    ∑ x (n )
                                        n =1


                             Trang 39
                    Luật yếu của số lớn (tt)

                                ∑ E (x )
                                N                           N
                         1                            1
                    yN =
                         N      n =1
                                             (n )
                                                    =
                                                      N
                                                           ∑ x =x
                                                            n =1


        ((                ))
                                  ⎛⎡ 1         N
                                                              ⎤
                                                                   2
                                                                       ⎞
                               = E⎜ ⎢        ∑x                        ⎟
                          2                         (n )
δ = E yN − yN
 2
                                                           − x⎥
 y
                                  ⎜⎣N                         ⎦        ⎟
                                  ⎝          n =1
                                                                       ⎠
        ⎛⎛ 1 ⎡ N              2
                                ⎞   ⎛             ⎤ ⎞⎟
                                                    2
                            ⎞
                          ⎤ ⎟     1 ⎜⎡
                                                                           (   )
                                         N
        ⎜
     = E ⎜⎜ ⎢∑ x − N x ⎥ ⎟⎟ = 2 E ⎢∑ x − x ⎥
                     ( n)                    (n )
        ⎜ ⎝ N ⎣ n =1      ⎦ ⎠   ⎟ N ⎜ ⎣ n =1      ⎦   ⎟
        ⎝                       ⎠   ⎝                 ⎠

                     ((           ))               δ
             N                                       2
       1                                  1
             ∑     (n )             2
     = 2       E x      −x              = 2 Nδ x2 = x
      N      n =1                        N          N


                                        Trang 40
                 Luật yếu của số lớn (tt)
   Đối với một số nguyên dương tuỳ ý ε, theo bất đẳng thức
    Chebyshev chúng ta có
                                        δ y2
                      (                  )
                    P | y N − y N |≥ ε ≤ 2
                                        ε
    từ đây chúng ta dẫn ra được luật yếu của số lớn
                      ⎛⎡1     N
                                         ⎤         ⎞   δ  2
                    P⎜⎜ ⎢    ∑    x (n )
                                         ⎥ − x ≥ ε ⎟
                                                   ⎟ ≤   x
                                                         ε  2
                      ⎝ ⎣N   n =1        ⎦         ⎠   N
   Chú ý rằng vế phải tiến tới 0 khi N tiến ra vô cùng.
   Luật yếu của số lớn vì vậy khẳng đinh rằng trị trung bình mẫu
    của x tiếp cận trị trung bình thống kê với xác suất cao khi N →
    ∞.

                              Trang 41
                              Tập lồi
   Trong không gian Ơclit, một tập S được gọi là lồi (∩) nếu đối
    với một cặp điểm P1, P2 thuộc S thì mọi điểm thuộc đoạn P1P2
    cũng thuộc S.
                                              P1         P1

                                            P2             P2
            (a)                                          (b)
 Nếu P1 = (x1, x2, ..., xn) và P2 = (y1, y2, ..., yn) là các điểm trong

  không gian Ơclit n chiều, thì đoạn thẳng nối chúng được biểu
  diễn bằng tập các điểm P, trong đó
P = λP1 + (1–λ)P2
  = (λx1 + (1–λ)y1, λx2 + (1–λ)y2, ..., λxn + (1–λ)yn) và λ ∈ [0, 1].
                              Trang 42
                               Hàm lồi
   Một ví dụ quan trọng của tập lồi là tập tất cả các điểm (p1, p2,
    ..., pn) trong đó (p1, p2, ..., pn) là một sự phân bố xác suất (tức là
    các pi ∈ [0, 1] và Σpi = 1).
   Một hàm thực f(P), được định nghĩa trên tập lồi S, được gọi là
    lồi nếu ∀cặp điểm P1, P2 ∈ S, và ∀ λ ∈ [0, 1] bất đẳng thức sau
    đây đúng:
                   f(λP1 + (1–λ)P2) ≥ λf(P1) + (1–λ)f(P2)
            f(x)        f((λx1 + (1-λ)x2)
                                                f(x2)


                 f(x1)   λf(x1) + (1-λ)f(x2)
                    x1 (λx1 + (1-λ)x2        x2              x
                               Trang 43
Q2



                 Định lý, bất đẳng thức Jensen
        Nếu λ1, ..., λN là các số không âm có tổng bằng 1 thì đối với
         mọi tập điểm P1, ..., PN trong miền xác định của hàm lồi f(P)
         bất đẳng thức sau đây đúng
                          ⎛ N        ⎞ N
                        f ⎜ ∑ λ n Pn ⎟ ≥ ∑ λ n f (Pn )
                          ⎜          ⎟
                          ⎝ n =1     ⎠ n =1
        Cho biến ngẫu nhiên x lấy các giá trị x1, ..., xn với các xác suất
         p1, ..., pn. Cho f(x) là một hàm lồi có miền xác định chứa x1, ...,
         xn. Chúng ta có E(x) = ∑ pi xi và E(f(x)) = ∑ pi f ( xi ) .
        Áp dụng định lý trên chúng i   ta có            i

                                    f(E(x)) ≥ E(f(x))
         Đây được gọi là bất đẳng thức Jensen.
                                    Trang 44
Slide 44

Q2         f(x1)+f(x2)+...+f(xn) >= nf((x1+x2+...+xn)/n)
           Quang, 13/03/2008
                       Bài 4 Lượng tin
4.1 Lượng tin
4.2 Lượng tin trung bình

  Vấn đề cơ bản của truyền thông là việc tái sinh tại một điểm hoặc
  chính xác hoặc gần đúng một thông báo được chọn tại một điểm
  khác.
                                              (Claude Shannon 1948)




                             Trang 45
                           Lượng tin
   Lượng tin (measure of information) dùng để so sánh định lượng
    các tin tức với nhau.
   Một tin đối với người nhận đều mang hai nội dung, một là
    độ bất ngờ của tin, hai là ý nghĩa của tin.
   Khía cạnh ngữ nghĩa chỉ có ý nghĩa đối với con người.
   Khía cạnh quan trọng nằm ở chỗ tin thật sự là một cái được
    chọn từ một tập các tin (tập các khả năng) có thể.
   Nếu số tin trong tập tin càng nhiều thì sẽ mang lại một “lượng
    tin” càng lớn khi nhận được một tin (giả sử các tin là bình đẳng
    như nhau về khả năng xuất hiện).
   Để sự truyền tin đạt hiệu quả cao chúng ta không thể đối đãi
    các tin như nhau nếu chúng xuất hiện ít nhiều khác nhau.
                             Trang 46
                                    Ví dụ
                                           n=16 -> log2n câu hỏi
                 yes=0                     -> lượng tin log2n bit


                                              yes=0
                                   yes=0
                                                         yes=0
                                               no=1
                 no=1                                     no=1
                                   no=1
Kết quả: 1010 -> số 11

                         Quá trình thực hiện 4 câu hỏi
                           Lượng tin
   Xét một tin x có xác suất xuất hiện là p(x), thì chúng ta có thể
    xem tin này như là một tin trong một tập có 1/p(x) tin với các
    tin có xác suất xuất hiện như nhau.
   Nếu p(x) càng nhỏ thì 1/p(x) càng lớn và vì vậy “lượng tin” khi
    nhận được tin này cũng sẽ càng lớn.
   Vậy “lượng tin” của một tin tỉ lệ thuận với số khả năng của một
    tin và tỉ lệ nghịch với xác suất xuất hiện của tin đó.
   Xác suất xuất hiện của một tin tỉ lệ nghịch với độ bất ngờ khi
    nhận được một tin.
          “lượng tin“ ↑ số khả năng ↑ độ bất ngờ ↓ xác suất
   Một tin có xác suất xuất hiện càng nhỏ thì có độ bất ngờ càng
    lớn và vì vậy có lượng tin càng lớn.
                             Trang 48
                              Lượng tin (tt)
   Xét một nguồn A = {a1, a2,…, am} với các xác suất xuất hiện là
    p(ai) i = 1, ..., m.
   Kí hiệu lượng tin trong mỗi tin ai là I(ai). Vậy hàm f dùng để
    biểu thị lượng tin phải thoã mãn những điều kiện gì?
   Phản ánh được các tính chất thống kê của tin tức.
        Ví dụ có hai nguồn K, L với số tin tương ứng là k, l (giả thuyết đều là
         đẳng xác suất). Nếu k > l, thì độ bất ngờ khi nhận một tin bất kỳ của
         nguồn K phải lớn hơn độ bất ngờ khi nhận một tin bất kỳ của nguồn L,
         vậy                      f(k) > f(l)
   Hợp lý trong tính toán.
        Giả thiết hai nguồn độc lập K và L với số tin tương ứng là k và l. Cho
         việc nhận một cặp ki và lj bất kỳ đồng thời là một tin của nguồn hỗn hợp
         KL. Số cặp kilj mà nguồn này có là k*l.

                                    Trang 49
                                  Lượng tin (tt)
             Độ bất ngờ khi nhận được một cặp như vậy phải bằng tổng lượng tin của
              khi nhận được ki và lj. Vì vậy chúng ta phải có:
                                            f(kl) = f(k) + f(l)
        Khi nguồn chỉ có một tin, lượng tin chứa trong tin duy nhất đó
         phải bằng không.
                                     f(1) = 0
   Định nghĩa
        Lượng đo thông tin của một tin được đo bằng logarit của độ bất
         ngờ của tin hay nghịch đảo xác suất xuất hiện của tin đó.
                                          1
                          I ( x ) = log        = − log p( x)
                                        p ( x)


                                       Trang 50
                        Lượng tin (tt)
   Lượng tin chứa trong một dãy x = a1a2 … an với ai ∈ A là
                                              n
                                   1
                 I ( x ) = log          = −∑ log p(ai )
                                 p( x)      i =1
   Trong trường hợp m kí hiệu của nguồn đẳng xác suất với nhau
    tức p(ai) = 1/m thì
                                         1
                        I (ai ) = log           = log m
                                       p(ai )
    Nếu x = a1a2 … an với ai ∈ A
                             I(x) = n logm




                            Trang 51
                        Lượng tin trung bình
   Đơn vị của lượng tin
        Nếu cơ số là 2 thì đơn vị là bits (cho các kí số nhị phân); nếu cơ
         số là e thì đơn vị là nats (cho đơn vị tự nhiên), nếu cơ số là 10
         thì đơn vị là Hartley.
   Định nghĩa
        Lượng tin trung bình của một nguồn tin A là lượng tin trung
         bình chứa trong một kí hiệu bất kỳ của nguồn tin. Nó thường
         được kí hiệu là I(A) và được tính bằng công thức sau
          I ( A) =    ∑ p(ai ) I (ai ) = − ∑ p(ai ) log p(ai )
                     ai ∈ A                  ai ∈ A

                                  Trang 52
                     Ví dụ

            Số câu hỏi nhị phân?

  1/2          1/4          1/8         1/8




    1          2             3           3

(1/2 x 1) + (1/4 x 2) + (1/8 x 3) + (1/8 x 3) =
  1.75 câu hỏi (trung bình) <> 2 câu hỏi
                                    Ví dụ
        Cho một nguồn tin U bao gồm 8 tin U = {u0, u1, u2, u3, u4, u5,
         u6, u7}, với các xác suất xuất hiện như sau:
              p(u0) p(u1) p(u2) p(u3) p(u4) p(u5) p(u6) p(u7)
               1/4 1/4 1/8 1/8 1/16 1/16 1/16 1/16
         Hãy cho biết lượng tin riêng của mỗi tin và lượng tin trung bình
         của nguồn này trong đơn vị bits.
   Giải
        Lượng tin riêng của mỗi tin là
               I(u0) I(u1) I(u2) I(u3) I(u4) I(u5) I(u6) I(u7)
                 2     2     3     3     4     4     4     4


                                  Trang 54
                             Ví dụ (tt)
   Lượng tin trung bình của nguồn là
    I(U) = (1/4) × 2 + (1/4) × 2 + (1/8) × 3 + (1/8) × 3 + (1/16) × 4
    + (1/16) × 4 + (1/16) × 4 + (1/16) × 4 = 2,75 bits.
   Điều này nói lên một ý nghĩa quan trọng rằng, chúng ta có thể
    biểu diễn mỗi tin trong nguồn U bằng một chuỗi có chiều dài
    trung bình là 2,75 bits. Nó sẽ tốt hơn so với trong trường hợp
    chúng ta không chú ý đến cấu trúc thông kê của nguồn. Lúc đó
    chúng ta sẽ biểu diễn mỗi tin trong 8 tin của nguồn bằng các
    chuỗi có chiều dài là 3 bits.




                              Trang 55
                     Bài 5 Entropy
5.1 Entropy của một biến ngẫu nhiên rời rạc
5.2 Các đặc tính của entropy
5.3 Entropy và các dãy của một biến ngẫu nhiên




                          Trang 56
           Entropy của một biến ngẫu nhiên rời rạc
   Định nghĩa
        Cho x là một biến ngẫu nhiên với không gian mẫu X = {x1, ... ,
         xN} và độ đo xác suất P(xn) = pn. Entropy của x được định nghĩa
         là:                      N
                        H (x ) = −∑ pn log( pn )
                                   n =1

               –p ln(p)
                      e-1



                            0   e-1 = 0,37        1    p

                                    Trang 57
         Entropy của một biến ngẫu nhiên rời rạc (tt)
   Ví dụ
        Cho X = {0, 1}, P(0) = p, còn P(1) = 1–p. Thì
                       H(x) = –plog(p) – (1– p) log(1– p)
                 H(x)
                     1




                       0         0,5          1   p

                                 Trang 58
                       Các đặc tính của entropy
     1. Entropy là một đại lượng luôn luôn dương hoặc bằng không.
            H(x) = 0 ⇔ có một xác suất pi = 1, còn tất cả các xác suất còn lại bằng 0.
             Điều này nói lên rằng độ bất ngờ về một thí nghiệm chỉ có một kết quả
             duy nhất là bằng 0.
     2. H(x) ≤ log N và dấu bằng xảy ra ⇔ p1 = p2 = ... = pN = 1/N.
        Hay nói cách khác entropy đạt cực đại khi xác suất xuất hiện
        của các kí hiệu bằng nhau.
   Chứng minh
                             N                     N
                                                                  ⎛ 1 ⎞
                                                                   N
    H ( x ) − ln( N ) = −∑ pn ln ( pn ) − ∑ pn ln ( N ) = ∑ pn ln⎜⎜     ⎟⎟
                           n =1            n =1           n =1    ⎝ Npn ⎠
                         N
                                ⎛ 1      ⎞ N ⎛1⎞ N
                      ≤ ∑ pn ⎜⎜      − 1⎟⎟ = ∑ ⎜ ⎟ − ∑ pn = 1 − 1 = 0
                        n =1    ⎝ Npn ⎠ n =1 ⎝ N ⎠ n =1
                                        Trang 59
                   Các đặc tính của entropy (tt)
     3. Cho biến ngẫu nhiên x có không gian mẫu X = {x1, ..., xN} và
        biến ngẫu nhiên y có không gian mẫu Y = {y1, ..., yM}. Thì biến
        ngẫu nhiên nối z = (x, y) có không gian mẫu Z = {(x1, y1), ...,
        (x1, yM), (x2, y1), ..., (x2, yM), ..., (xN, y1), ..., (xN, yM)} gồm NM
        phần tử. Nếu x, y độc lập nhau thì H(z) = H(x) + H(y).
   Chứng minh
         N M                                 N M
H(z) = −∑∑P(xn , ym ) logP(xn , ym ) = −∑∑P(xn )P( ym )[logP(xn ) + logP( ym )]
         n=1 m=1                            n=1 m=1
          N                M            M                  N
     = −∑P(xn ) logP(xn )∑P( ym ) − ∑P(xm ) logP(xm )∑P( yn )
         n=1               m=1         m=1                n=1

     = H (x) + H (y)

                                    Trang 60
                      Các đặc tính của entropy (tt)
      4. Xét một biến ngẫu nhiên x có không gian mẫu X = {x1, ..., xn,
         xn+1, ..., xN} và các xác xuất p(xi) = pi. Chúng ta phân X thành
         hai không gian con, Y = {x1, ..., xn} và Z = {xn+1, ..., xN}. Các
                                                                n
         xác suất liên kết với Y và Z được cho bởi P(Y) =∑ i =1 pi
                         N
         và P(Z) = ∑ i = n +1 pi . Hơn nữa, chúng ta định nghĩa các biến
         ngẫu nhiên y và z bằng P(yi) = P(xi)/P(Y), i = 1, 2, ..., n và P(zi)
         = P(xi)/P(Z), i = n+1, n+2, ..., N. H(x) bây giờ có thể được viết
         thành
          N                 n                    N
H ( x ) = −∑ pi log pi = −∑ pi log pi −         ∑ p log p i            i
         i =1              i =1                i = n +1
                n                                               N
     = −P(Y )∑P( yi )(logP( yi ) + logP(Y )) − P(Z ) ∑P(zi )(logP(zi ) + logP(Z ))
                i=1                                           i =n+1
     = − [P(Y )log P(Y ) + P(Z )log P(Z )] + [P(Y )H ( y) + P(Z )H ( z)]
                                    Trang 61
               Các đặc tính của entropy (tt)
        Trong biểu thức cuối cặp ngoặc vuông đầu biểu diễn độ bất ngờ liên kết
         với thí nghiệm thứ nhất (là chọn một trong hai không gian mẫu Y và Z)
         còn cặp ngoặc vuông thứ hai biểu diễn độ bất ngờ trung bình liên kết với
         thí nghiệm thứ hai (sau khi đã chọn một trong hai không gian mẫu, sẽ
         chọn tiếp sự kiện cơ bản nào). Công thức này diễn tả một tính chất của
         entropy đó là tính chất nhóm.
   Người ta đã chứng minh được rằng công thức định nghĩa của
    H(x) là công thức duy nhất phù hợp để đo về độ bất ngờ, cái mà
    phải thoả mãn các tính chất 2,3, 4 và cộng thêm tính liên tục.
   Mặc dầu hai khái niệm lượng tin trung bình và entropy xuất
    hiện một cách độc lập và ở trong những lĩnh vực khác nhau
    (entropy vốn xuất phát từ việc nghiên cứu các quá trình nhiệt
    động) nhưng chúng có cùng công thức giống nhau. Vì vậy
    chúng ta có thể xem lượng tin trung bình của một nguồn chính
    là entropy của nguồn đó.
                                   Trang 62
                       Entropy và các dãy của
                        một biến ngẫu nhiên
   Ví dụ
        Xét một biến ngẫu nhiên x có không gian mẫu X = {x1, x2},
         P(x1) = p1 = 1/3, P(x2) = 2/3. Thì entropy của x là
           H(x) = –(1/3) log(1/3) – (2/3) log(2/3) = 0.918295834 bits
        Chúng ta hãy lặp lại thí nghiệm này N lần để nhận một dãy N
         phần tử. Tổng quát có đến 2N dãy có thể. Nếu trong dãy có n
         phần tử x1 thì xác suất xuất hiện của dãy là p1n(1–p1)N–n
        Có (nN) = N! dãy như vậy, nên tổng xác suất của chúng
         bằng      n!( N −n)!    N    n        N-n
                             ( n ) p1 (1-p1 )
        Bảng bên dưới trình bày xác suất của các dãy khác nhau đối với
         N = 15

                                 Trang 63
                        Entropy và các dãy của
                        một biến ngẫu nhiên (tt)

  Số dãy P mỗi dãy         P tổng cộng n Số dãy P mỗi dãy           P tổng cộng
n
    (nN) p1n(1–p1)N–n (nN ) p1n(1–p1)N–n    (nN ) p1n(1–p1)N–n (nN ) p1n(1–p1)N–n
0       1 2–15x0.584962501  0.002284      8 6435 2–15x1.118295834    0.057404
1      15 2–15x0.651629167  0.017127      9 5005 2–15x1.184962501    0.022324
2     105 2–15x0.718295834  0.059946     10 3003 2–15x1.251629167    0.006697
3     455 2–15x0.784962501  0.129883     11 1365 2–15x1.318295834    0.001522
4 1365 2–15x0.851629167     0.194825     12   455 2–15x1.384962501   0.000254
5 3003 2–15x0.918295834     0.214307     13   105 2–15x1.451629167   0.000029
6 5005 2–15x0.984962501     0.178589     14     15 2–15x1.518295834  0.000002
7 6435 2–15x1.051629167     0.114807     15      1 2–15x1.584962501  0.000000


                                    Trang 64
                              Nhận xét
   Những dãy có xác suất lớn (dãy có khả năng) là những dãy mà
    có n gần với giá trị Np1 = 5, cụ thể là 2 ≤ n ≤ 8. Nói cách khác,
    Xác suất xuất hiện của một dãy mà có n nằm xa giá trị Np1 là
    rất nhỏ.
   Xsuất riêng của những dãy có khả năng nằm giữa 2–15×0.718295834
    và 2–15× 1.118295834, cái mà gần sát với 2–NH(x) = 2–15×0.918295834.
    Nói cách khác, Tất cả những dãy có khả năng là nhiều hay ít
    đẳng xác suất với xác suất 2–NH(x).
   Số lượng tổng cộng các dãy khả năng (2 ≤ n ≤ 8) là 22803 =
    215× 0.965129067 cái mà không xa so với 2NH(x). Nói cách khác, Số
    lượng các dãy có khả năng là khoảng 2NH(x).


                               Trang 65
                                  Định lý
   Định lý 5.1
        Cho các số ε > 0 và δ > 0 nhỏ tuỳ ý, ∃ một số nguyên dương N0
         sao cho một dãy có chiều dài bất kỳ N ≥ N0 sẽ rơi vào một trong
         hai lớp sau đây:
         (1) Một tập các dãy mà có tổng xác suất của chúng nhỏ hơn
             hoặc bằng ε.
         (2) Tập còn lại bao gồm các dãy có xác suất thoã mãn bất đẳng
             thức          − NH − A N         − NH + A N
                        2           < p<2
             với A là một số dương nào đó. Hay nói cách khác,
                              log p −1
                                       −H ≤δ
                                 N
                                 Trang 66
                    Chứng minh định lý
   Chứng minh cho nguồn rời rạc không nhớ A = {a1, a2, ..., aK}.
    Gọi x là biến ngẫu nhiên gắn với nguồn A. Ta có
                                K
                    H ( x ) = −∑ p (ak ) log p (ak )
                                k =1
   Gọi y là biến ngẫu nhiên bằng cách ánh xạ mỗi ai tới log p(ai).
                          K
                   y = −∑ p (ai ) log p (ai ) = H ( x )
                         i =1
   Xét các dãy có chiều dài N. Có tất cả KN dãy như vậy. Ta kí
    hiệu các dãy này bằng các Si và xác suất của dãy là P(Si). Ta có
                                       N
                         P( Si ) = ∏ p(a ( j ) )
                                       j =1
    trong đó a(j) là kí hiệu thứ j của dãy.

                                Trang 67
                   Chứng minh định lý
   Gọi z là biến ngẫu nhiên bằng cách ánh xạ mỗi Si tới -log P(Si).
                                    N
    Chú ý

                            i         ∑
                   − log P ( S ) = − log p (a ( j ) )
                                       j =1
   Vì vậy z là tổng của N biến ngẫu nhiên y độc lập.
   Áp dụng luật yếu của số lớn cho hai số ε > 0 và δ > 0 nhỏ tuỳ ý,
    tồn tại N0 sao cho với mọi N ≥ N0
                     ⎛⎡      N          ⎤        ⎞
                     ⎜⎢1            ( j)⎥        ⎟
                   P⎜       ∑
                     ⎜ ⎢⎣ N j = 1
                                  y
                                        ⎥
                                          − y ≥ δ⎟ ≤ ε
                                                 ⎟
                     ⎝                  ⎦        ⎠
    hay
               ⎛ ⎡1 N              ⎤         ⎞
              P⎜ − ⎢ ∑log p(a )⎥ − H (x) ≥ δ ⎟ ≤ ε
                             ( j )
               ⎜ ⎣ N j =1          ⎦         ⎟
               ⎝                             ⎠
                                Trang 68
                Chứng minh định lý (tt)
                  ⎛ 1                            ⎞
   Hay         P⎜⎜ − log P(S i ) − H ( x ) ≥ δ ⎟⎟ ≤ ε
                  ⎝ N                            ⎠
   Vì vậy chúng ta có thể kết luận rằng với xác suất lớn hơn 1– ε
                         1
                       − log P ( S i ) − H ( x ) ≤ δ
                        N
    đối với mọi N ≥ N0.
   Từ đây ta suy ra rằng các dãy được chia thành hai nhóm, một
    nhóm có tổng xác xuất nhỏ hơn hoặc bằng ε và nhóm thứ hai
    bao gồm các dãy thoã điều kiện .
                        1        1
                           log         − H (x) ≤ δ
                        N      P( Si )
   Vì vậy định lý được chứng minh.

                             Trang 69
                     Bài 6 Mã hiệu
6.1 Giới thiệu
6.2 Mã hiệu và các thông số cơ bản của mã hiệu
6.3 Một số phương pháp biểu diễn mã
6.4 Điều kiện phân tách mã




                          Trang 70
                                Giới thiệu
        Trong các hệ thống truyền tin, bên nhận thường biết tập hợp các
         tin mà bên phát dùng để lập nên các bản tin.
        Các tin thường sẽ được ánh xạ (mã hóa) thành một dạng biểu
         diễn khác thuận tiện hơn để phát đi.
   Ví dụ
        Xét một nguồn tin A = {a, b, c, d}. Chúng ta có thể thiết lập
         một song ánh như sau từ A vào tập các chuỗi trên bảng chữ cái
         {0, 1}
                             a → 00      c → 10
                             b → 01      d → 11
        Vậy để phát đi bản tin baba chúng ta phát đi chuỗi 01000100.
         Khi bên nhận nhận được chuỗi này thì xác định được bản tin
         bên phát đã phát đi là baba.
                                 Trang 71
             Mã hiệu và những thông số cơ bản
   Mã hiệu (Code), cơ số mã
        Mã hiệu là một tập hữu hạn các kí hiệu và phép ánh xạ các
         tin/bản tin của nguồn tin thành các dãy kí hiệu tương ứng. Tập
         các kí hiệu và phép ánh xạ này thường sẽ phải đáp ứng các yêu
         cầu tùy theo hệ thống truyền tin đặt ra.
        Tập các kí hiệu mã dùng để biểu diễn được gọi là bảng kí hiệu
         mã, còn số các kí hiệu thì được gọi là cơ số mã, và thường kí
         hiệu là m. Nếu mã có cơ số hai thì gọi là mã nhị phân, còn nếu
         mã có cơ số ba thì gọi là mã tam phân ...
   Mã hoá (Encoding), giải mã (decoding)
        Mã hoá là quá trình dùng các kí hiệu mã để biểu diễn các tin
         của nguồn.


                                  Trang 72
          Mã hiệu và những thông số cơ bản (tt)
        Nói cách khác mã hoá là một phép biến đổi từ nguồn tin thành
         mã hiệu, hay mã hoá là phép biến đổi từ một tập tin này thành
         một tập tin khác có đặc tính thống kê yêu cầu.
        Quá trình ngược lại của quá trình mã hoá được gọi là giải mã.
   Từ mã (Code word), bộ mã
        Từ mã là chuỗi kí hiệu mã biểu diễn cho tin của nguồn. Tập tất
         cả các từ mã tương ứng với các tin của nguồn được gọi là bộ
         mã.
        Vì vậy có thể nói mã hoá là một phép biến đổi một–một giữa
         một tin của nguồn và một từ mã của bộ mã.
        Trong một số trường hợp người ta không mã hoá mỗi tin của
         nguồn mà mã hoá một bản tin hay khối tin. Lúc này chúng ta có
         khái niệm mã khối.

                                 Trang 73
          Mã hiệu và những thông số cơ bản (tt)
        Các từ mã thường được kí hiệu là u, v, w.
   Chiều dài từ mã, chiều dài trung bình
        Chiều dài từ mã là số kí hiệu có trong từ mã thường được kí
         hiệu là l. Chiều dài trung bình của bộ mã thường được kí hiệu là
         l và được cho bằng công thức
                                    n
                              l = ∑ p ( xi )li
                                  i =1
         trong đó n là số tin của nguồn còn li là chiều dài từ mã tương
         ứng với tin xi của nguồn.
   Phân loại mã: mã đều, mã đầy, mã vơi
         Một bộ mã được gọi là mã đều nếu các từ mã của bộ mã có
         chiều dài bằng nhau.

                                  Trang 74
          Mã hiệu và những thông số cơ bản (tt)
        Một bộ mã đều có cơ số mã là m, chiều dài từ mã là l và số
         lượng từ mã n bằng với ml thì được gọi là mã đầy, ngược lại thì
         được gọi là mã vơi.
        Ngoài ra khái niệm mã đầy còn được dùng theo nghĩa rộng hơn
         như sau: một bộ mã được gọi là đầy theo một tính chất nào đó
         (chẳng hạn tính đều hay tính prefix như sau này các bạn sẽ
         thấy) nếu không thể thêm một từ mã nào vào mà vẫn giữ được
         tính chất đó.
   Ví dụ
        Cho bảng kí hiệu mã A = {0, 1}. Thì bộ mã X1 = {0, 10, 11} là
         mã không đều, bộ mã X2 = {00, 10, 11} là mã đều nhưng vơi
         còn bộ mã X3 = {00, 01, 10, 11} là mã đều và đầy.


                                  Trang 75
             Một số phương pháp biểu diễn mã
   Bảng đối chiếu mã
        Là cách liệt kê các tin của nguồn và từ mã tương ứng trong một
         bảng.
                  Tin   a1 a2 a3 a4 a5 a6
                  Từ mã 00 010 011 10 110 111

   Mặt toạ độ mã
        Là cách biểu diễn mỗi từ mã w = a0a1…al-1 bằng một điểm (l,
         b) trong mặt phẳng toạ độ hai chiều, trong đó l là chiều dài từ
         mã còn b là trọng số của từ mã được tính như sau với m là cơ số
         mã                         l −1
                               b=   ∑ i
                                     a  m i
                                    i=0
                                 Trang 76
        Một số phương pháp biểu diễn mã (tt)
   Ví dụ
                                            b                a6
    Tin   a1 a2 a3 a4 a5 a6                 7
                                                             a3
    Từ mã 00 010 011 10 110 111             6
                                            5
    Tin           a1 a2 a3     a4 a5 a6     4
                                                             a5
    Từ mã         00 010 011   10 110 111   3
                                                             a2
                                            2
    Chiều dài l   2 3     3    2 3     3            a4
                                            1
    Trọng số b    0 2     6    1 3     7            a1
                                            0
                                                1        2        3   4 l


                                Trang 77
         Một số phương pháp biểu diễn mã (tt)
   Cây mã
       Là cách biểu diễn các từ mã bằng các nút lá của một cây. Mỗi
        nút lá biểu diễn cho từ mã trùng với nhãn của con đường đi từ
        nút gốc đến nút lá này.
                               0         1
                         0    1              0   1

                    00        0     1 10         0   1
                            010 011        110 111
       Mã có cơ số m thì cây mã tương ứng sẽ là cây m phân.
       Phương pháp cây mã chỉ cho phép biểu diễn những mã prefix,
        tức là không có từ mã nào trùng với phần đi đầu của một từ mã
        khác.
                                  Trang 78
          Một số phương pháp biểu diễn mã (tt)
   Đồ hình kết cấu mã
        Là một dạng đặc biệt của cây mã, trong đó các nút lá trùng với
         nút gốc và ngoài ra mỗi cạnh của đồ hình kết cấu mã đều là
         cạnh có hướng. Vì vậy một từ mã được biểu diễn bằng một chu
         trình xuất phát từ nút gốc và quay trở về lại nút gốc.
                                0                     0
                                    0             1
                                        0,1 0,1
                               1                          1
   Hàm cấu trúc mã
        Là cách biểu diễn sự phân bố các từ mã theo độ dài của chúng.
         Phương pháp này biểu diễn bằng một hàm G(li) cho biết có bao
         nhiêu từ mã có chiều dài li.
                                    Trang 79
          Một số phương pháp biểu diễn mã (tt)
   Ví dụ
        Bộ mã trong các ví dụ trên được biểu diễn bằng hàm cấu trúc
         mã sau đây
                            G(li) = 2, khi li = 2
                                    4, khi li = 3




                                 Trang 80
                     Điều kiện phân tách mã
   Ví dụ
        Xét bộ mã X1 = {0, 10, 11} mã hoá cho nguồn A = {a, b, c}.
         Giả sử bên phát phát đi bảng tin x = abaac, lúc đó chuỗi từ mã
         tương ứng được phát đi là y = 0100011.
        Vấn đề là bên nhận sau khi nhận được chuỗi từ mã y làm sao có
         thể nhận biết được bảng tin tương ứng mà bên phát đã phát.
        Để làm được điều này, bên nhận phải thực hiện một quá trình
         được gọi là tách mã. Chẳng hạn với chuỗi kí hiệu mã nhận được
         như trên thì bên nhận chỉ có một khả năng để tách mã hợp lý là
         0 | 10 | 0 | 0 | 11 và xác định được bảng tin đã được gởi đi là
         abaac.



                                 Trang 81
             Điều kiện phân tách mã (tt)
   Xét một bộ mã khác X2 = {0, 10, 01} mã hoá cho nguồn A trên.
    Giả sử bên nhận nhận được chuỗi kí hiệu là y = 01010 và thực
    hiện quá trình tách mã. Ở đây ta thấy bên nhận có thể thực hiện
    được ba khả năng tách mã hợp lý sau 0 | 10 | 10, 01 | 0 | 10 và
    01 | 01 | 0. Và vì vậy bên nhận sẽ không biết được chính xác
    bên phát đã phát đi bảng tin nào trong ba bảng tin sau abb hay
    cab hay cca.
   Một mã như vậy thì không phù hợp cho việc tách mã và được
    gọi là mã không phân tách được (uniquely undecodable code).
   Vì vậy điều kiện để một bộ mã là phân tách được (uniquely
    decodable code) là không tồn tại dãy từ mã này trùng với dãy từ
    mã khác của cùng bộ mã.



                            Trang 82
             Điều kiện phân tách mã (tt)
   Xét một bộ mã khác X3 = {010, 0101, 10100} mã hoá cho
    nguồn A trên. Giả sử bên nhận nhận được chuỗi kí hiệu là
    01010100101 và thực hiện quá trình tách mã. Ở đây ta thấy chỉ
    có một cách tách mã duy nhất là 0101 | 010 | 0101 nhưng việc
    tách mã trở nên khó khăn hơn so với bộ mã X1.
   Chẳng hạn lúc chúng ta gặp chuỗi 010 chúng ta chưa dám chắc
    đó là một từ mã vì nó có thể là phần đi đầu của từ mã 0101,
    điều này phụ thuộc vào kí hiệu đi ngay sau chuỗi 010.
   Nếu kí hiệu đi ngay sau là 0 thì chúng ta khẳng định được 010
    là từ mã và 0 là phần đi đầu của một từ mã khác sau đó. Còn
    nếu kí hiệu đi ngay sau là 1 thì chúng ta không khẳng định
    được, vì có hai khả năng hoặc 010 là một từ mã và 1 là phàn đi
    đầu của một từ mã khác sau đó, hoặc 0101 là một từ mã.

                            Trang 83
             Điều kiện phân tách mã (tt)
   Nguyên nhân của điều này là do trong bộ mã có một từ mã này
    là tiếp đầu ngữ của một từ mã khác.
   Và đó cũng chính là nguyên nhân và bản chất của việc một dãy
    kí hiệu có thể tách thành hai dãy từ mã khác nhau.
   Thật vậy, nếu không có từ mã nào là tiếp đầu ngữ của từ mã
    khác (hay mã là prefix) thì với mỗi dãy từ mã chỉ có duy nhất
    một cách tách thành các từ mã thành phần. Vì vậy như sau này
    chúng ta sẽ thấy các mã thường được sử dụng là các mã prefix.
   Dựa vào tính tiếp đầu ngữ trên, để nhận biết một bộ mã (dĩ
    nhiên không phải là mã prefix) có phân tách được hay không
    người ta thường dùng một công cụ được gọi là bảng thử mã.



                            Trang 84
                          Bảng thử mã
   Bản chất của bảng thử mã là phân tích những từ mã dài thành
    những từ mã ngắn đi đầu.
   Chẳng hạn từ mã dài u1 có thể được phân tích thành
    v11v12...v1kw11 trong đó v11, .., v1k là các từ mã ngắn còn w11 là
    phần còn lại của u1.
   Nếu w11 cũng là một từ mã thì bộ mã này là không phân tách
    được vì chuỗi v11v12...v1kw11 có ít nhất hai cách phân tách thành
    các từ mã, đó là u1 và v11, v12, ..., v1k, w11.
   Còn nếu ngược lại w11 không là từ mã thì chúng ta dùng nó để
    xét tiếp. Trong lần xét tiếp theo chúng ta xét xem mỗi w11 này
    có là tiếp đầu ngữ của các từ mã hay không, nếu đúng với một
    từ mã nào đó, giả sử là u2, thì từ mã này sẽ có dạng v21...v2lw22
    trong đó v21, ..., v2l là các từ mã ngắn (l có thể bằng 0) còn w22
    là tiếp vĩ ngữ còn lại.
                              Trang 85
                       Bảng thử mã (tt)
   Tương tự nếu w22 cũng là một từ mã thì bộ mã là không phân
    tách được vì chuỗi v11v12...v1kw11v21...v2lw22 có ít nhất hai cách
    phân tách thành các từ mã, đó là v11v12...v1kw11 | v21 | ... | v2l |
    w22, và v11 | v12 | ... | v1k | w11v21...v2lw22.
   Nếu ngược lại w22 không là từ mã thì chúng ta dùng nó để xét
    tiếp theo khuôn mẫu tương tự như trên. Vì vậy chúng ta kết
    luận rằng
   Nếu trong một lần phân tích nào đó, có một từ mã dài, chẳng
    hạn u, được phân tích thành dãy wiiv(i+1)1...v(i+1)n trong đó wii là
    tiếp vĩ ngữ của một từ mã nào đó trong lần phân tích ngay trước
    đó, còn v(i+1)1, ..., v(i+1)n là các từ mã ngắn thì bộ mã là không
    phân tách được.



                              Trang 86
                            Bảng thử mã (tt)
   Thật vậy, lúc đó sẽ tồn tại một dãy kí hiệu sau
       v11v12...v1kw11v21...v2lw22 . . .w(i–1)(i–1)vi1...vimwiiv(i+1)1...v(i+1)n
    cái mà có thể phân tách thành hai dãy từ mã khác nhau.
   Cách 1 là
    v11 | v12 | ... | v1k | w11v21...v2lw22 | . . . | w(i–1)(i–1)vi1...vimwii | v(i+1)1 |
    ... | v(i+1)n
   Cách 2 là
    v11v12...v1kw11 | v21 | ... | v2l | w22 ...w(i–1)(i–1) | vi1 | . . . | vim |
    wiiv(i+1)1...v(i+1)n




                                     Trang 87
           Cách xây dựng bảng thử mã
(1) Đem các từ mã xếp thành một cột, theo thứ tự chiều dài của từ
    mã từ nhỏ đến lớn, đánh dấu là cột 1.
(2) Trong cột này, đối chiếu các từ mã ngắn với các từ mã dài
    hơn, nếu từ mã ngắn là tiếp đầu ngữ của từ mã dài thì ghi tiếp
    vĩ ngữ vào cột tiếp theo và đánh dấu là cột 2.
(3) Tiếp tục, đối chiếu các chuỗi trong cột 1 và cột 2 với nhau,
    nếu có chuỗi nào trong cột này là tiếp đầu ngữ của chuỗi trong
    cột kia thì tiếp vĩ ngữ sẽ được ghi vào cột tiếp theo là cột 3.
(4) Tiếp tục theo khuôn mẫu này nếu đang xét cột thứ j thì đối
    chiếu các chuỗi trong cột này với cột 1. Nếu có chuỗi nào
    trong cột này là tiếp đầu ngữ của chuỗi trong cột kia thì tiếp vĩ
    ngữ sẽ được ghi vào cột j + 1. Thực hiện cho đến khi không
    thể điền thêm được nữa hoặc cột mới thêm vào trùng với một
    cột trước đó hoặc có một chuỗi trong cột mới trùng với một từ
    mã.
                            Trang 88
                             Bảng thử mã (tt)
   Ví dụ
        Lập bảng thử mã cho bộ mã như đã nói ở trên A = {00, 01, 011,
         1100, 00010}
     1         2   3     4      5
     00        010 0     0      0              Mã là không phân tách được
                                               trên chuỗi 000101100 vì có hai
     01        1    100 1       1
                                               cách phân tách khác nhau
     011                11   11
                                                      00 | 01 | 011 | 00
     1100               0010 0010
     00010                      100                     00010 | 1100
                                00
                                10
                                    Trang 89
                           Bảng thử mã (tt)
   Ví dụ:
      Xét bộ mã {010, 0101, 10100} có bảng thử mã như

       sau:
         1        2    3       4    5     6
      010     1       0100 0       10    100   Mã là phân
      0101                         101   00    tách được

      10100
                           Bảng thử mã (tt)
        Điều kiện cần và đủ để một bộ mã phân tách được là không có
         phần tử nào trong các cột từ j ≥ 2 trùng với một phần tử trong
         cột 1.
   Độ chậm giải mã
        Độ chậm giải mã, thường kí hiệu là Tch, là số kí hiệu cần phải
         nhận được đủ để có thể phân tách (nhận dạng) được từ mã.
        Trong trường hợp không có chuỗi nào trong các cột j ≥ 2 trùng
         với từ mã nhưng có hai cột k, l nào đó (k ≠ l, k, l ≥ 2 ) trùng
         nhau thì mã là phân tách được nhưng có độ chậm giải mã vô
         hạn.




                                  Trang 91
                       Bảng thử mã (tt)
   Xét bộ mã {01, 10, 011, 100} có bảng thử mã như sau:
                       1       2        3        4
                 01        1           0    1
                 10        0           00   11
                 011                   1    0
                 100                   11   00
   Bảng thử mã này có các cột 3 và 4 trùng nhau về các chuỗi nên
    bộ mã có độ chậm giải mã trong trường hợp xấu nhất là vô hạn.
   Chẳng hạn với chuỗi có dạng sau đây thì trong quá trình nhận
    chưa hết chuỗi chúng ta không thể thực hiện được việc tách mã:
                            0110101010...

                            Trang 92
                            Bài tập
   Hãy lập bảng thử mã cho những bộ mã sau. Cho biết mã có
    phân tách được không, nếu được thì độ chậm giải mã (trong
    trường hợp xấu nhất) là bao nhiêu.
   X1 = {00, 01, 100, 1010, 1011}
   X2 = {00, 01, 101, 1010}
   X3 = {00, 01, 110, 111, 1100}
   X4 = {00, 01, 110, 111, 1110}
   X5 = {00, 01, 110, 111, 0111}
   X6 = {00, 01, 110, 111, 1011, 1101}




                            Trang 93
                         Bất đẳng thức Kraft
   Định lý 6.1
        Cho l1, l2, ..., lK là các chiều dài của một bộ mã prefix có bảng
         kí hiệu mã kích thước m (tức gồm m kí hiệu mã). Thì
                                 K
                                     − li
                                 ∑ m      ≤1
                                 i =1
        Ngược lại, nếu các số nguyên l1, l2, ..., lK thoả bất đẳng thức
         trên thì tồn tại một bộ mã prefix với các từ mã có chiều dài là l1,
         l2, ..., lK.
   Chứng minh
     Chiều thuận
      Gọi T là cây mã tương ứng với bộ mã trên



                                     Trang 94
                  Bất đẳng thức Kraft
          Mức 0                        Gốc
          Mức 1
          Mức 2
                    m-2 m-2    m-2          m-2 m-2 m-2
          Mức 3
                          m-3    m-3 m-3 m-3 m-3
   Nút lá ở mức li sẽ được gán trọng số là m-li.
   Trọng số của mỗi nút cha được tính bằng tổng trọng số của các
    nút con.
   Với cách gán này, chúng ta suy ra trọng số của nút cha ở mức h
    là ≤ m-h.
   Điều này đúng là vì mỗi nút cha mức h có tối đa m nút con mức
    h + 1.

                            Trang 95
                      Bất đẳng thức Kraft (tt)
      Từ đây suy ra, trọng số của nút gốc là ≤ 1.
      Mà trọng số của nút gốc chính là tổng trọng số của các nút lá.

      Vậy suy ra điều cần chứng minh.

     Chiều đảo
      Chúng ta chứng minh bằng cách xây dựng một cây mã cho nó.

      Điều này là thực hiện được theo như chứng minh của chiều

       thuận.
   Ví dụ
        Tìm bộ mã prefix cho các bộ mã nhị phân có các chiều dài từ
         mã tương ứng như sau.
        {2, 2, 3, 4, 4}, {2, 2, 3, 3, 3, 4, 4}, {2, 2, 3, 4, 4, 4, 5, 5}

                                   Trang 96
                                        Định lý
   Định lý 6.2
        Một mã phân tách được thì có các chiều dài từ mã thoả mãn bất
         đẳng thức Kraft.     K
                                    − li
                             ∑   m       ≤1
                                    i =1
   Chứng minh
        Gọi l1 ≤ l2 ≤ ... ≤ lK là các chiều dài từ mã với cơ số là m.
        Với số nguyên N bất kỳ ta có thể viết
                                N
                ⎛ K
                       − li ⎞
                                           K        K
                                                              (                  )
                ⎜∑ m ⎟                  ∑ L∑ m
                                                            − l i1 + L + l i N
                                    =
                ⎝ i =1      ⎠           i1 =1      i N =1



                                        Trang 97
                         Định lý 6.2 (tt)
   Chú ý l i + L + l i là chiều dài của một dãy N từ mã và có thể
            1          N
    nhận giá trị bất kỳ giữa Nl1 và NlK. Gọi Aj là số dãy N từ mã mà
    có tổng chiều dài là j. Thì
                                  N
                  ⎛ K
                         − li ⎞
                                          Nl K
                  ⎜∑m ⎟ =                 ∑ j
                                           A  m −j

                  ⎝ i =1      ⎠           j = Nl1

   Vì bộ mã là phân tách được, nên các dãy N từ mã mà có tổng
    chiều dài là j phải khác nhau.
   Số các dãy có chiều dài j tối đa là mj. Vì vậy Aj ≤ mj và
                     N
        ⎛  K
               − li ⎞
                           Nl K
        ⎜∑m ⎟ ≤            ∑m m       j    −j
                                                    = N (lK − l1 ) + 1
        ⎝ i =1      ⎠     j = Nl1

                              Trang 98
                Chứng minh định lý (tt)
                             K
   Nếu
                             ∑ >1
                              m − li

                             i =1

                                           N
                    ⎛    K
                             ⎞                              N (l K − l1 ) + 1

                     ∑
    Thì với N đủ lớn ⎜
                    ⎝ i =1
                           m ⎟
                             ⎠
                                    − li       sẽ lớn hơn

   Vì vậy chúng ta có được điều cần chứng minh.
                             K

                             ∑ ≤1
                              m − li

                             i =1
   Kết hợp hai định lý trên chúng ta rút ra một nhận xét sau.
   Nếu một mã phân tách được thì tồn tại một bộ mã tương đương
    về chiều dài các từ mã mà có tính prefix.

                                    Trang 99
                 Bài 7 Mã hóa tối ưu
               nguồn rời rạc không nhớ
7.1 Các định lý về giới hạn trên và dưới của chiều dài trung
    bình
7.2 Mã hoá theo Shannon và Fano
7.3 Phương pháp mã hoá tối ưu theo Huffman




                           Trang 100
            Các định lý về giới hạn trên và dưới của
                     chiều dài trung bình
   Định lý 7.1
        Cho nguồn tin X = {a1, ..., aK} với các xác suất tương ứng p1,
         ..., pK. Một bộ mã phân tách được bất kỳ cho nguồn này với cơ
         số mã m, chiều dài trung bình từ mã sẽ thoả (trong đó H(X) là
         entropy của nguồn với cơ số của logarit là m).
                                     H (X )
                                 l≥
                                     log m
   Chứng minh
                               K            K             K
                                                                 m − li
         H ( X ) − l ln m = −∑ pi ln pi − ∑ pi li ln m = ∑ pi ln
                             i =1         i =1           i =1     pi
                           K
                                ⎛ m − li     ⎞ ⎛ K − li ⎞
                        ≤ ∑ pi ⎜⎜        − 1⎟⎟ = ⎜ ∑ m ⎟ − 1 ≤ 1 − 1 = 0
                          i =1  ⎝ pi         ⎠ ⎝ i =1   ⎠
                                    Trang 101
            Các định lý về giới hạn trên và dưới của
                   chiều dài trung bình (tt)
                                             m − li
        Chú ý dấu “=” xảy ra khi và chỉ khi        = 1 , tức là pi = m − li
                                              pi
   Định lý 7.2
        Cho nguồn tin X = {a1, ..., aK} với các xác suất tương ứng p1,
         ..., pK, có thể xây dựng một mã prefix với cơ số m sao cho
                                    H (X )
                                 l<        +1
                                    log m
   Chứng minh
                                                                   ⎡
         Chọn chiều dài li của từ mã cho tin ai theo qui tắc li = − log mi
                                                                               p
                                                                                   ⎤
        Chúng ta có
                 li = ⎡− log mpi ⎤ ⇒ li ≥ − log mpi ⇒ m − li ≤ pi
                                      K          K
                                 ⇒ ∑ m −li ≤ ∑ pi = 1
                                      i =1       i =1

                                    Trang 102
                Chứng minh định lý (tt)
   Vì các chiều dài được chọn này thoã bất đẳng thức Kraft nên
    tồn tại một mã prefix tương ứng có các chiều dài này.
   Tiếp tục chúng ta có
                li = ⎡− log mpi ⎤ ⇒ li < − log mpi + 1
                 K             K                K

                ∑ i i ∑ i m + ∑ pi
                 p l
                 i =1
                     < − p log pi

                               i =1             i =1

                             ⎛ K pi log pi ⎞        H (X )
                          = ⎜⎜ − ∑         ⎟⎟ + 1 =        +1
                             ⎝ i =1 log m ⎠         log m
   Điều này hoàn tất chứng minh của chúng ta.


                              Trang 103
                            Hệ quả
   Có thể mã hoá một nguồn mà có chiều dài trung bình tiếp cận
    đến                     H (X )
    với sai số nhỏ tuỳ ý.   log m
   Chúng ta thực hiện điều này bằng cách mã hoá các dãy N tin
    của nguồn X = {a1, ..., aK} theo Định lý 7.2.
   Lúc này chúng ta có nguồn mới với kích thước là KN, mỗi phần
    tử là một dãy của N tin được lấy độc lập từ nguồn X.
   Entropy của nguồn mới này là NH(X) và chiều dài trung bình
    các từ mã của nó theo định nghĩa sẽ là N lần chiều dài trung
    bình các từ mã của nguồn ban đầu, l .
   Áp dụng Định lý 7.1 và Định lý 7.2 đối với nguồn mới chúng ta
    có
                           Trang 104
                               Hệ quả (tt)
        Áp dụng Định lý 7.1 và Định lý 7.2 đối với nguồn mới ta có
      NH (X )           NH (X )         ⇒
                                              H (X )        H (X ) 1
              ≤ Nl <             +1                  ≤l <          +
       log m             log m                log m         log m N
      Vì N có thể lớn tuỳ ý, nên l tiếp cận đến H(X) / log m với tốc

         độ tương đương với 1/N tiến đến 0 khi N tiến ra vô cùng.
        Để đánh giá một phương pháp mã hoá nào đó là tốt hay không
         người ta đưa ra khái niệm hiệu suất lập mã.
   Hiệu suất lập mã
        Hiệu suất lập mã h được định nghĩa bằng tỉ số của entropy của
         nguồn với chiều dài trung bình của bộ mã được lập
                                   H (X )
                                h=
                                     l
                                 Trang 105
                      Mã hóa tối ưu
   Là phép mã hóa mà kết quả là một bộ mã có chiều dài trung
    bình là nhỏ nhất trong tất cả các phép mã hóa có thể có cho
    nguồn.
   Bộ mã của phép mã hóa tối ưu cho nguồn được gọi là bộ mã tối
    ưu.
   Ba phép mã hóa: Shannon, Fano, Huffman.
   Trong mỗi phép mã hóa chúng ta sẽ mã hóa với cơ số mã m = 2
    trước (mã hóa nhị phân), sau đó sẽ mở rộng cho trường hợp m
    > 2.




                           Trang 106
         Phương pháp mã hoá Shannon
B1. Sắp xếp các xác suất theo thứ tự giảm dần. Không mất tổng
    quát giả sử p1 ≥ ... ≥ pK.
                               i −1

B2. Định nghĩa q1 = 0, qi =    ∑p
                                j =1
                                       j   , ∀ i = 1, 2, ..., K.

B3. Đổi qi sang cơ số 2, (biểu diễn qi trong cơ số 2) sẽ được một
    chuỗi nhị phân

B4. Từ mã được gán cho ai là li kí hiệu lấy từ vị trí sau dấu phẩy
    của chuỗi nhị phân tương ứng với qi, trong đó li = ⎡ − log pi ⎤
                                                          ⎢     2 ⎥



                              Trang 107
                                  Ví dụ
   Hãy mã hoá nguồn S = {a1, a2, a3, a4, a5, a6} với các xác suất
    lần lượt là 0,3; 0,25; 0,2; 0,12; 0,08; 0,05.
                        i −1
Tin Xác suất                      Biểu diễn                       Từ mã
             qi = ∑ p j                       li = ⎡− log2 pi ⎤
 ai    pi         j =1            nhị phân                          wi
a1     0,3       0              0,00          2                   00
a2     0,25      0,3            0,01001...    2                   01
a3     0,2       0,55           0,10001...    3                   100
a4     0,12      0,75           0,11000...    4                   1100
a5     0,08      0,87           0,11011...    4                   1101
a6     0,05      0,95           0,111100...   5                   11110
   H = 2.36, l = 2,75, h = 2,36/2,75 = 85,82%
                               Trang 108
                           Nhận xét - Bài tập
        Phương pháp Shannon cho kết quả là một mã prefix.
        Phương pháp Shannon có thể mở rộng cho trường hợp m > 2
   Bài tập
        Hãy mã hoá các nguồn sau bằng phương pháp Shannon. Tính
         entropy của nguồn, chiều dài trung bình và hiệu suất của phép
         mã hóa.
        S1 = {a1, a2, a3, a4, a5, a6} với các xác suất lần lượt là 0,25;
         0,21; 0,19; 0,16; 0,14; 0,05.
        S2 = {a1, a2, a3, a4, a5, a6 , a7, a8} với các xác suất lần lượt là
         0,21; 0,18; 0,15; 0,14; 0,12; 0,01; 0,06 ; 0,04.
        S3 = {a1, a2, a3, a4, a5, a6 , a7, a8 , a9} với các xác suất lần lượt
         là 0,25; 0,19; 0,15; 0,11; 0,09; 0,07; 0,06; 0,04; 0,04.

                                   Trang 109
           Phương pháp mã hoá Fano
B1. Sắp xếp các xác suất theo thứ tự giảm dần. Không mất tổng
    quát giả sử p1 ≥ ... ≥ pK.
B2. Phân các xác suất thành 2 nhóm có tổng xác suất gần bằng
    nhau nhất.
B3. Gán cho hai nhóm lần lượt các kí hiệu 0 và 1 (hoặc ngược
    lại).
B4. Lặp lại bước 2 cho các nhóm con cho đến khi không thể tiếp
    tục được nữa.
B5. Từ mã ứng với mỗi tin là chuỗi bao gồm các kí hiệu theo thứ
    tự lần lượt được gán cho các nhóm có chứa xác suất tương
    ứng của tin.


                          Trang 110
                                Ví dụ
   Hãy mã hoá nguồn S = {a1, a2, a3, a4, a5, a6} với các xác suất
    lần lượt là 0,3; 0,25; 0,2; 0,12; 0,08; 0,05.
                        Phân nhóm lần
           Tin Xác suất                     Từ mã
                        1 2 3 4
           a1 0,3       0 0                00
           a2 0,25      0 1                01
           a3 0,2       1 0                10
           a4 0,12      1 1 0              110
           a5 0,08      1 1 1 0            1110
           a6 0,05      1 1 1 1            1111
   H = 2.36, l = 2,38, h = 2,36/2,38 = 99,17%
                             Trang 111
                                    Chú ý
        Chú ý, trong nhiều trường hợp có nhiều hơn một cách chia
         thành các nhóm có tổng xác suất gần bằng nhau, ứng với mỗi
         cách chia có thể sẽ cho ra các bộ mã có chiều dài trung bình
         khác nhau.
   Ví dụ
        Hãy mã hoá nguồn S = {a1, a2, a3, a4, a5, a6, a7, a8} với các xác
         suất lần lượt là 0,23; 0,2; 0,14; 0,12; 0,1; 0,09; 0,06; 0,06.




                                  Trang 112
                                      Ví dụ
ai    pi    1      2   3 4      wi            ai    pi    1     2   3 4  wi
a1   0,23   0      0           00             a1   0,23   0     0       00
a2   0,2    0      1           01             a2   0,2    0     1   0   010
a3   0,14   1      0   0       100            a3   0,14   0     1   1   011
a4   0,12   1      0   1       101            a4   0,12   1     0   0   100
a5   0,1    1      1   0   0   1100           a5   0,1    1     0   1   101
a6   0,09   1      1   0   1   1101           a6   0,09   1     1   0   110
a7   0,06   1      1   1   0   1110           a7   0,06   1     1   1 0 1110
a8   0,06   1      1   1   1   1111           a8   0,06   1     1   1 1 1111

    l 1 = 2,88,                                   l 2 = 2,89
                                  Trang 113
                          Nhận xét - Bài tập
   Nhận xét
        Phương pháp Fano thường cho kết quả tốt hơn phương pháp
         Shannon.
   Bài tập
        Hãy mã hoá các nguồn sau bằng phương pháp Fano. Tính hiệu
         suất của phép mã hóa.
        S1 = {a1, a2, a3, a4, a5, a6} với các xác suất lần lượt là 0,25;
         0,21; 0,19; 0,16; 0,14; 0,05.
        S2 = {a1, a2, a3, a4, a5, a6 , a7, a8} với các xác suất lần lượt là
         0,21; 0,18; 0,15; 0,14; 0,12; 0,1; 0,06 ; 0,04.
        S3 = {a1, a2, a3, a4, a5, a6 , a7, a8 , a9} với các xác suất lần lượt
         là 0,25; 0,19; 0,15; 0,11; 0,09; 0,07; 0,06; 0,04; 0,04.

                                   Trang 114
          Phương pháp mã hoá tối ưu Huffman
        Trước hết xét cơ số mã m = 2. Trường hợp m > 2, chúng ta sẽ
         có một sự chú ý về sự khác biệt so với trường hợp m = 2.
   Bổ đề
        Cho nguồn S = {a1, ..., aK} có các xác suất lần lượt là p1, ..., pK.
         Gọi l1, ..., lK là chiều dài các từ mã tương ứng với bộ mã tối ưu
         cho S. Nếu pi > pj thì li ≤ lj.
   Chứng minh
        Với pi > pj, giả sử li > lj. Xét bộ mã mới bằng cách hoán đổi hai
         từ mã có chiều dài li và lj cho nhau. Xét hiệu chiều dài trung
         bình của bộ mã mới so với bộ mã cũ
                  Δl = pilj + pjli – pili – pjlj = (pj – pi)(li – lj) < 0
         Điều này mâu thuẫn với định nghĩa của bộ mã tối ưu.

                                   Trang 115
                    Hai định lý của Huffman
        Bổ đề này thật sự phát biểu một điều rằng, để mã hoá tối ưu cho
         một nguồn tin thì tin có xác suấ càng lớn phải được mã hoá
         thành từ mã có chiều dài càng nhỏ.
   Định lý 7.3 (Định lý số 1 của Huffman)
        Trong bộ mã tối ưu (m = 2) cho một nguồn tin, thì hai từ mã
         tương ứng với hai tin có xác suất nhỏ nhất phải có chiều dài
         bằng nhau (lK–1 = lK) và có thể làm cho chúng chỉ khác nhau
         duy nhất ở bit cuối (bit tận cùng bên phải).
   Chứng minh
        Nếu lK–1 < lK thì loại bỏ bit cuối cùng của từ mã wK chúng ta
         được một bộ mã mới vẫn có tính prefix nhưng có chiều dài
         trung bình nhỏ hơn bộ mã cũ.


                                  Trang 116
            Hai định lý của Huffman (tt)
   Giả sử wK–1 và wK không thoả điều kiện là khác nhau chỉ ở bit
    cuối.
   Nếu có một từ mã wi khác có chiều dài bằng lK đồng thời khác
    từ mã wK chỉ ở bit cuối thì chúng ta có thể hoán đổi wK–1 và wi
    cho nhau, vì vậy định lý cũng được chứng minh.
   Nếu không tồn tại một từ mã wi như vậy thì chúng ta có thể tạo
    ra một bộ mã mới bằng cách bỏ đi bit cuối của từ mã wK. Bộ mã
    mới này không vi phạm điều kiện prefix và có chiều dài trung
    bình nhỏ hơn bộ mã cũ. Vì vậy định lý được chứng minh.




                            Trang 117
                  Hai định lý của Huffman (tt)
   Định lý 7.4 (Định lý số 2 của Huffman)
        Xét một nguồn mới S’ = {a’1, ..., a’K–1} với sự phân bố xác suất
         là p’1, ... , p’K–1 trong đó p’i = pi với 1 ≤ i ≤ K – 2 còn p’K–1 =
         pK–1 + pK. Nếu {w’1, ..., w’K–1} làm một mã tối ưu cho S’ thì mã
         nhận được theo qui tắc sau là mã tối ưu cho S.
                                    wi = w’i,       1≤i≤K–2
                                    wK–1 = w’K–10
                                    wK = w’K–11
   Chứng minh
        Vì lK = lK–1 = 1 + l’K–1, nên
         l = p1l1 + ... + pKlK = p1l’1 + ... + (pK–1 + pK)(1 + l’K–1)
            = l ' + (pK–1 + pK)

                                    Trang 118
            Hai định lý của Huffman (tt)
   Sự khác biệt giữa l và l ' là một hằng số.
   Nên nếu mã tối ưu cho nguồn S là tốt hơn mã theo qui tắc đã
    phát biểu thì mã được dẫn xuất từ mã tối ưu này bằng cách bỏ
    đi hai từ mã wK và wK–1 và thay vào từ mã mà bỏ đi bit cuối của
    wK thì sẽ được một mã tối ưu tốt hơn cho nguồn S’, điều này
    mâu thuẫn.
   Vậy mã nhận được cho S theo qui tắc trên là tối ưu.
   Định lý Định lý 7.3 và 7.4 cho phép qui bài toán tìm mã tối ưu
    cho nguồn có K tin về bài toán tìm mã tối ưu cho nguồn có K–1
    tin. Và quá trình này có thể được lặp lại cho đến khi chỉ còn hai
    tin. Lúc đó thì mã tối ưu là dễ thấy.


                             Trang 119
                  Giải thuật mã hóa Huffman
     B1. Sắp xếp các xác suất theo thứ tự giảm dần chẳng hạn p1 ≥ ...
         ≥ pK
     B2. Gán 0 tới bit cuối của wK–1 và 1 đến bit cuối của wK hoặc
         ngược lại. Tuy nhiên chúng ta sẽ qui ước thực hiện theo chiều
         thứ nhất.
     B3. Kết hợp pK và pK–1 để tạo thành một tập xác suất mới p1, ... ,
         pK–2, pK–1 + pK
     B4. Lặp lại các bước trên cho tập mới này.
   Ví dụ
        Hãy mã hoá nguồn S = {a1, a2, a3, a4, a5, a6} với các xác suất
         lần lượt là 0,3; 0,25; 0,2; 0,12; 0,08; 0,05.

                                  Trang 120
                                Ví dụ
ai        pi    Lần 1    Lần 2          Lần 3   Lần 4   wi
a1     0,3      0,3      0,3       0,55 0 00
                                        0,45
a2     0,25     0,25        0,3 0 0,45 1 01
                         0,25
a3     0,2    0,2    0,25 0 0,25 1        11
a4     0,12   0,13 0 0,2 1                101
a5     0,08 0 0,12 1                      1000
a6     0,05 1                             1001

    H = 2.36, l = 2,38, h = 2,36/2,38 = 99,17%



                            Trang 121
                                Nhận xét
   Nhận xét
        So sánh với phương pháp Fano ta thấy trong trường hợp trên thì
         cả hai phương pháp cho hiệu suất bằng nhau.
        Tuy nhiên trong trường hợp tổng quát phương pháp Fano
         không phải là phương pháp mã hóa tối ưu.
   Chú ý
        Trong trường hợp nếu xác suất pK–1 + pK bằng với một xác suất
         pi nào đó thì chúng ta có thể đặt pK–1 + pK nằm dưới hoặc nằm
         trên xác suất pi thì kết quả chiều dài từ mã trung bình vẫn
         không thay đổi cho dù các từ mã kết quả có thể khác nhau.



                                 Trang 122
              Mở rộng cho cơ số m > 2
 Nếu K ≤ m thì việc mã hoá tối ưu là quá tầm thường
 Giả sử K > m, tồn tại n sao cho: m + (n – 1)(m – 1) < K ≤ m +
  n(m – 1). Chúng ta sẽ bổ sung vào một số tin “phụ” có xác suất
  bằng 0 sao cho tổng số tin của nguồn bằng với m + n(m – 1).
  Sau đó thủ tục mã hoá trên được điều chỉnh như sau
B1. Sắp xếp các xác suất theo thứ tự giảm dần chẳng hạn p1 ≥ ...
    ≥ pK
B2. Gán lần lượt các kí hiệu 0, 1, ..., m – 1 tới các bit cuối của m
    từ mã có xác suất nhỏ nhất
B3. Kết hợp m xác suất nhỏ nhất lại thành một và tạo với K – m
    xác suất còn lại thành một tập mới.
B4. Lặp lại các bước trên cho tập mới này.
                           Trang 123
                               Ví dụ
   Hãy mã hoá nguồn S = {a1, a2, a3, a4, a5, a6} với các xác suất
    lần lượt là 0,3; 0,25; 0,2; 0,12; 0,08; 0,05 với m = 3.
            ai      pi     Lần 1 Lần 2            wi
           a1 0,3          0,3       0,45 0 1
           a2 0,25         0,25      0,3 1 2
           a 0,2
            3              0,2 0 0,25 2 00
          a4    0,12   0,13 1                02
          a5    0,08 0 0,12 2                010
          a6    0,05 1                       011
          a7    0,0 2

   H = 1.49, l = 1,58, h = 1,49/1,58 = 94,24%
                            Trang 124
                                 Bài tập
   Hãy mã hoá các nguồn sau bằng phương pháp Huffman theo
    các cơ số m = 2 và m = 3. Tính hiệu suất của phép mã hóa trong
    mỗi trường hợp.
   S1 = {a1, a2, a3, a4, a5, a6} với các xác suất lần lượt là 0,25;
    0,21; 0,19; 0,16; 0,14; 0,05.
   S2 = {a1, a2, a3, a4, a5, a6 , a7, a8} với các xác suất lần lượt là
    0,23; 0,2; 0,14; 0,12; 0,1; 0,09; 0,06 ; 0,06.
   S3 = {a1, a2, a3, a4, a5, a6 , a7, a8} với các xác suất lần lượt là
    0,21; 0,18; 0,15; 0,14; 0,12; 0,01; 0,06 ; 0,04.
   S4 = {a1, a2, a3, a4, a5, a6 , a7, a8 , a9} với các xác suất lần lượt là
    0,25; 0,19; 0,15; 0,11; 0,09; 0,07; 0,06; 0,04; 0,04.


                                Trang 125
                                 Nhận xét
        Xét nguồn S = {a1, a2, a3, a4} có sự phân bố xác suất là {0,4;
         0,25; 0,2; 0,15}. Xét nguồn mới S2 = {aiaj, 1 ≤ i, j ≤ 4} có tập
         phân bố xác suất là {0,16; 0,1; 0,08; 0,06; 0,1; 0,0625; 0,05;
         0,0375; 0,08; 0,05; 0,04; 0,03; 0,06; 0,0375; 0,03; 0,0225}.
        H(S) = 1,9 và H(S2) = 2H(S) = 3,8.
        Hai bảng sau đây trình bày kết quả việc mã hoá tối ưu cho S và
         S2 theo Huffman.
   Nhận xét
        Việc mã hoá cho một dãy tin (hay khối tin) thì cho hiệu suất
         cao hơn so với việc mã hoá cho từng tin.



                                  Trang 126
                          Nhận xét (tt)

Tin     pi    Từ mã    Tin      pij        Từ mã     Tin     pij    Từ mã
a1     0,4    1        a1a1   0,16         000     a2a3    0,05     1110
a2     0,25   01       a1a2   0,1          101     a3a2    0,05     1111
a3     0,2    000      a2a1   0,1          110     a3a3    0,04     01000
a4     0,15   001      a1a3   0,08         0010    a2a4    0,0375   01001
                       a3a1   0,08         0011    a4a2    0,0375   01010
     l S = 1,95       a2a2   0,0625       0110    a3a4    0,03     01011
     h1 = 97,63%      a1a4   0,06         0111    a4a3    0,03     10010
     l S 2 = 3,8375   a4a1   0,06         1000    a4a4    0,0225   10011
     h2 = 99,26%
                               Trang 127
            Bài 8 Mã hóa nguồn phổ quát
8.1 Nguồn rời rạc không nhớ với thống kê không biết trước
8.2 Các vectơ tần xuất và tựa–entropy (quasi–entropy)
8.3 Một sơ đồ mã hoá phổ quát cho nguồn rời rạc không
    nhớ




                          Trang 128
                          Giới thiệu
   Vấn đề này không được khởi xướng bởi Shannon mà bởi B. M.
    Fitingof.
   Lý thuyết của Shannon dựa trên kiến thức về các hàm phân bố
    xác suất và chứng minh tồn tại phép mã hoá tối ưu.
   Mã hoá nguồn phổ quát tiếp cận theo cách khác bằng việc lợi
    dụng cấu trúc của các dãy và cũng đi đến được cùng kết quả tối
    ưu.
   Trong trường hợp mà các hàm phân bố xác suất là không có sẵn
    hoặc sự thống kê về nguồn là thay đổi theo thời gian, những
    điều mà thường xảy ra trong thực tế, thì kỹ thuật mã hoá nguồn
    phổ quát là một lựa chọn thích hợp hơn là dùng kỹ thuật của
    Shannon.

                            Trang 129
               Nguồn rời rạc không nhớ với
                thống kê không biết trước
   Xét nguồn A = {a1, ..., aK} có sự phân bố xác suất là {p1, ..., pK}
    sinh ra một dãy các kí hiệu độc lập có phân bố đồng nhất.
   Chúng ta giả thiết rằng sự phân bố xác suất {p1, ..., pK} là cố
    định nhưng không được biết trước bởi bộ mã hoá (encoder).
   Thực tế sự phân bố xác suất thường là không được biết trước
    hoặc chỉ được biết ở mức độ gần đúng, hoặc sự phân bố này
    thay đổi chậm theo thời gian.
   Vì vậy một sơ đồ mã hoá dựa trên xác suất có thể hiệu quả ở
    khung thời gian này nhưng sẽ không hiệu quả ở khung thời gian
    khác.



                              Trang 130
              Nguồn rời rạc không nhớ với
              thống kê không biết trước (tt)
   Đánh giá ảnh hưởng của sự biết không chính xác về thống kê
    của nguồn đến hiệu quả của việc mã hoá
   Xét nguồn rời rạc không nhớ nhị phân với sự phân bố xác suất
    là P(0) = p, P(1) = 1– p.
   Nếu bộ mã hoá được cung cấp xác suất gần đúng với p là p0 thì
    theo phương pháp của Shannon kí hiệu 0 sẽ được gán với từ mã
    có chiều dài là –log p0 còn 1 được gán với từ mã có chiều dài –
    log (1– p0).
   Chiều dài trung bình của các từ mã là
                     l = –p log p0 – (1–p) log(1–p0)
   Chiều dài trung bình từ mã tối ưu là
                  l opt = –p log p – (1–p) log(1–p)

                            Trang 131
              Nguồn rời rạc không nhớ với
              thống kê không biết trước (tt)
                                     l


                                           l opt



                  0                          1     p

   Chú ý rằng l là một tiếp tuyến của l opt tại p = p0, nhưng khi p
    lệch ra xa p0 thì khoảng cách giữa hai đồ thị gia tăng khá nhanh.


                             Trang 132
              Nguồn rời rạc không nhớ với
              thống kê không biết trước (tt)
   Trong bài này chúng ta phát triển các ý tưởng cơ bản về mã hoá
    phổ quát, một sơ đồ mã hoá không dựa trên xác xuất của các
    dãy mà lại dựa vào cấu trúc của chúng.
   Chúng ta sẽ chứng minh rằng ∀ ε nguyên dương nhỏ tuỳ ý có
    khả năng mã hoá một nguồn sao cho l ≤ H(x) + ε đối ∀ sự
    phân bố xác suất {p1, ..., pK} của nguồn.
   ε có thể được làm nhỏ                          Cận trên của l
    tuỳ ý bằng cách chọn
    chiều dài khối tin cần
    mã hoá đủ lớn.                                l opt

                                    0                    1    p
                            Trang 133
        Các vectơ tần suất và tựa-entropy
   Xét các dãy nguồn Si có chiều dài N.
   Có KN dãy và ta gọi tập KN dãy này là không gian mẫu S.
   Chúng ta kí hiệu Nki là số kí hiệu ak có trong dãy Si và qki là tần
    suất của ak trong Si
                                 qki = Nki / N
   Vectơ (q1i, ..., qKi) (kí hiệu là Q(Si) hay gọn hơn là Qi) được gọi
    là vectơ tần suất ứng với chuỗi Si.
   Gọi các qk (k = 1, ..., K) là các biến ngẫu nhiên trên S bằng cách
    gán mỗi Si với qki. Chúng ta có bổ đề sau.
   Giá trị trung bình của qk chính là xác suất pk của ak.
                          KN
               E (q k ) = ∑ P(S i )qki = pk
                          i =1
                                 Trang 134
          Các vectơ tần suất và tựa-entropy (tt)
   Chứng minh
        Định nghĩa biến ngẫu nhiên xk(n) bằng 1/N nếu nguồn sinh ra kí
         hiệu ak tại vị trí thứ n của dãy và bằng 0 nếu ngược lại.
         Vì nguồn là không nhớ, dãy xk(1), ..., xk(N) là độc lập và có phân
         bố đồng nhất.                                            N
         Giá trị trung bình của xk(n) bằng pk/N ∀ n. Mà q k = ∑ x k
                                                                      (n)

         Vì vậy                        N                         n =1
                          E (q k ) = ∑ E (x k ) = pk
                                              (n)

                                     n =1
        Mỗi dãy Si có tương ứng một vectơ tần suất Qi, nhưng ngược
         lại với một vectơ Q = (q1, ..., qK) có thể tương ứng với nhiều
         dãy Si.

                                   Trang 135
          Các vectơ tần suất và tựa-entropy (tt)
        Gọi ω(Q) là số các dãy Si mà có cùng vectơ tần suất Q (tức là
         những dãy mà có số lần xuất hiện của mỗi ak trong dãy bằng
         nhau và bằng Nk = Nqk ∀ k = 1, ..., K).
                                              N!
                           ω (Q) =
                                     ∏
                                          K
                                          k =1
                                                 Nk !
        Gọi φ(K, N) là số vectơ biểu diễn cho các dãy nguồn có chiều
         dài N.
        Con số này có thể diễn đạt thành một bài toán tập hợp tương
         đương khá quen thuộc là: Có bao nhiêu bộ gồm K số nguyên
         không âm mà có tổng bằng N.
   Bổ đề                                  ⎛ N + K − 1⎞
                            Φ ( K , N ) = ⎜⎜          ⎟⎟
                                           ⎝    N      ⎠
                                  Trang 136
          Các vectơ tần suất và tựa-entropy (tt)
   Chứng minh
        Xét một hàng gồm N + K – 1 khoảng trống. Dùng N đối tượng
         giống nhau lấp vào N khoảng trống bất kỳ. K – 1 khoảng trống
         còn lại sẽ chia N đối tượng này thành K nhóm. Do đó ứng với
         mỗi cách lấp N đối tượng vào N + K – 1 vị trí chúng ta có một
         tổng tương ứng. Vì vậy số lượng tổng này bằng
                                    ⎛ N + K − 1⎞
                                    ⎜⎜          ⎟⎟
                                     ⎝   N       ⎠
        Với mỗi dãy Si chúng ta có tương ứng một vectơ Qi = (q1i, ...,
         qKi). Chúng ta định nghĩa một biến ngẫu nhiên ψ(Q) gán mỗi
         dãy Si với giá trị (kí hiệu là ψ(Si) hoặc ψ(Qi))
                                K
                           −   ∑ qki log qki
                               k =1
                                      Trang 137
          Các vectơ tần suất và tựa-entropy (tt)
        Chú ý Qi là một vectơ xác suất và ψ(Qi) có công thức giống
         như của entropy nên chúng ta gọi ψ(Qi) là tựa–entropy.
        Dĩ nhiên ψ(Qi) có tất cả các tính chất của hàm entropy H(Qi)
         cái mà chỉ phụ thuộc duy nhất vào Qi.
        Chúng ta có định lý sau thiết lập mối quan hệ giữa ψ(Q) (hay
         viết rõ ra là ψ(q1, ..., qK)) với entropy của nguồn H(p1, ..., pK).
   Định lý 8.1
                             E(ψ(Q)) ≤ H(p1, ..., pK)
   Chứng minh
                            ⎛ K               ⎞ K
               E (ψ(Q)) = E ⎜ − ∑ q k log q k ⎟ = ∑ E (− q k log q k )
                            ⎝ k =1            ⎠ k =1

                                    Trang 138
    Các vectơ tần suất và tựa-entropy (tt)
   Mà để ý hàm –x log x là hàm lồi, vì vậy theo bất đẳng thức
    Jensen chúng ta có
                  E(–qk logqk) ≤ E(–qk) log E(qk)
    Theo một bổ đề trước đây chúng ta có E(qk) = pk. Vì vậy
                      K
         E (ψ(Q )) = ∑ − pk log pk = H ( p1 ,..., p K )
                     k =1




                            Trang 139
             Một sơ đồ mã hoá phổ quát cho
               nguồn rời rạc không nhớ
   Một từ mã cho một dãy Si gồm hai phần: phần đầu là chuỗi mã
    hoá cho vectơ tuần suất Qi tương ứng của dãy Si, phần thứ hai
    là chuỗi mã hoá cho dãy Si trong số các dãy có cùng vectơ Qi.
   Vì tổng các vectơ tần suất khác nhau là φ(K, N), nên số bit
    dùng để biểu diễn cho phần đầu là
                            ⎡log φ( K , N )⎤
   Tương tự số bit để biểu diễn cho phần thứ hai là
                             ⎡log ϖ (Qi )⎤
   Vì vậy từ mã biểu diễn cho dãy Si có chiều dài là

            l(Si) = ⎡log φ( K , N )⎤ + ⎡log ϖ (Qi ) ⎤
                  < log φ(K, N) + log ω(Qi) + 2.

                             Trang 140
               Một sơ đồ mã hoá phổ quát cho
                nguồn rời rạc không nhớ (tt)
      Chúng ta chứng minh được giá trị trung bình của l(Si) thoã
                                                K −1                       N
E (l ( S i )) < NH ( p1 ,..., p K ) + N log(1 +      ) + ( K − 1) log(1 +      )
                                                 N                        K −1
    Suy ra chiều dài trung bình trên một kí tự nguồn thoã

   E (l ( S i ))                        ⎡        K −1 K −1          N ⎤
l=               < H ( p1 ,..., p K ) + ⎢log(1 +     )+    log(1 +     )⎥
       N                                ⎣         N      N         K −1 ⎦
   Chú ý thành phần nằm trong dấu móc vuông tiến đến 0 khi N

    → ∞ với tốc độ bằng với tốc độ của log N
                                                        →0
                                                    N
   Điều này nói lên rằng phương pháp này tiếp cận đến entropy
    của nguồn chậm hơn so với các phương pháp mà biết trước
    xác suất. Điều này cũng dễ hiểu và cũng là cái giá phải trả nếu
    chúng ta không biết trước xác suất.
                                  Trang 141
                              Ví dụ
   Bảng sau đây mô tả việc mã hoá phổ quát cho một nguồn nhị
    phân cho từng khối có chiều dài 7.
   Có φ(2, 7) = 8 vectơ tần suất và vì vậy cần dùng 3 bit để mã
    hoá 8 vectơ này; 3 bit này sẽ là 3 bit đầu của mọi từ mã. Các
    bit còn lại dùng để nhận biết mỗi dãy trong lớp đã cho (là lớp
    các dãy có cùng vectơ tần suất).
         Qi      ω(Qi)         Si            ψ(Si)       wi
     (0/7,7/7)     1        1111111      0           000
                            0111111                  001 000
                            1011111                  001 001
     (1/7,6/7)      7                    0,592
                               ...
                            1111110                  001 110

                           Trang 142
                    Ví dụ (tt)
   Qi       ω(Qi)      Si         ψ(Si)        wi
                    0011111               010 00000
                    0101111               010 00001
(2/7,5/7)    21                  0,863
                       ...                ...
                    1111100               010 10100
                    0001111               011 000000
                    0010111               011 000001
(3/7,4/7)    35                  0,985
                       ...
                    1111000               011 100010
                    0000111               100 000000
                    0001011               100 000001
(4/7,3/7)    35                  0,985
                       ...
                    1110000               100 100010
                     Trang 143
                    Ví dụ (tt)
   Qi       ω(Qi)      Si            ψ(Si)        wi
                    0000011                  101 00000
                    0000101                  101 00001
(5/7,2/7)    21                  0,863
                       ...                   ...
                    1100000                  101 10100
                    0000001                  110 000
                    0000010                  110 001
(6/7,1/7)    7                   0,592
                       ...
                    1000000                  110 110
(7/7,0/7)    1      0000000      0           111



                     Trang 144
              Bài 9 Kênh rời rạc không nhớ
                   Lượng tin tương hỗ
9.1 Kênh rời rạc không nhớ và ma trận kênh
9.2 Entropy điều kiện và lượng tin tương hỗ
9.3 Một số loại kênh
9.4 Sự nhập nhằng (equivocation) và tốc độ truyền tin
9.5 Dung lượng kênh




                          Trang 145
           Kênh rời rạc không nhớ và ma trận kênh
   Định nghĩa
      Một kênh rời rạc không nhớ (DMC) được định nghĩa bằng một
       bảng kí hiệu đầu vào (nguồn phát) X = {x1, ..., xK}, một bảng kí
       hiệu đầu ra (nguồn nhận) Y = {y1, ..., yJ}, và một sự phân bố xác
       suất có điều kiện p(yj | xk), với 1 ≤ k ≤ K, 1 ≤ j ≤ J.

                           X        p(yj | xk)   Y
                           xk                    yj

        Bảng kí hiệu đầu ra không nhất thiết giống bảng kí hiệu đầu
         vào. Điều này có nghĩa là bên nhận có thể nhận những kí hiệu
         mà không giống với những kí hiệu mà bên phát phát đi.


                                 Trang 146
                           Nhận xét
   Thuật ngữ không nhớ (memoryless) suy ra rằng
                                               N
     p{ y j1 K y jN | x k1 L x kN } =         ∏ p( y jn | xkn )
    với N bất kỳ.                          n =1
   Một kênh rời rạc không nhớ thường được biểu diễn dưới dạng
    một ma trận kênh [p(yj | xk)] có kích thước K × J.

                   y1         y2                 yJ
             x1 p(y1 | x1) p(y2 | x1)   ...   p(yJ | x1)
             x2 p(y1 | x2) p(y2 | x2)   ...   p(yJ | x2)
             ...   ...        ...       ...      ...
             xK p(y1 | xK) p(y2 | xK)   ...   p(yJ | xK)
                            Trang 147
                         Nhận xét (tt)
   Chúng ta thấy, ma trận kênh chính là cái mà biểu diễn tính chất
    tạp nhiễu của kênh truyền.
   Chú ý, nếu chúng ta biết sự phân bố xác suất trên X thì sự phân
    bố xác suất của Y sẽ được xác định như sau
                                K
                  p( y j ) =   ∑ p( xk ) p( y j | xk )
                               k =1




                               Trang 148
         Entropy điều kiện và lượng tin tương hỗ
        Xét bài toán truyền tin sau
         Cho biết cấu trúc thống kê của nguồn X và ma trận kênh. Hãy
         xác định kí hiệu xk nào đã được phát phát đi khi nhận được ở
         đầu nhận một kí hiệu yj nào đó?
   Ví dụ
        Cho nguồn X = {x1, x2} với các xác suất lần lượt là p(x1) = 1/4,
         p(x2) = 3/4, nguồn Y = {y1, y2} và ma trận kênh là
                                   y1 y2
                                x1 4/5 1/5
                                x2 2/5 3/5
        Nếu nhận được y1 thì xk nào có khả năng đã được phát đi?
                                  Trang 149
                                              Ví dụ
                  p( xk , y j )       p( xk ) × p( y j | xk )        p( xk ) × p( y j | xk )
p( xk | y j ) =                   =                             =
                    p( y j )              K                         K
                                         ∑ p ( xi , y j )           ∑ p ( xi ) × p ( y j | xi )
                                         i =1                       i =1

                             p ( x1 ) p ( y1 | x1 )                                         3
p ( x1 | y1 ) =                                                            p ( x 2 | y1 ) =
                p ( x1 ) p( y1 | x1 ) + p ( x 2 ) p ( y1 | x 2 )                            5
                          (1 / 4) × (4 / 5)           2
             =                                      =
               (1 / 4) × (4 / 5) + (3 / 4) × (2 / 5) 5

      p(x1 | y1) < p(x2 | y1), như vậy chúng ta có thể khẳng định được
       kí hiệu x2 có khả năng được phát đi hơn x1?

                                          Trang 150
                             Ví dụ (tt)
   Để ý, trong công thức của p(xi | yj) có chứa thừa số p(xi), nên
    p(xi | yj) đã bị ảnh hưởng bởi xác suất lề p(xi).
   Vì vậy để công bằng trong việc so sánh chúng ta phải dựa trên
    tỉ số p(xi | yj)/p(xi) cái mà không bị ảnh hưởng nhiều bởi p(xi).
                           p ( x1 | y1 ) 2 / 5 8
                                        =     =
                              p ( x1 )    1/ 4 5
                       p ( x 2 | y1 ) 3 / 5 4
                                     =     =
                          p( x2 )      3/ 4 5
   Như vậy thực sự kí hiệu x1 mới có khả năng được phát đi hơn kí
    hiệu x2.
   Từ xác suất điều kiện chúng ta giới thiệu khái niệm lượng tin có
    điều kiện.
                              Trang 151
                Lượng tin có điều kiện I(xk | yj)
   Định nghĩa
                               I(yj | xk) = –log p(yj | xk)
                               I(xk | yj) = –log p(xk | yj)
        p(yj | xk) → 1 thì I(yj | xk) → 0 và ngược lại.
        Nếu khi phát đi xk và biết chắc yj sẽ nhận được thì ở phía nhận
         chúng ta không cần tốn thêm thông tin gì để giải thích.
        Nếu p(yj | xk) = 1/2 (I(yj | xk) = 1 bit) thì khi phát đi xk bên nhận
         sẽ có hai khả năng và yj chỉ là một trong hai khả năng đó, có
         nghĩa là bên nhận cần thêm thông tin (cần thêm 1 bit) để biết
         chính xác đó là khả năng nào.
        Xác suất p(yj | xk) = 1/2 chỉ xảy ra khi kênh truyền có nhiễu.

                                    Trang 152
          Lượng tin có điều kiện I(xk | yj)
   Vì vậy lượng tin có điều kiện còn được gọi là lượng tin bị mất
    đi do nhiễu.
   Khi phát đi xk bên nhận sẽ có một tập các yj có khả năng được
    nhận.
   Ngược lại khi nhận được yj bên phát sẽ có một tập các xk có khả
    năng được phát.
   Để đo mức độ “quan hệ” giữa xk với yj chúng ta giới thiệu khái
    niệm lượng tin tương hỗ.




                            Trang 153
                         Lượng tin tương hỗ
   Định nghĩa
        Lượng tin tương hỗ giữa hai tin là lượng tin của của tin này
         được chứa trong tin kia và ngược lại. Bằng công thức
         Lượng tin tương hỗ = Lượng tin riêng – Lượng tin bị mất đi
         I(xk, yj) = I(xk) – I(xk | yj) = I(yj) – I(xk | yj)
                          p( x k |y j )       p( y j|x k )
                   = log                = log
                            p( x k )            p( y j )
        Nếu p(xk | yj) = 1 có nghĩa là nếu yj đã nhận được thì chắc chắn
         xk đã được phát đi, điều này có nghĩa là lượng tin của xk đã
         được truyền nguyên vẹn thông qua kênh, do đó I(xk, yj) = I(xk).


                                  Trang 154
          Lượng tin có điều kiện trung bình
                K                                 K
I(X | y j ) =   ∑ p(xk | y j )I (xk | y j ) = − ∑ p(xk | y j ) log p(xk | y j )
                k =1                              k =1
                 J                                    J
I (Y | xk ) =   ∑ p( y j | xk )I ( y j | xk ) = − ∑ p( y j | xk ) log p( y j | xk )
                j =1                                j =1
                J                           J              K
I(X | Y) =      ∑ p( y j )I ( X | y j ) = − ∑ p( y j ) ∑ p(xk | y j ) log p(xk | y j )
                j =1                       j =1            k =1
                   K   J
           = − ∑ ∑ p( xk , y j ) log p( xk | y j )
                 k = 1 j =1
                  K J
 I (Y | X ) = − ∑ ∑ p( xk , y j ) log p( y j | xk )
                 k =1 j =1
                                      Trang 155
                           Entropy điều kiện
   Định nghĩa
        Xét hai biến ngẫu nhiên x và y với phân bố xác suất đồng thời
         p(xk, yj), k = 1, ..., K , j = 1, ..., J. Entropy điều kiện của x đã
         cho y được định nghĩa là
                                 K   J
                  H (x | y ) = − ∑ ∑ p( xk , y j ) log p( xk | y j )
                                k =1 j =1
        H(x | y) có thể được diễn dịch như là độ bất ngờ trung bình về x
         sau khi đã biết y.
   Định lý 9.1
        H(x | y) ≤ H(x), dấu “=” xảy ra ⇔ x và y là độc lập.


                                     Trang 156
                                 Chứng minh
                      K J                                K
H (x | y) − H (x) = − ∑∑ p(xk , y j ) ln p(xk | y j ) + ∑ p(xk ) ln p(xk )
                     k =1 j =1                           k =1
                      K J
                                          p(xk )
                 = − ∑∑ p(xk , y j ) ln
                    k =1 j =1
                                        p(xk | y j )
    Lấy tổng trên những cặp (k, j) mà p(xk, yj) ≠ 0. Vì vậy
                                         ⎡ p( xk )          ⎤
     H (x | y) − H (x) = ∑∑ p( xk , y j )⎢               − 1⎥
                         k j             ⎢⎣ p( xk | y j ) ⎥⎦
                    =   ∑ ∑ p( xk ) p( y j ) − p( xk , y j )
                         k       j
                                     [
                     = ∑∑ p( xk ) p( y j ) − 1 ≤ 0   ]
                         k   j
                                         Trang 157
                            Chứng minh (tt)
        Dấu “=” xảy ra ⇔ p(xk) = p(xk | yj) đối với tất cả các cặp (k, j)
         mà p(xk, yj) ≠ 0 đồng thời tổng p(xk)p(yj) trên tất cả những cặp
         này bằng 1.
        Điều kiện thứ hai tương đương với điều kiện p(xk)p(yj) = 0 bất
         kỳ khi nào mà p(xk, yj) = 0.
        Cả hai điều kiện này cuối cùng tương đương với điều kiện là x
         và y độc lập.
   Định lý 9.2
        H(x, y) = H(x) + H(y | x) = H(y) + H(x | y)




                                  Trang 158
                           Chứng minh
H (x, y) = − ∑∑ p( xk , y j ) log p( xk , y j )
              k   j
                               [
         = − ∑∑ p( xk , y j ) log p( xk ) + log p( y j | xk )   ]
              k   j
         = − ∑ p( xk )[log p( xk )] − ∑∑ p( y j , y k ) log p( y j | xk )
              k                            k   j
         = H (x) + H (y | x)
   Phần thứ hai chứng minh hoàn toàn tương tự.
   Kết hợp hai định lý trên chúng ta suy ra rằng
                         H(x, y) ≤ H(x) + H(y)
   dấu “=” xảy ra ⇔ x, y là độc lập.

                               Trang 159
          Lượng tin tương hỗ trung bình
           I ( X , Y ) = ∑∑ p( xk , y j ) I ( xk , y j )
                        k    j                p( xk | y j )
                     = ∑∑ p ( x k , y j ) log
                       k j
                                                p( xk )
                                             p( y j | xk )
                     = ∑∑ p ( xk , y j ) log
                       k j
                                               p( y j )
                                              p( xk , y j )
                     = ∑∑ p ( xk , y j ) log
                       k j
                                             p( xk ) p( y j )

   Nếu biểu diễn theo entropy thì chúng ta có
              I(x, y) = H(x) – H(x | y) = H(y) – H(y | x)



                                 Trang 160
            Một số loại kênh rời rạc không nhớ
   Kênh đối xứng (Symmetric channel)
        Là kênh mà mỗi dòng của ma trận kênh chứa cùng tập các số
         p1’, ..., pJ’ và mỗi cột chứa cùng tập các số q1’, ..., qK’.
   Ví dụ                                         j=1    2    3     4
                                                  0,2   0,2   0,3   0,3 k = 1
                                 [p(yj | xk)] =
                                                  0,3   0,3   0,2   0,2 k = 2

     Các ma trận biểu                             0,2   0,3   0,5
     diễn                        [p(yj | xk)] =   0,3   0,5   0,2
     các kênh đối xứng                            0,5   0,2   0,3
     Kênh đối xứng nhị                            1–ε    ε
     phân (binary                [p(yj | xk)] =               0≤ε≤1
                                                   ε    1–ε
     symmetric channel –
     BSC).                       Trang 161
                                       Nhận xét
        Kênh đối xứng thì H(y | x) độc lập với sự phân bố xác suất của
         nguồn phát và được xác định duy nhất bằng ma trận kênh.
   Chứng minh
                            K     J
            H (y | x ) = − ∑ ∑ p ( x k , y j ) log p ( y j | x k )
                           k =1 j =1
                            K           J
                      = − ∑ p ( x k ) ∑ p ( y j | x k ) log p ( y j | x k )
                           k =1        j =1
                            K           J
                      = − ∑ p ( x k ) ∑ p 'j log p 'j
                           k =1        j =1
                             J
                      = − ∑ p 'j log p 'j
                           j =1
                                       Trang 162
            Kênh không mất (Lossless channel)
        Cạnh nối giữa xk và yj nghĩa là p(yj | xk) ≠ 0. Trong kênh không
         mất đầu ra xác định duy nhất đầu vào, vì vậy H(x | y) = 0.
                x1                  x1                         xK


           y1 y2       ym    ym+1                                  yJ
   Kênh đơn định (Deterministic channel)
           x1 x2       xm    xm+1                                 xK


                 y1               y2                     yJ
        Trong kênh này đầu vào xác định duy nhất đầu ra, vì vậy
         H(y | x) = 0
                                    Trang 163
               Kênh vô dụng (Useless channel)
        Một kênh là vô dụng nếu và chỉ nếu x và y là độc lập với mọi
         sự phân bố xác suất của đầu vào (nguồn phát).
        Đối với một kênh vô dụng thì H(x | y) = H(x), tức là kiến thức
         về đầu ra không làm giảm độ bất ngờ về đầu vào. Vì vậy, đối
         với mục đích xác định đơn định đầu vào, chúng ta có thể phớt
         lờ đầu ra hoàn toàn. Bây giờ chúng ta sẽ chứng minh rằng.
        Một kênh rời rạc không nhớ là vô dụng nếu và chỉ nếu ma trận
         kênh của nó có các dòng giống nhau.
   Chứng minh
        Điều kiện đủ
         Giả sử ma trận có các dòng giống nhau p1’, ..., pJ’. Thì đối với
         mọi đầu ra yj


                                  Trang 164
                          Kênh vô dụng (tt)
              K                   K                                 K
p( y j ) =   ∑ p( xk , y j ) =   ∑ k
                                  p ( x ) p ( y j | x k ) = p '
                                                               j   ∑ k
                                                                    p ( x ) = p '
                                                                                 j
             k =1                k =1                              k =1

    Đối với mọi cặp đầu vào– ra (xk, yj), chúng ta có
             p(xk, yj) = p(xk) p(yj | xk) = p(xk) pj’ = p(xk) p(yj)
    Vì vậy đầu vào và đầu ra độc lập nhau bất chấp sự phân bố xác
    suất của đầu vào.
   Điều kiện cần
    Giả sử các dòng của ma trận không giống nhau ⇒ ∃ một cột
    chẳng hạn j0 mà có các phần tử không giống nhau.
    Giả sử p(yj0 | xk0) là phần tử lớn nhất trong cột này. Xét sự phân
    bố đồng nhất (đẳng xác suất) ở đầu vào (đầu phát), chúng ta có

                                      Trang 165
                          Kênh vô dụng (tt)
             K
                                         1 K
p( y j 0 ) = ∑ p( xk ) p( y j 0 | xk ) =   ∑    p( y j 0 | xk ) < p( y j 0 | xk 0 )
             k =1
                                         K k =1

    Tức là p(yj0) ≠ p(yj0 | xk0). Vì vậy p(xk0, yj0) = p(xk0) p(yj0 | xk0) ≠
     p(xk0) p(yj0). Mâu thuẫn với giả thiết là x, y độc lập với mọi sự
     phân bố xác suất của đầu vào.




                                   Trang 166
              Sự nhập nhằng (equivocation)
                   và tốc độ truyền tin
   Xét một kênh nhị phân đối xứng với xác suất chéo ε. Giả sử
    rằng tại đầu vào P(0) = P(1) = 1/2, tốc độ sinh thông tin ở đầu
    phát là H(x) = 1 bit/kí hiệu.
   Một thiết bị được gọi là bộ quan sát, nhận mỗi cặp kí hiệu
    vào/ra (x, y) và sinh ra một kí hiệu z
   z = 0 nếu x = y, z = 1 nếu x ≠ y

                                         …z(2)z(1)
                         Bộ quan sát


                             Kênh
         …x(2)x(1)                       …y(2)y(1)


                             Trang 167
              Sự nhập nhằng (equivocation)
                 và tốc độ truyền tin (tt)
   Sự phân bố của z được tìm thấy như sau:
    P(z = 1) = P(x = 0) P(y = 1 | x = 0) + P(x = 1) P(y = 0 | x = 1)
              = ε/2 + ε/2 = ε
    P(z = 0) = 1 – P(z = 0) = 1 – ε
   Tốc độ sinh thông tin bởi bộ quan sát vì vậy bằng
             H(z) = –ε log ε – (1 – ε) log(1 – ε) bits/kí hiệu
   Đối với một dãy đầu ra đã cho y(1)y(2)..., nơi nhận (receiver) có
    thể xây dựng lại chính xác dãy đầu vào x(1)x(2)... chỉ khi đầu ra
    của bộ quan sát z(1)z(2)... đã được tạo sẵn.
   Tốc độ truyền thông tin trên kênh, thường kí hiệu là R, là bằng
    tốc độ sinh thông tin H(x) trừ tốc độ sinh thông tin bổ sung
    H(z).
                               R = H(x) – H(z)
                             Trang 168
                                Ví dụ
   Chẳng hạn, nếu dữ liệu đầu vào được sinh ở tốc độ 1000 kí
    hiệu/giây và ε = 0,01, chúng ta có
    H(x) = 1         → tốc độ dữ liệu đầu vào = 1000 bits/giây
    H(z) = 0,081 → tốc độ dữ liệu bổ sung = 81 bits/giây
    R     = 0,919 → tốc độ truyền thông tin = 919 bits/giây
   Một người có thể lý luận rằng trong một dãy dài, vì ε = 0,01,
    nghĩa là chỉ 1% số bit được truyền bị lỗi, và vì vậy tốc độ
    truyền thông tin phải là 990 bits/giây.
   Câu trả lời là rằng kiến thức về số bit bị lỗi không đủ để xây
    dựng lại dữ liệu, mà chúng ta cần phải biết thêm về vị trí lỗi
    nữa, và vì lý do này nên tốc độ truyền thông tin là thực sự bằng
    một giá trị thấp hơn là 919 bits/giây.


                             Trang 169
                            Nhận xét
   Trong trường hợp tốt nhất ε = 0, chúng ta có H(z) = 0 và vì vậy
    R = 1000 bits/giây.
   Trong một trường hợp khác nếu ε = 1/2, thì H(z) = 1, kết quả là
    R = 0 bits/giây.
   Cả hai kết luận là nhất quán với sự mong đợi của chúng ta.
   Đối với kênh nhị phân đối xứng với đầu vào đẳng xác suất,
    chúng ta chứng minh được rằng H(z) = H(x | y).
   Tổng quát chúng ta chứng minh được rằng
   Sự tái xây dựng chính xác dãy đầu vào từ dãy đầu ra là có thể
    nếu bộ quan sát có thể sinh ra thông tin bổ sung ở tốc độ lớn
    hơn hay bằng H(x | y).



                            Trang 170
                         Nhận xét (tt)
   Để thấy điều này một cách trực quan, quan sát rằng đối với các
    dãy dài có chiều dài N có khoảng 2NH(x | y) dãy đầu vào có thể
    sinh ra một dãy đầu ra cụ thể.
   Chỉ khi thông tin bổ sung được sinh ra tại tốc độ H(x | y) hay
    nhanh hơn mới cho phép phân biệt giữa các khả năng này.
   Đối với lý do này, H(x | y) thường được coi như là sự nhập
    nhằng (equivocation) của kênh. Và chúng ta định nghĩa lại tốc
    độ truyền thông tin trên kênh là
                      R = H(x) – H(x | y) = I(x, y)




                            Trang 171
                     Dung lượng kênh
   Theo phần trên tốc độ truyền tin trên kênh được định nghĩa là
                        R = H(x) – H(x | y) = I(x, y)
   I(x, y) tổng quát là một hàm của sự phân bố xác suất đầu vào
    {p1, …, pK}. Vì vậy, có thể tìm thấy một sự phân bố mà cực đại
    I(x, y). Giá trị cực đại của I(x, y) được định nghĩa là dung
    lượng kênh C và là một hàm của ma trận kênh.
    C = Cực đại (trên các sự phân bố xác suất đầu vào) của I(x, y).
   Tổng quát, việc tính dung lượng kênh là một bài toán khó và là
    một bài toán chưa được giải một cách triệt để.
   Tuy nhiên đối với các kênh đã được giới thiệu ở trên C có thể
    tính toán được như phần sau đây trình bày.



                            Trang 172
                            Kênh đối xứng
                                      J
                       C = log J +   ∑ j
                                      p '
                                          log p '
                                                 j
                                     j =1
         trong đó p1’, …, pJ’ là các phần tử của các hàng của ma trận.
        Trong trường hợp kênh nhị phân đối xứng với xác suất chéo là
         p chúng ta có
                 C = 1 – H(p) với H(p) = –plogp – (1–p)log(1–p)
   Kênh không mất
        H(x | y) = 0, vì vậy
                 C = Max {H(x) – H(x | y)} = Max{H(x)} = log K
         trong đó K là kích thước của bảng kí hiệu đầu vào. Dung lượng
         đạt được trong trường hợp đầu vào có sự phân bố đẳng xác
         suất.

                                 Trang 173
                           Kênh đơn định
        Ở đây H(y | x) = 0, vì vậy
                C = Max {H(y) – H(y | x)} = Max{H(y)} = log J
         trong đó J là kích thước của bảng kí hiệu đầu ra.
   Kênh vô dụng
        Ở đây H(x | y) = H(x), vì vậy
              C = Max {H(x) – H(x | y)} = Max{H(x) – H(x)} = 0
        Một kênh vô dụng thì có dung lượng kênh bằng 0.




                                Trang 174
               Bài 10 Mã hóa chống nhiễu,
                      định lý kênh
  1‎ 0.1 Giới thiệu bài toán chống nhiễu
 ‎10.2 Định lý kênh có nhiễu cho kênh nhị phân đối xứng rời
         rạc (BSC)
‎10.3 Định lý ngược của kênh truyền có nhiễu




                           Trang 175
          Giới thiệu bài toán chống nhiễu
   Mục tiêu chống nhiễu là bên nhận có thể đoán (giải mã) được
    càng chính xác càng tốt dãy kí hiệu đã được phát.
   Chẳng hạn xét nguồn nhị phân đối xứng với xác suất chéo ε,
    đồng thời giả sử nguồn phát đẳng xác suất, tức P(0) = P(1) =
    1/2.
   Với ε < 1/2, xét cơ chế giải mã ở bên nhận như sau: Nếu y = 0
    thì đoán x = 0 và nếu y = 1 thì đoán x = 1.
   Xác suất giải mã bị lỗi của cơ chế này là
     P(lỗi) = P(y = 0) P(x = 1 | y = 0) + P(y = 1) P(x = 0 | y = 1) =
                              ε/2 + ε/2 = ε.
   Chú ý trong trường hợp ở đây chúng ta tính được
               P(y = 0) = P(y = 1) = 1/2 và P(x ≠ y | y) = ε.
   Vấn đề quan trọng là có thể giảm được xác suất giải mã bị lỗi
    hay không?

                             Trang 176
       Giới thiệu bài toán chống nhiễu (tt)
   Một hướng giải quyết như sau: để gởi 0 chúng ta gởi chuỗi 3 kí
    hiệu 0 và tương tự để gởi 1 chúng ta gởi 3 kí hiệu 1.
   Cơ chế giải mã của bên nhận như sau: Nếu chuỗi nhận có nhiều
    kí hiệu 0 hơn 1 thì giải mã thành 0 và ngược lại.
   Chẳng hạn bên nhận nếu nhận được 010 thì giải mã thành 0 còn
    nếu nhận được 110 thì giải mã thành 1.
   Cơ chế này có xác suất giải mã bị lỗi là
                        P(lỗi) = 3(1 – ε)ε2 + ε3 < ε
   Xác suất này nhỏ hơn ε. Tuy nhiên hiệu suất truyền thông tin bị
    giảm xuống 3 lần.
   Tương tự nếu muốn xác suất giải mã tiến đến 0 chúng ta sẽ mã
    hoá 0 thành dãy 2n + 1 kí hiệu 0 và mã hoá 1 thành 2n + 1 kí
    hiệu 1, nhưng tương ứng lúc này hiệu suất truyền thông tin
    giảm xuống 2n + 1 lần so với ban đầu.

                            Trang 177
       Giới thiệu bài toán chống nhiễu (tt)
   Có một cách có thể giảm xác suất giải mã lỗi xuống gần bằng 0
    nhưng không giảm hiệu suất truyền thông tin xuống gần bằng 0
    mà chỉ cần nhỏ hơn một ngưỡng nào đó là đủ.
   Ngưỡng đó chính là dung lượng kênh.
   Cách này cũng khai thác ý tưởng trên ở chỗ thay vì để gởi đi 0
    và 1, cái mà có “khoảng cách Hamming” giữa chúng là 1 thì
    chúng ta sẽ mã hoá lần lượt thành 000 và 111, cái mà có
    “khoảng cách Hamming” giữa chúng là 3 và vì vậy giảm xác
    suất giải mã bị lỗi.




                            Trang 178
                  Định lý kênh có nhiễu cho kênh
                  nhị phân đối xứng rời rạc (BSC)
        Xét kênh nhị phân đối xứng với xác suất chéo p.
        Dung lượng kênh trong đơn vị bits/kí hiệu là
                 C = 1 – H(p) với H(p) = –plogp – (1–p)log(1–p)
        Giả sử thời gian truyền 1 kí hiệu là T, số kí hiệu được truyền
         trong 1 giây là 1/T, thì dung lượng theo đơn vị bits/giây là
                                   C = [1 – H(p)]/T
        Xét nguồn X có entropy H(X) bits/ký hiệu, tức là nguồn này tạo
         ra thông tin ở tốc độ theo đơn vị bits/giây.
                                     R = H(X)/T
   Định lý 10.1.
        Chừng nào mà R (bits/giây) còn nhỏ hơn C (bits/giây), thì việc
         truyền trên kênh với tỉ lệ lỗi nhỏ tuỳ ý là có thể thực hiện được.
        Để chứng minh định lý này cần một số khái niệm sau.

                                   Trang 179
                               Các khái niệm
   Trọng số Hamming
        Trọng số Hamming của một dãy kí hiệu v = a1a2...an , trong đó
         mỗi ai ∈ {0, 1, ..., m–1}, là số kí hiệu khác 0 của dãy, và
         thường được kí hiệu là w(v).
   Khoảng cách Hamming
        Khoảng cách Hamming của hai dãy kí hiệu v1, v2 với chiều dài
         bằng nhau là số vị trí khác nhau của hai dãy, và thường được kí
         hiệu là d(v1, v2).
   Phép cộng cơ số m, ⊕
        Xét a, b ∈ {0, 1, ..., m–1} thì a ⊕ b = (a + b) mod m.
        Nếu v1 = a1a2...an, v2 = b1b2...bn thì v1 ⊕ v2 = c1c2...cn trong đó ci
         = ai ⊕ bi với i = 1, 2, ..., n.


                                    Trang 180
                         Các khái niệm (tt)
   Ví dụ
      w(10100) = 2, w(01120) = 3.
        d(10100, 10001) = 2, d(011010, 101101) = 5.
        Với m = 2 thì 1011 ⊕ 1101 = 0110. Với m = 3 thì 1021 ⊕ 2120
         = 0111.
   Bổ đề
                             d(v1, v2) = w(v1 ⊕ v2 )
                         d(v1, v2) + d(v2, v3) ≥ d(v1, v3)
   Nhận xét
        Bất đẳng thức thứ hai có dạng của bất đẳng thức tam giác: tổng
         hai cạnh của một tam giác lớn hơn hoặc bằng cạnh còn lại.
        Định lý 10.1 đúng cho kênh rời rạc không nhớ bất kỳ. Tuy
         nhiên ở đây chúng ta chỉ chứng minh cho kênh nhị phân đối
         xứng rời rạc.
                                 Trang 181
                   Chứng minh định lý
   Ý tưởng chứng minh là mã hoá các dãy dữ liệu thành các từ mã,
    trong đó các kí hiệu mã lấy từ bảng kí hiệu đầu vào của kênh và
    xử lý các từ mã này như các đầu vào cơ bản của kênh.
   Xác suất lỗi nhỏ tuỳ ý có thể đạt được dựa trên sự mã hoá như
    sau:
    (1) chọn chiều dài N của dãy dữ liệu đủ dài
    (2) mã hoá các dãy này thành các từ mã có khoảng cách
        Hamming xa nhau.
   Nguyên tắc giải mã ở đầu ra được thiết kế như sau: dãy kí hiệu
    nhận được ở đầu ra vj sẽ được giải mã thành từ mã wi mà có
    khoảng cách Hamming nhỏ nhất đối với vj.
   Với cách chọn này xác suất giải mã lỗi là nhỏ nhất. Thật vậy
                      p(wi | vj) = p(wi)p(vj | wi)/p(vj)


                            Trang 182
                Chứng minh định lý (tt)
   ‎Do đó khi chúng ta không rõ về p(wi) và dĩ nhiên sẽ kéo theo
     p(vj) thì p(wi | vj) lớn nhất khi p(vj | wi) là lớn nhất. Mà
                              p(vj | wi) = pD(1–p)N–D
     trong đó D là khoảng cách Hamming giữa vj và wi, N là chiều dài
     của chúng, p là xác suất chéo.
    Nếu xác suất chéo p < 0,5 thì p(vj | wi) sẽ lớn nhất khi D là nhỏ
     nhất.
    Chứng minh rằng ∀ θ > 0 nhỏ tuỳ ý, với N đủ lớn tồn tại cách
     mã hoá các dãy dữ liệu thành các từ mã sao cho với nguyên tắc
    giải mã trên có xác suất giải mã lỗi là nhỏ hơn θ.
    Thật vậy số dãy dữ liệu có chiều dài N là vào khoảng
                                M = 2NH(X) = 2NRT
     trong khi đó tổng số dãy có chiều dài N là 2N.


                             Trang 183
                 Chứng minh định lý (tt)
   ‎ ọi {w1, w2, …, wM} là một tập từ mã bất kỳ, Pe là xác suất giải
     G
    mã lỗi đối với tập này.
    Nếu chúng ta chứng minh được rằng ∀ θ > 0 nhỏ tuỳ ý, với N
    đủ lớn giá trị trung bình của Pe, Pe , nhỏ hơn θ thì sẽ tồn tại một
    tập từ mã mà có xác suất giải mã lỗi Pe nhỏ hơn θ.
    Với xác suất lỗi trên đường truyền là p, một dãy có chiều dài N
    sẽ có trung bình Np vị trí lỗi.
    Với hai số dương ε, δ nhỏ tuỳ ý, theo luật yếu của số lớn với N
     đủ lớn thì xác suất để số vị trí của chuỗi nhận vj khác với chuỗi
     phát wi lớn hơn N(p + ε) là nhỏ hơn δ. Hay nói theo ngữ cảnh
    của khoảng cách Hamming là
                         P[d(wi, vj) > N(p + ε)] < δ
    Vì vậy bộ mã mà chúng ta mong muốn sẽ như sau: Khoảng
     cách Hamming giữa hai từ mã bất kỳ là ≥ 2N(p + ε) + 1

                              Trang 184
                Chứng minh định lý (tt)
   Như vậy với mỗi vj nhận được theo bất đẳng thức tam giác tồn
    tại một từ mã wi mà có
                           d(wi, vj) ≤ N(p + ε)
    còn các từ mã wk khác có
                        d(wk, vj) ≥ N(p + ε) + 1
   Vì vậy chúng ta sẽ giải mã được duy nhất vj thành wi.
   Với ý tưởng này, chúng ta sẽ đưa ra cơ chế giải mã lỏng hơn
    cho một tập từ mã bất kỳ {w1, w2, …, wM}, nhưng cũng sẽ đảm
    bảo xác suất giải mã lỗi là nhỏ hơn θ.
   Với mỗi dãy vj nhận được, định nghĩa một tập kiểm tra Aj bao
    gồm tất cả những dãy có chiều dài N và có khoảng cách
    Hamming so với vj nhỏ hơn hay bằng N(p + ε).
   Nếu từ mã được truyền wi là từ mã duy nhất thuộc tập Aj thì giải
    mã vj thành wi. Ngược lại thông báo một lỗi đã xảy ra.

                            Trang 185
                Chứng minh định lý (tt)
   Một lỗi xảy ra thuộc vào một trong hai trường hợp sau đây
    (1) Từ mã được truyền wi không thuộc Aj, tức là
                           d(wi, vj) > N(p + ε)
        Lỗi này xảy ra với xác suất nhỏ hơn δ.
    (2) Tồn tại một từ mã wk khác cũng thuộc Aj. Lúc này chúng ta
        không biết nên giải mã vj thành wi hay wk.
   Chúng ta chứng minh rằng theo cách này xác suất giải mã lỗi
    trung bình sẽ nhỏ hơn θ với θ nhỏ tuỳ ý cho trước.
   Chúng ta có
                                  M
                      Pe ≤ δ +    ∑ P(wi ∈ A j )
                                 i =1
                                 i≠ j


                            Trang 186
                Chứng minh định lý (tt)
   Để tính Pe chúng ta sẽ tính giá trị trung bình của P(wi ∈ Aj).
   Giá trị trung bình này sẽ bằng số dãy thuộc tập Aj chia cho tổng
    số dãy
                                  N ( p + ε)
                                           ⎛N⎞
                                      ∑ ⎜⎜ k ⎟⎟
                                     k =0 ⎝ ⎠
                P (Wi ∈ A j ) =
   Suy ra                              2N
                                  N ( p + ε)
                                     ⎛N⎞
                                ∑ ⎜⎜ k ⎟⎟
                               k =0 ⎝ ⎠
             Pe < δ + ( M − 1)
                                  2N

                             Trang 187
                Chứng minh định lý (tt)
   Mà chúng ta có một bất đẳng thức nổi tiếng sau
                   Nα N
                       ⎛ ⎞        NH (α )
                    ∑⎜k⎟≤2
                       ⎜ ⎟
                       k =0⎝ ⎠
    với H(α) = –α logα – (1–α)log(1–α).
   Áp dụng vào bất đẳng thức trên chúng ta có
     Pe ≤ δ + M×2–N [1 – H(p + ε)] = δ + 2NRT 2–N [1 – H(p + ε)]
        = δ + 2–N [1 – H(p + ε) – RT]
   Vì ε và δ có thể nhỏ tuỳ ý, nên chừng nào R < [1 – H(p)]/T = C
    (bits/giây) thì có thể làm cho Penhỏ tuỳ ý bằng cách tăng N.
   Chứng minh được hoàn tất.



                            Trang 188
                                    Ví dụ
        Xét ví dụ trước đây, một kênh đối xứng nhị phân có xác suất
         chéo ε = 0,01. Tốc độ truyền kí hiệu f = 1000 kí hiệu/giây (tức
         T = 0,001 giây). Chúng ta có C = 0,919 bits/kí hiệu hay C = 919
         bits/giây.
        Định lý kênh cho phép chúng ta kết luận, với xác suất đúng tiến
         tới 1, rằng với N khá lớn chẳng hạn N = 1000, thì trong 21000
         dãy có chiều dài 1000 chúng ta có thể chọn được 2K dãy với K
         < 919 sao cho khoảng cách Hamming giữa các dãy là ≥ 2Nε + 1
         = 21.
   Khoảng cách Hamming của bộ mã
        Khoảng cách Hamming của một bộ mã A, với điều kiện A là mã
         đều, kí hiệu là d(A), là khoảng cách Hamming nhỏ nhất trong
         tất cả các khoảng cách giữa hai từ mã bất kỳ của A.

                                 Trang 189
                                   Định lý
   Định lý 10.2
        Một bộ mã nhị phân có khoảng cách Hamming d thì có thể
           Phát hiện sai được t bit nếu d ≥ t + 1.

           Sửa sai được t bit nếu d ≥ 2t + 1.

   Chứng minh
        Gọi wi là từ mã phát, vi là dãy nhận tương ứng. Nếu sai tối đa t
         > 0 bit thì d(wi, vi) ≤ t. Do đó tổ hợp nhận sẽ không thể trùng
         với bất kỳ từ mã nào vì khoảng cách Hamming giữa hai từ mã
         bất kỳ là ≥ t + 1. Vì vậy bên nhận có thể phát hiện được sai.
        Tương tự nếu d(wi, wj) ≥ 2t + 1, theo bất đẳng thức tam giác ⇒
         d(wj, vi) ≥ t + 1 ∀ từ mã wj ≠ wi. Vì vậy bên nhận có thể giải mã
         đúng vi thành wi dựa trên sự khác biệt này.

                                  Trang 190
         Định lý ngược của kênh truyền có nhiễu
   Định lý 10.2
        Nếu tốc độ truyền tin R (bits/giây) lớn hơn dung lượng kênh C
         (bits/giây), thì sự truyền thông trên kênh với tỉ lệ lỗi nhỏ tuỳ ý
         là không thể thực hiện được. Hay nói cách khác xác suất giải
         mã lỗi tiến đến 1 khi chiều dài của dãy cần truyền gia tăng.
        Định lý này nói cách khác nếu tốc độ truyền tin lớn hơn dung
         lượng kênh thì việc truyền không được đảm bảo có nghĩa là
         chúng ta không thể giải mã đúng được.




                                   Trang 191
     Bài 11 Cơ sở toán học của mã chống nhiễu
   Bài này trình bày các cơ sở toán học của mã khối tuyến tính.
   Các kiến thức này là rất quan trọng để hiểu được cách xây dựng
    các loại mã khối tuyến tính.
   Các khái niệm được trình bày bao gồm các cấu trúc đại số như
    nhóm, trường và đặc biệt là các trường GF(2) và GF(2m), đây là
    các trường có ứng dụng đặc biệt vào trong việc xây dựng các
    mã khối tuyến tính chống nhiễu.




                            Trang 192
      Bài 11 Cơ sở toán học của mã chống nhiễu
11.1 Một số khái niệm cơ bản
11.2 Trường GF(2) và các đa thức trên trường GF(2)
11.3 Trường GF(2m)




                         Trang 193
                     Một số khái niệm cơ bản
   Phép toán đóng
        Cho G là một tập hợp, một phép toán hai ngôi f được gọi là
         đóng trên G nếu f có dạng
                                   f:G×G→G
         tức là nếu a, b ∈ G thì f(a, b) ∈ G.
   Chú ý
         f(a, b) có một cách viết tương đương là afb và ngược lại f(b, a)
         còn được viết là bfa. Chẳng hạn nếu f là phép cộng thì thay vì
         viết +(a, b) chúng ta thường viết là a + b.
        Kể từ đây trở về sau khi nói đến một phép toán nếu chúng ta
         không nói gì thêm thì có nghĩa là phép toán này có tính đóng.


                                  Trang 194
                 Một số khái niệm cơ bản (tt)
   Tính kết hợp
        Một phép toán hai ngôi f trên G được gọi là có tính kết hợp nếu
         ∀ a, b, c ∈ G thì
                                (afb)fc = af(bfc)
   Tính giao hoán
        Một phép toán hai ngôi f trên G được gọi là có tính giao hoán
         nếu ∀ a, b ∈ G thì
                                     afb = bfa
   Ví dụ
        Trên tập số thực khác 0, phép cộng và phép nhân có tính kết
         hợp và giao hoán nhưng phép trừ và phép chia không có tính
         kết hợp và giao hoán.

                                 Trang 195
                                   Nhóm
   Tính phân phối
        Phép toán f1 được gọi là có tính phân phối đối với phép toán f2
         nếu ∀ a, b, c ∈ G thì
                             af1(bf2c) = (af1b)f2(af1c)
        Chẳng hạn trên tập số thực, phép nhân có tính phân phối đối với
         phép cộng vì ∀ a, b, c ∈ R
                              a×(b+c) = (a×b)+(a×c)
   Nhóm
        Một tập G ≠ ∅, với một phép toán hai ngôi f được gọi là một
         nhóm nếu thoả 3 điều kiện sau:
         (1) f có tính kết hợp.


                                 Trang 196
                                 Nhóm (tt)
         (2) G chứa phần tử e, sao cho ∀ a ∈ G thì afe = efa = a. e được
             gọi là phần tử trung hoà (đối với một số phép toán e còn
             được gọi là phần tử đơn vị)
         (3) Mọi phần tử đều có phần tử đối xứng, tức là ∀ a ∈ G, tồn
             tại phần tử b ∈ G sao cho
                                     afb = bfa = e
        Chẳng hạn, trên tập R nếu f là phép cộng thì phần tử trung hoà
         là số 0, còn trên tập số thực khác 0 nếu f là phép nhân thì phần
         tử trung hoà là 1 và còn được gọi là phần tử đơn vị.
   Nhóm giao hoán
        Một nhóm mà phép toán f có tính giao hoán thì được gọi là
         nhóm giao hoán.


                                  Trang 197
                                Nhóm (tt)
   Nhóm hữu hạn, nhóm vô hạn
        Một nhóm có số phần tử hữu hạn được gọi là nhóm hữu hạn,
         một nhóm có số phần tử vô hạn được gọi là nhóm vô hạn.
   Nhóm con
        Cho G là một nhóm. Một tập H con của G được gọi là một
         nhóm con nếu H đóng với phép toán hai ngôi của G và thoã
         điều kiện của một nhóm.
        Tập các số chẵn ≥ 0 là một nhóm con của tập số tự nhiên với
         phép cộng thông thường.




                                 Trang 198
                  Phép cộng và nhân modulo
   Phép cộng modulo và phép nhân modulo
        Cho một số nguyên dương m xác định. Xây dựng một tập số
         nguyên sau G = {0, 1, …, m –1}. Với + là phép cộng thông
         thường. Định nghĩa phép toán mới ⊕ như sau và gọi là phép
         cộng modulo
                     ∀ a, b ∈ G thì a ⊕ b = (a + b) mod m
        Tương tự với × là phép nhân thông thường. Định nghĩa phép
         toán mới ⊗ như sau và gọi là phép nhân modulo
                     ∀ a, b ∈ G thì a ⊗ b = (a × b) mod m




                                Trang 199
                               Ví dụ
   Tập R là một nhóm giao hoán đối với phép cộng và là một
    nhóm vô hạn.
   Tập R – {0} là một nhóm giao hoán đối với phép nhân và là
    một nhóm vô hạn.
   Với m là một số nguyên dương xác định, tập G = {0, 1, …, m –
    1} với phép cộng modulo là một nhóm giao hoán và là một
    nhóm hữu hạn.
   Hai bảng sau đây trình bày lần lượt trường hợp m = 5 và m = 6.




                            Trang 200
                                Ví dụ (tt)
                m=5                         m=6

        ⊕   0   1   2   3   4   ⊕ 0 1 2 3 4 5
        0   0   1   2   3   4    0 0 1 2 3 4 5
        1   1   2   3   4   0    1 1 2 3 4 5 0
        2   2   3   4   0   1    2 2 3 4 5 0 1
        3   3   4   0   1   2    3 3 4 5 0 1 2
        4   4   0   1   2   3    4 4 5 0 1 2 3
                                 5 5 0 1 2 3 4
   Tương tự tập G = {1, …, m –1} với phép nhân modulo và m
    nguyên tố là một nhóm giao hoán hữu hạn.


                                Trang 201
                                   Bổ đề
   Bổ đề 11.1
        Nếu m là một số nguyên tố thì G = {1, …, m – 1} là một nhóm
         giao hoán với phép nhân modulo ⊗. Ngược lại nếu m không
         nguyên tố thì G không là một nhóm.
                    m=5                          m=6
                ⊗   1 2 3   4               ⊗   1 2 3 4   5
                1   1 2 3   4               1   1 2 3 4   5
                2   2 4 1   3               2   2 4 0 2   4
                3   3 1 4   2               3   3 0 3 0   3
                4   4 3 2   1               4   4 2 0 4   2
                                            5   5 4 3 2   1

                                Trang 202
                                  Trường
   Trường
        Một tập G với hai phép toán đóng hai ngôi bất kỳ, chẳng hạn kí
         hiệu là + và *, được gọi là một trường nếu thoả 3 điều kiện sau
         (1) G là nhóm giao hoán đối với phép +. Phần tử trung hoà
             trong phép + thường được kí hiệu là 0.
         (2) Tập các phần tử khác 0 là một nhóm đối với phép *. Phần tử
             trung hoà trong phép * thường được gọi là phần tử đơn vị
             và kí hiệu là 1.
         (3) Phép * có tính phân phối đối với phép +.
   Chú ý
        Phép + và phép * ở trên không nhất thiết là phép cộng và phép
         nhân thông thường mà chúng có thể là bất kỳ phép nào. Chúng
         ta kí hiệu như vậy để dễ trình bày.
                                 Trang 203
                                Trường (tt)
        Các phần tử của một trường không nhất thiết là các số nguyên
         hay thực mà có thể là bất kỳ cái gì, chẳng hạn có thể là các số
         phức, vectơ, ma trận hay đa thức ...
        Từ định nghĩa của trường chúng ta suy ra một trường bao gồm
         tối thiểu hai phần tử: phần tử trung hoà của phép + (kí hiệu là 0)
         và phần tử trung hoà của phép * (kí hiệu là 1). Các phần tử 0 và
         1 không nhất thiết là số 0 và số 1 theo nghĩa thông thường mà
         có thể là bất kỳ cái gì chẳng hạn là ma trận 0 và ma trận đơn vị,
         ...
   Trường giao hoán
        Một trường mà phép * có tính giao hoán thì được gọi là trường
         giao hoán.


                                  Trang 204
                                Trường (tt)
        Chẳng hạn trong ví dụ ở slide 202 với m = 5 chúng ta thấy G là
         một trường giao hoán.
        Tổng quát chúng ta có bổ đề sau và để dành việc chứng minh
         cho các bạn sinh viên.
   Bổ đề 11.2
        Cho p là một số nguyên tố bất kỳ, G = {0, 1, ..., p – 1} thì G là
         một trường giao hoán đối với phép cộng modulo ⊕ và phép
         nhân modulo ⊗.
        Sau đây là một số tính chất của trường
   Tính chất 1
        Mọi phần tử a của trường đều thoả a * 0 = 0.


                                  Trang 205
                             Trường Galois
   Tính chất 2
        Nếu a, b là hai phần tử khác 0 của trường thì a * b ≠ 0.
   Tính chất 3
        Nếu a ≠ 0 và a * b = a * c thì b = c. Hay nói cách khác nếu a ≠
         0 và b ≠ c thì a * b ≠ a * c.
   Bậc của một trường, trường hữu hạn, trường vô hạn.
        Số phần tử của một trường được gọi là bậc của một trường. Một
         trường có số phần tử hữu hạn được gọi là trường hữu hạn, một
         trường có số phần tử vô hạn được gọi là trường vô hạn.
   Trường GF(q)
        Một trường có số phần tử hữu hạn được gọi là trường Galois.
         Nếu bậc của trường Galois là q thì trường được kí hiệu là
         GF(q).
                                  Trang 206
                            Trường Galois
        Đối với các trường hữu hạn tức là trường Galois chúng ta có
         định lý sau.
   Định lý 11.1
        Một trường hữu hạn thì số phần tử của nó phải có dạng pm trong
         đó p là một số nguyên tố còn m là một số nguyên dương. Hay
         nói cách khác các trường Galois đều có dạng GF(pm) trong đó p
         là một số nguyên tố còn m là một số nguyên dương.
        Đối với các trường GF(p) với p nguyên tố thì đó chính là tập
         {0, 1, 2, ..., p – 1} với hai phép toán cộng modulo ⊕ và nhân
         modulo ⊗ như đã biết.
        Đối với các trường GF(pm), vì tính phức tạp của chúng, chúng
         ta sẽ giới thiệu sau. Chú ý lúc này các phần tử của trường
         GF(pm) không đơn thuần là các số mà sẽ có dạng khá đặc biệt.

                                 Trang 207
                         Trường Galois (tt)
   Kí hiệu các phần tử đối xứng
        Phần tử đối xứng của a trong phép + được kí hiệu là –a, phần tử
         đối xứng của a trong phép * được kí hiệu là a–1.
   Phép – và phép /
        Đối với một trường giao hoán, từ hai phép + và phép * chúng ta
         định nghĩa thêm hai phép – và phép / như sau (không nhất thiết
         là phép trừ và phép chia bình thường)
                                 a – b = a + (–b)
                                  a / b = a * b–1
         trong đó –b là phần tử đối xứng của b qua phép +, còn b–1 là
         phần tử đối xứng của b qua phép *.
        Vậy một trường giao hoán G có bốn phép toán +, –, *, /. Phép +
         và – đóng trên G, phép * và / đóng trên G – {0}.
                                 Trang 208
               Trị riêng của một trường
   Xét một trường GF(q). Xét các dãy tổng của các phần tử đơn vị
                 k
                ∑1 = 1 + 1 + L + 1        (k lần, với k = 1, 2, 3, …)
                i =1
   Vì trường đóng với phép cộng nên kết quả của những tổng này
    cũng là các phần tử của trường. Vì k có thể nhận vô hạn giá trị
    mà trường chỉ có q phần tử nên tồn tại hai giá trị k1 và k2 khác
    nhau (giả sử k1 > k2 ) sao cho
                              k1          k2

    Từ đây suy ra
                              ∑1 = ∑1
                             i =1        i =1
                               k1 − k 2
                                 ∑1 = 0
                                 i =1



                             Trang 209
                    Trị riêng của một trường
        Trị riêng của một trường kí hiệu là số nguyên dương nhỏ nhất λ
         sao cho                   λ
                                  ∑1 = 0
                                  i =1
        Dễ thấy đối với các trường GF(p) = {0, 1, 2, ..., p – 1} với p là
         một số nguyên tố thì trị riêng λ = p. Tổng quát chúng ta có định
         lý sau.
   Định lý 11.2
        Trị riêng λ của một trường GF(q) là một số nguyên tố.
   Chứng minh
        Giả sử λ không nguyên tố ⇒ λ = k × l (k, l nguyên > 1). Từ qui
         tắc phân phối của phép nhân đối với phép cộng suy ra


                                  Trang 210
                  Trị riêng của một trường (tt)
                           k           l        k ×l    λ
                          ∑1× ∑1 = ∑1 = ∑1 = 0
                          i =1        i =1      i =1   i =1
                                 k                       l
         Suy ra
                               ∑1 = 0hoặc i =1
                                                        ∑1 = 0
                               i =1
         Mà k, l < λ, điều này mâu thuẫn với định nghĩa của λ.
   Chu kỳ của một phần tử
        Xét một phần tử a bất kỳ khác 0 của trường GF(q). Xét các luỹ
         thừa ak của a với k = 1, 2, 3, … Vì trường đóng với phép nhân
         nên các ak cũng là các phần tử của trường. Vì k có thể nhận vô
         hạn giá trị mà trường chỉ có q phần tử nên tồn tại hai giá trị k1
         và k2 khác nhau (giả sử k1 > k2 ) sao cho
                        a k1 = a k 2 ⇒ a k1 − k 2 = 1

                                           Trang 211
                     Chu kỳ của một phần tử
        Chu kỳ của một phần tử a của một trường GF(q) là số nguyên
         dương nhỏ nhất n sao cho an = 1.
   Ví dụ
        Xét trường GF(7) = {0, 1, 2, 3, 4, 5, 6} với hai phép ⊕ và ⊗.
         Trị riêng của trường này là 7. Còn chu kỳ của các phần tử khác
         0 của trường được trình bày trong bảng sau
                   Phần tử    1   2     3      4   5   6
                   Chu kỳ     1   3     6      3   6   2

        Từ định nghĩa trên chúng ta thấy dãy các luỹ thừa của a
                         a1, a2, ..., ak, ..., an = 1, an+1 = a, ...
         sẽ lặp lại sau n phần tử.

                                   Trang 212
                            Nhóm tuần hoàn
   Bổ đề 11.3
        Dãy a1, a2, ..., ak, ..., an = 1 tạo nên một nhóm con đóng với
         phép nhân trên trường GF(q).
   Nhóm tuần hoàn
        Một nhóm (không chứa phần tử 0) với phép nhân * được gọi là
         tuần hoàn nếu tồn tại một phần tử trong nhóm mà các luỹ thừa
         của nó tạo nên mọi phần tử trong nhóm.
        Từ định nghĩa này suy ra một nhóm hữu hạn được gọi là tuần
         hoàn nếu tồn tại một phần tử trong nhóm có chu kỳ đúng bằng
         số phần tử của nhóm.
   Định lý 11.3
        Nếu a là một phần tử khác 0 của một trường GF(q) thì
                                    aq–1 = 1
                                   Trang 213
                        Nhóm tuần hoàn (tt)
   Chứng minh
        Gọi b1, b2, ..., bq-1 là q – 1 phần tử khác nhau và khác 0 của
         trường. Theo tính chất 3 và tính chất 2 của trường chúng ta có
         a*b1, a*b2, ..., a*bq-1 cũng là q – 1 phần tử khác nhau và khác 0
         của trường. Vì vậy chúng ta có
                       a*b1*a*b2* ... *a*bq-1 = b1*b2* ... *bq-1
        Từ đây suy ra aq–1 = 1. Hoàn tất chứng minh.
   Định lý 11.4
        Chu kỳ của một phần tử bất kỳ khác 0 của một trường GF(q) là
         ước số của q – 1.




                                  Trang 214
                              Phần tử cơ sở
   Chứng minh
        Gọi n là chu kỳ của phần tử a khác 0 của trường GF(q). Giả sử
         q – 1 không chia hết cho n. Do đó q – 1 = kn + r, trong đó r là
         số dư của phép chia q – 1 cho n, 0 < r < n. Chúng ta có
                                aq-1 = akn+r = (an)k*ar
         Do aq-1 = 1 và an = 1 suy ra ar = 1. Mà 0 < r < n điều này mâu
         thuẫn với định nghĩa chu kỳ của a. Vậy q – 1 chia hết cho n.
   Phần tử cơ sở
        Một phần tử a khác 0 của một trường GF(q) được gọi là phần
         tử cơ sở nếu chu kỳ của a bằng q – 1.
        Từ định nghĩa này ⇒ nếu a là một phần tử cơ sở thì các luỹ
         thừa của a gồm a0 = 1, a1 = a, a2, …, aq – 2 hình thành nên q – 1
         phần tử khác 0 của trường.
                                  Trang 215
                               Ví dụ
   Xét trường GF(7) như trong ví dụ ở slide 209. Chu kỳ của các
    phần tử khác 0 của trường đều là ước số của 6. Đặc biệt các
    phần tử 3 và 5 có chu kỳ bằng 6 nên chúng là các phần tử cơ sở
    của trường GF(7).
           31 = 3 32 = 2 33 = 6 34 = 4 35 = 5 36 = 1
           51 = 5 52 = 4 53 = 6 54 = 2 55 = 3 56 = 1

   Trong các trường Galois thì trường GF(2) và trường GF(2m) là
    những trường có nhiều ứng dụng đặc biệt trong lý thuyết mã,
    nên chúng ta sẽ chỉ trình bày hai trường này.




                            Trang 216
                            Trường GF(2)
   Trường GF(2)
        Trường GF(2) bao gồm hai phần tử {0, 1} với hai phép cộng +
         và nhân * như sau
                        +   0    1           *   0   1
                        0   0    1           0   0   0
                        1   1    0           1   0   1

        Phần tử đối xứng của 0 và 1 qua phép cộng cũng chính là 0 và
         1. Phần tử đối xứng của 1 qua phép nhân cũng chính là 1.
        Trong trường GF(2) thì phép trừ giống với phép cộng, phép
         chia cho một số khác 0 cũng giống với phép nhân.

                                 Trang 217
                Các đa thức trên trường GF(2)
   Đa thức trên trường GF(2)
        Một đa thức trên trường GF(2), chẳng hạn kí hiệu là f(x), là đa
         thức có dạng
                        f(x) = a0 + a1x + a2x2 + … + anxn
         trong đó các hệ số ai ∈ GF(2).
   Bậc của đa thức
        Là bậc lớn nhất của đa thức.
   Ví dụ
        Đa thức f(x) = 1 + x + x3 có bậc 3 đa thức g(x) = x + x2 + x5 có
         bậc 5.


                                  Trang 218
            Các đa thức trên trường GF(2) (tt)
   Phép cộng đa thức và nhân đa thức
        Với f(x) = a0 + a1x + a2x2 + … + anxn, g(x) = b0 + b1x + b2x2 +
         … + bnxn với các hệ số ai và bj thuộc trường GF(2) chúng ta
         định nghĩa các phép cộng đa thức và nhân đa thức như sau
                                           n           i
                         f(x) + g(x) =    ∑   (a +
                                                i ib )x
                                        i=0
                                           n
                         f(x) * g(x) = ∑ (ai *bj )xi + j
                                       i, j = 0
     trong đó ai + bi và ai * bj được thực hiện trên trường GF(2).


                                  Trang 219
             Các đa thức trên trường GF(2) (tt)
   Ví dụ
        Cho f(x) = 1 + x + x3, g(x) = x + x2 thì
                 f(x) + g(x) = (1 + x + x3) + (x + x2) = 1 + x2 + x3
                 f(x) * g(x) = (1 + x + x3) * (x + x2) = x + x3 + x4 + x5
        Nếu g(x) có bậc khác 0 thì chúng ta có thể chia f(x) cho g(x) và
         có thể viết như sau
                              f(x) = q(x) * g(x) + r(x)
         trong đó q(x) là đa thức thương còn r(x) là đa thức dư có bậc
         nhỏ hơn đa thức chia g(x).
   Ví dụ
        f(x) = 1 + x + x4 + x5 + x6 chia cho g(x) = 1 + x + x3
                                  Trang 220
             Các đa thức trên trường GF(2) (tt)
        1 + x + x4 + x5 + x6 = (x2 + x3) * (1 + x + x3) + (1 + x + x2)
        Để phân tích một đa thức ra thành các thừa số trong đại số
         Euclid chúng ta có
        Nếu f(a) = 0 thì f(x) chia hết cho (x - a).
        Điều này cũng đúng trên trường GF(2).
   Ví dụ
         f(x) = 1 + x + x3 + x5 có f(1) = 0, nên f(x) chia hết cho (x - 1)
         mà trong trường GF(2), phép trừ cũng chính là phép cộng tức là
         f(x) chia hết cho (x + 1).
                        1 + x + x3 + x5 = (1 + x)(1 + x3 + x4)


                                   Trang 221
                           Đa thức tối giản
   Một đa thức trên GF(2) được gọi là tối giản nếu nó không phân
    tích được thành tích của hai đa thức có bậc nhỏ hơn.
         1, 2, 3, 4                  5                      6
    x                      1 + x2 + x5             1 + x + x6
    1+x                    1 + x3 + x5             1 + x3 + x6
    1 + x + x2             1 + x + x2 + x3 + x5    1 + x + x2 + x4 + x6
    1 + x + x3             1 + x + x2 + x4 + x5    1 + x + x3 + x4 + x6
    1 + x2 + x3            1 + x + x3 + x4 + x5    1 + x5 + x6
    1 + x + x4             1 + x2 + x3 + x4 + x5   1 + x + x2 + x5 + x6
    1 + x3 + x4                                    1 + x2 + x3 + x5 + x6
    1 + x + x2 + x3 + x4                           1 + x + x4 + x5 + x6
                                Trang 222          1 + x2 + x4 + x5 + x6
                                         Bổ đề
        Cho f(x) là một đa thức trên trường GF(2), thì
                                 2n            2n
                         f (x)        = f (x        )
   Chứng minh
        Đặt f(x) = a0 + a1x + … + anxn.
         [f(x)]2 = (a0 + a1x + … + anxn)2
                  = a02 + a0*(a1x + … + anxn) + a0*(a1x + … + anxn) +
                    (a1x + … + anxn)2
                  = a02 + (a1x + … + anxn)2
                  = a02 + (a1x)2 + … + (anxn)2
                  = f(x2) (vì trong GF(2) ai2 = ai )
        Điều này cũng giúp chúng ta suy ra điều phải chứng minh.
                                      Trang 223
                            Trường GF(2m)
        Trước hết chúng ta kí hiệu trường GF(2m) như sau
                        GF(2m) = {0, 1, a1, a2, ..., a m }
                                                      2 −2
         trong đó 0 và 1 ∈ GF(2). Trường GF(2) là một trường con của
         GF(2m) và được gọi là trường cơ sở của GF(2m).
   Chú ý
        Nếu a là một phần tử ∈ GF(2m), f(x) là một đa thức trên trường
         GF(2), thì f(a) cũng là một phần tử của GF(2m).
        Có vô hạn đa thức f(x) trên trường GF(2) mà chỉ có hữu hạn
         (2m) phần tử ∈ GF(2m), nên ∀ a ≠ 0 của GF(2m) tồn tại hai đa
         thức f1(x) và f2(x) khác nhau sao cho f1(a) = f2(a). Từ đây nếu
         đặt f(x) = f1(x) – f2(x) (chú ý trong trường GF(2) thì phép –
         giống với phép cộng +) thì f(a) = 0.
                                 Trang 224
                            Đa thức tối thiểu
   Đa thức tối thiểu (minimal polinomial)
        Cho a là một phần tử khác 0 của trường GF(2m). Đa thức tối
         thiểu của a là đa thức f(x) khác 0 trên trường GF(2) và có bậc
         nhỏ nhất sao cho f(a) = 0.
        Một lần nữa ta phải chú ý rằng khi chúng ta viết f(α) = 0 hoặc
         f(α) = 1 thì các kí hiệu 0 và 1 không nhất thiết là các số 0 và 1,
         mà sẽ được hiểu tuỳ theo ngữ cảnh.
        Chẳng hạn nếu phần tử α là một ma trận thì 0 chính là ma trận
         0 còn 1 chính là ma trận đơn vị.




                                   Trang 225
                       Đa thức tối thiểu (tt)
                                                    ⎡0        1 0 0⎤
    Ví dụ                                           ⎢0        0 1 0⎥⎥


      Chẳng hạn nếu a là ma trận 4 × 4 bên T4× 4 = ⎢
                                                    ⎢0        0 0 1⎥
                                                    ⎢               ⎥
                                                    ⎣1        1 0 0⎦
         trong đó các phép cộng và nhân trên ma trận vẫn thực hiện như
         bình thường với chú ý rằng các phép cộng và nhân các phần tử
         của ma trận được thực hiện trên trường GF(2).
        Chúng ta có thể kiểm tra rằng
                                   1 + T + T4 = 0
         với chú ý rằng 1 là ma trận đơn vị, còn 0 là ma trận 0.
        Và f(x) = 1 + x + x4 là đa thức tối thiểu của a

                                 Trang 226
                                    Định lý
        Hơn nữa chúng ta cũng có
                                      T15 = 1
         và chúng ta có thể kiểm tra rằng 15 chính là chu kỳ của a.
   Định lý 11.5
        Cho a là một phần tử khác 0 của trường GF(2m) có bậc của đa
         thức tối thiểu của a là k. Gọi Z là tập tất cả các phần tử có dạng
                               b0 + b1a + … + bk-1ak-1
         trong đó bi ∈ GF(2). Thì Z là một tập con của GF(2m) và hình
         thành nên một trường có 2k phần tử.




                                   Trang 227
                         Chứng minh
   Đầu tiên chúng ta chứng minh các phần tử được hình thành từ
    b0 + b1a + … + bk-1ak-1 là khác nhau bằng cách chứng minh các
    phần tử 1, a, a2, …, ak-1 là độc lập tuyến tính.
    Thật vậy nếu           k −1         k −1
                           ∑ i b  a i
                                      = ∑ i c a i
                         i=0             i=0
    thì
                                k −1
                       p(a) =   ∑ i i =0
                                 (b − c ) a i
                                i=0
    Vậy chúng ta có đa thức p(x) có bậc nhỏ hơn k thoã p(a) = 0.
    Mà bậc của đa thức tối thiểu của a bằng k. Vậy p(x) = 0, suy ra
    bi = ci ∀ i = 0, 1, ..., k – 1.

                             Trang 228
                           Chứng minh (tt)
   Thứ hai, rõ ràng Z là một nhóm giao hoán đối với phép +.
    Thật vậy nếu
    k −1            k −1               k −1            k −1
    ∑ i ∈ Z,
     b a i
                    ∑ i ∈Z ⇒
                     c a i
                                       ∑ i i =
                                        (b + c ) a i
                                                        ∑ i i ∈Z
                                                         ( c + b ) a i

    i=0             i=0                i=0             i=0
    Để chứng minh tập Z0 = Z – {0} là một nhóm đối với phép nhân
    * chúng ta chứng minh nếu
           k −1            k −1               k −1     k −1
           ∑ i
            b  a i
                   ∈ Z 0 ∑ i ∈ Z0 ⇒
                        , c a i
                                              ∑ i ∑ i ∈ Z0
                                               b a i
                                                     * c a i

           i=0             i=0                i=0      i=0
                     k
    Gọi f ( x ) =   ∑ i là đa thức tối thiểu của a, trong đó hệ số
                     d x i
                    i=0
    cao nhất dk = 1.
                                  Trang 229
                   Chứng minh (tt)
                                  k −1
Từ đây suy ra
                          xk =    ∑ i
                                   d  x i
                                  i=0
Do đó mọi an với n ≥ k đều có thể biểu diễn thông qua một đa
thức g(a) nào đó có bậc ≤ k – 1. Vì vậy k −1 i k −1 i
                                         ∑ bi a * ∑ ci a
                    k −1          k −1          i=0          i=0
cũng vậy. Suy ra
                    ∑ i ∑ i ∈Z
                     b a i
                           * c a i
                    i=0           i=0
Và rõ ràng nếu
     k −1          k −1                  k −1         k −1
      ∑ bi a ≠ 0, ∑ ci a ≠ 0 ⇒
                              i
            i
                                         ∑ i ∑ i ≠0
                                          b a * c i
                                                  a i

     i=0           i=0                   i=0          i=0
Tính chất này được kế thừa từ trường GF(2m).

                           Trang 230
                                   Hệ quả
        Cuối cùng tính phân phối của phép nhân * đối với phép cộng +
         chúng ta cũng kế thừa từ trường GF(2m). Chứng minh hoàn tất.
   Hệ quả 11.1
        Nếu đa thức tối thiểu của phần tử a ∈ GF(2m) có bậc bằng m thì
         trường Z trùng với trường GF(2m) và mỗi phần tử của trường có
         thể được biểu diễn như một vectơ m thành phần
                                   (b0b1…bm-1)
   Định lý 11.6
        Gọi f(x) là đa thức tối thiểu của phần tử a ≠ 0 của trường
         GF(2m) thì f(x) là đa thức tối giản trên trường GF(2).


                                  Trang 231
                              Chứng minh
        Giả sử f(x) = g(x) * h(x) trong đó g(x) và h(x) có bậc lớn hơn 0
         và nhỏ hơn bậc của f(x). Chúng ta có f(a) = g(a) * h(a) = 0, suy
         ra g(a) = 0 hoặc h(a) = 0. Điều này mâu thuẫn với định nghĩa
         về đa thức tối thiểu của a.
   Bổ để 11.5
        Cho f(x) là đa thức tối thiểu của phần tử a ≠ 0 của trường
         GF(2m) và p(x) là đa thức bất kỳ trên trường GF(2) sao cho p(a)
         = 0. Thì p(x) chia hết cho f(x).
   Chứng minh
        Chia p(x) cho f(x) chúng ta được
                             p(x) = g(x) * f(x) + r(x)
         trong đó bậc của r(x) nhỏ hơn bậc của f(x).
         Thay x = a ⇒ r(a) = 0, nên từ định nghĩa của đa thức tối thiểu
         ⇒ r(x) = 0 ⇒ p(x) chia hết cho f(x).
                                  Trang 232
                                   Định lý
   Định lý 11.7
        Cho f(x) là đa thức tối thiểu của phần tử a ≠ 0 của trường
         GF(2m) và p(x) là đa thức tối giản trên trường GF(2) sao cho
         p(a) = 0. Thì f(x) = p(x).
   Chứng minh
        Theo Bổ đề 11.5 trên chúng ta có p(x) chia hết cho f(x) tức là
         chúng ta có thể viết
                                 p(x) = g(x) * f(x)
         Do p(x) là đa thức tối giản nên f(x) = 1 hoặc f(x) = p(x). Tuy
         nhiên f(x) không thể bằng 1 nên suy ra f(x) = p(x).
   Hệ quả 11.2
        2m – 1 phần tử khác 0 của trường GF(2m) đều là nghiệm của
         phương trình
                               2 m −1
                             x        +1= 0
                                  Trang 233
                                  Hệ quả
   Hệ quả
         m
           11.3
        x 2 −1 + 1 chia hết cho các đa thức tối thiểu của các phần tử
         khác 0 của trường GF(2m).
        Chúng ta sẽ dẫn ra một hệ quả mạnh hơn như sau. Trước hết
         chúng ta phân tích
                                  2 m −1
                                x        +1
         thành tích của các đamthức tối giản trên trường GF(2)
                              2 −1
               m            x       + 1 = p1(x) * p2(x) * … * pl(x)
         Vì x 2 −1 + 1 có các nghiệm là các phần tử của trường GF(2m)
         nên các phần tử của trường GF(2m) sẽ là nghiệm của một pi(x)
         nào đó và ngược lại một pi(x) bất kỳ sẽ có các nghiệm là các
         phần tử của trường GF(2m).
         Hơn nữa nếu pi(x) có bậc t thì sẽ có t nghiệm trong trường
         GF(2m).

                                 Trang 234
                                             Hệ quả
   Hệ quả 11.4
                                           2 m −1
        Trong việc triển khai x        + 1 thành tích các đa thức tối giản,
         thì mỗi đa thức tối giản sẽ là đa thức tối thiểu của một phần tử
         khác 0 nào đó của trường GF(2m).
   Định lý 11.8
        Cho a là một phần tử khác 0 của trường GF(2m) và f(x) là một
         đa thức trên trường GF(2). Nếu f(a) = 0 thì
                                      2l
                               f (a        ) = 0 ∀ l = 0, 1, 2, ...
   Hệ quả 11.5
        Nếu f(x) là đa thức tối thiểu của phần tử a ≠ 0 của trường
         GF(2m) thì f(x) cũng là đa thức tối thiểu của các phần tử
                          2l
                      a        với l = 0, 1, 2, ... của trường GF(2m).
                                            Trang 235
                                Hệ quả (tt)
                                                2l
   Hay nói cách khác các phần tử a với l = 0, 1, 2, ... là các
    nghiệm của đa thức tối thiểu f(x) của phần tử a.
   Hơn nữa chúng ta sẽ chứng minh rằng ngoài chúng ra f(x)
    không còn nghiệm nào khác thuộc trường GF(2m).
                                                     2l
   Vì vậy nếu có bao nhiêu phần tử a khác nhau thì f(x) có bậc
    bấy nhiêu.
   Để làm rõ điều này gọi k là số nguyên dương nhỏ nhất sao cho
                                    2k
                                a        =a
    Số k chắc chắn tồn tại vì chúng ta đã có
                       2 m −1                   2m
                   a            = 1 hay a                 =a
    Và số k biểu diễn chu kỳ của dãy
                                2 l với l = 0, 1, 2, ...
                           a
                                    Trang 236
                                             Bổ đề
   Bổ dề 11.6
        Cho a là một phần tử khác 0 của trường GF(2m) và k là số
         nguyên dương nhỏ nhất sao cho
                                        2k
                                    a        =a
         thì k là một ước số của m.                      2l
                                                     a
   Chứng minh
        Chia m cho k, m = n × k + r, trong đó r là số dư và r < k
                                         2k
                 2k         ⎛ 2k ⎞                   2k                 2 2k
             a        = a ⇒ ⎜a ⎟               =a           = a hay a          =a
                            ⎝    ⎠
                                                            2 nk
         Tiếp tục theo kiểu này chúng ta có a                      = a . Mặt khác chúng
         ta có                                                               2r
               2m          2 n× k + r        2 n× k × 2 r       ⎛ 2 n× k ⎞                 2r
         a=a          =a                =a                    = ⎜a       ⎟        = (a )
                                                                ⎝        ⎠
                                         Trang 237
                                    Bổ đề (tt)
         Do định nghĩa của k ⇒ r = 0. Hoàn tất chứng minh.
   Phần tử liên hợp
        Cho a là một phần tử khác 0 của trường GF(2m) và k là số
         nguyên dương nhỏ nhất sao cho
                                   2k
                          2l   a        =a
         thì các phần tử a với l = 0, 1, 2, ..., k - 1 được gọi là các phần
         tử liên hợp của a và k được gọi là số phần tử liên hợp của a.
        Từ định nghĩa chúng ta thấy tập các phần tử liên hợp của a là
         tập các phần tử khác nhau được sinh ra bởi
                                   2l
                                a với l = 0, 1, 2, ...
   Bổ dề 11.7
        Nếu a1 và a2 là các phần tử liên hợp bất kỳ của a thì a1 là phần
         tử liên hợp của a2 và ngược lại a2 là phần tử liên hợp của a1.
                                    Trang 238
                                              Bổ đề (tt)
   Thật vậy giả sử (với k là số phần tử liên hợp của a)
                                    2 l1                2l2
                           a1 = a           , a2 = a           ,0 ≤ l1 < l 2 < k
    Thì
              2 l 2 − l1          2 l1 2 l 2 − l1          2 l1 × 2 l 2 − l1          2l2
         a1                = (a        )             =a                        =a           = a2
    và
              2 k + l1 − l 2               2 l 2 2 k + l1 − l 2          2 l 2 × 2 k + l1 − l 2
         a2                    = (a             )                   =a
                                       2 k + l1            2 k 2 l1            2 l1
                                  =a                = (a        )       =a             = a1

    Hoàn tất chứng minh.
   Chú ý bổ đề này nói lên rằng các phần tử liên hợp của a là liên
    hợp với nhau.

                                               Trang 239
                            Bổ đề (tt)
   Vì các phần tử a 2 lvới l = 0, 1, 2, ..., k - 1 là các nghiệm của đa
    thức tối thiểu f(x) của a, nên ta sẽ chứng minh f(x) có dạng
                                                               k −1
                                                 2 k −1                   2i
                            2
    f (x) = (x + a) * (x + a ) * K * (x + a               )=   ∏ (x + a        )
                                                               i=0
   Để chứng minh điều này chúng ta sẽ chứng minh
                                k −1
                                            2i
                      p(x) =    ∏ (x + a         )
                                i=0
    là một đa thức tối giản và do p(a) = 0 nên theo ‎Định lý 11.7
    chúng ta suy ra f(x) = p(x).




                                Trang 240
                                       Bổ đề (tt)
   Bổ dề 11.7
        Cho a là một phần tử khác 0 của trường GF(2m) và k là số
         nguyên dương nhỏ nhất sao cho
                                         2k
                                    a         =a
                                       k −1
         thì                                          2i
                              p(x) =   ∏ (x + a               )
                                       i=0
         là một đa thức tối giản trên trường GF(2).
   Chứng minh
                                                          2
                                ⎡ k −1             2i
                                                      ⎤           k −1
                                                                         2i 2
                  [ p (x )]
                          2
                              = ⎢ ∏ (x + a           )⎥ = ∏ (x + a         )
                                ⎢⎣ i = 0              ⎥⎦  i=0

                                       Trang 241
                          Chứng minh (tt)
         2i 2         2        2i         2i                 2i 2        2         2 i +1
(x + a     ) = x + (a               +a         ) x + (a          ) =x +a
                    k −1                            k
                                    2 i +1                          2i
⇒ [ p ( x )] =
           2
                    ∏ (x   2
                               +a            ) = ∏ (x + a    2
                                                                         )
                    i=0                            i =1
                    k −1
                           2        2i         2        2k
                =   ∏ (x       +a        )(x + a             )
                    i =1
                    k −1                                     k −1
                           2        2i         2                    2         2i
                =   ∏ (x       +a        )(x + a ) =         ∏ (x        +a        )
                    i =1                                     i=0
                = p(x 2 )

                                Trang 242
                     Chứng minh (tt)
Mặt khác p(x) là một đa thức của x và có thể biểu diễn
                    p(x) = b0 + b1x + … + bkxk
trong đó các bi với i = 0, 1, 2, …, k là các đa thức trên trường
GF(2) của a. Vì vậy các bi là các phần tử của trường GF(2m).
    [ p(x)]2 = (b0 + b1x + Kbk x k ) 2
                k                     k   k                k
                                                 i+ j
           =   ∑ i x + (1 + 1) ∑
                b 2 2i
                                          ∑i j
                                           b b x      =   ∑ix
                                                           b 2 2i
               i=0                i=0 j=0                 i=0
                                        i≠ j
Do [p(x)]2 = p(x2) suy ra
                    bi = bi2 ∀ i = 0, 1, 2, …, k
Điều này chỉ đúng nếu các bi bằng phần tử 0 hoặc phần tử 1 tức
là các bi ∈ GF(2) hay p(x) là một đa thức trên trường GF(2).


                          Trang 243
                             Chứng minh (tt)
         Nếu p(x) không tối giản tức p(x) có thể phân tích thành
                                     p(x) = q(x) * h(x)
         trong đó bậc của q(x) và h(x) nhỏ hơn bậc của p(x) là k. Nhưng
         do p(a) = 0 ⇒ q(a) = 0 hoặc h(a) = 0.
                                                                           2l
         Giả sử q(a) = 0, theo ‎Định lý 12.8 ⇒ q(x) có các nghiệm là a
         với l = 0, 1, 2, ..., k – 1, ⇒ q(x) có bậc tối thiểu là k, mẫu thuẫn.
         Từ đây suy ra điều phải chứng minh.
   Định lý 11.9
        Cho a là một phần tử khác 0 của trường GF(2m) và k là số
         nguyên dương nhỏ nhất sao cho
                                      2k
                                  a        =a
                                                  k −1
                                                             2i
         thì đa thức tối thiểu của a là f (x) =   ∏ (x + a        ) và có bậc = k.
                                                  i=0
                                      Trang 244
                                    Hệ quả
   Hệ quả 11.6
        Bậc của một đa thức tối thiểu của một phần tử a khác 0 của
         trường GF(2m) là một ước số của m.
   Định lý 11.10                                                     2l
     
                                                                  a
         Cho a là một phần tử khác 0 của trường GF(2m) có chu kỳ bằng
         n thì các phần tử liên hợp của a cũng có chu kỳ bằng n.
   Chứng minh
        Gọi k là số thành phần liên hợp của a. ∀ i = 0, 1, ..., k
                               n
                        ⎛ 2i ⎞   2i × n     n 2i
                        ⎜a ⎟ = a        = (a ) = 1
                        ⎝    ⎠
        Chúng ta chứng minh rằng không ∃ số nguyên dương l < n
                                               l
                                   ⎛ 2i ⎞
                                   ⎜a ⎟ =1
                                   ⎝    ⎠
                                   Trang 245
                                  Chứng minh
                                                 2 i ×l
         Thật vậy giả sử tồn tại, suy ra a        =1
         Chia 2i × l cho n
                                  2i × l = h × n + r
         trong đó 0 ≤ r < n,
                          2i ×l
                ⇒1= a             = a h× n + r = (a n ) h × a r = a r
         Từ định nghĩa khái niệm chu kỳ, ⇒ r = 0.
         Từ ‎Định lý 11.4 ⇒ n là một ước số của 2m – 1, ⇒ n lẽ. Kết hợp
         với 2i × l = h × n ⇒ n là một ước số của l, ⇒ n ≤ l vô lý.
   Định lý 11.11
        ∀ m ≥ 1 đều tồn tại một đa thức tối giản bậc m trên trường
         GF(2).


                                     Trang 246
                                  Định lý
   Định lý 11.12
        Với một đa thức tối giản p(x) bất kỳ có bậc m,
                           p(x) = b0 + b1x + … + bmxm
         trong đó bm = 1, chúng ta luôn xây dựng được một trường
         GF(2m) trong đó p(x) là đa thức tối thiểu của một phần tử của
         trường.
                                   ⎡    0    1   0   0   L   0       0 ⎤
                                   ⎢                                 0 ⎥⎥
Để xây dựng trường                 ⎢    0    0   1   0   L   0
GF(2m) chúng ta cho                ⎢    0    0   0   1   L   0       0 ⎥
phần tử a là một ma        Tm× m = ⎢                                      ⎥
                                   ⎢    M    M   M   M   L   M       M ⎥
trân m×m như bên                   ⎢    0    0   0   0   L   0       1 ⎥
                                   ⎢                                      ⎥
                                   ⎢⎣   b0   b1 b2   b3 L bm − 2   bm −1 ⎥⎦


                                 Trang 247
                                Định lý (tt)
        Trên ma trận định nghĩa phép cộng và nhân ma trận như bình
         thường, với chú ý rằng việc cộng hoặc nhân hai phần tử trong 2
         ô của hai ma trận được thực hiện như trên trường GF(2).
        Chúng ta công nhận rằng ma trận này có đa thức tối thiểu là
         p(x). Từ đây chúng ta có thể dẫn ra được các phần tử còn lại
         của trường GF(2m) nhờ ‎Định lý 11.5.
        Chú ý, phần tử 0 chính là ma trận 0 và phần tử 1 chính là ma
         trận đơn vị.
   Định lý 11.13
        ∀ m ≥ 2, các đa thức tối giản bậc m trên trường GF(2) đều là
         ước số của
                                      2 m −1
                                    x        +1
        Chúng ta có thể quay trở về bảng liệt kê các đa thức tối giản để
         kiểm tra rằng các đa thức tối giản bậc 3 là ước số của x7 – 1,
         các đa thức tối giản bậc 4 là ước số của x15 – 1, …
                                  Trang 248
                               Định lý (tt)
   Đa thức căn bản
         Một đa thức căn bản là một đa thức tối giản, đồng thời không
         tồn tại số nguyên dương n < 2m – 1 sao cho xn + 1 chia hết cho
         nó.
        Ví dụ, không tồn tại số nguyên dương n < 15 sao cho xn + 1
         chia hết cho 1 + x + x4 nên 1 + x + x4 là đa thức căn bản.
        Còn đa thức 1 + x + x2 + x3 + x4 là tối giản nhưng không căn
         bản vì x5 + 1 chia hết cho nó.
                    1, 2, 3      4, 5            6, 7, 8
                  1+x         1 + x + x4 1 + x + x6
                  1 + x + x2 1 + x3 + x4 1 + x3 + x7
                  1 + x + x3 1 + x2 + x5 1 + x2 + x3 + x4 + x8
                  1 + x2 + x3 1 + x3 + x5
                                 Trang 249
                                Định lý (tt)
   Định lý 11.14
        Cho a là một phần tử khác 0 của trường GF(2m) có đa thức tối
         thiểu là f(x). Nếu f(x) là một đa thức căn bản trên trường GF(2)
         và có bậc bằng m thì a có chu kỳ là 2m – 1 và a là một phần tử l
         cơ sở của GF(2m).                                            a2
   Chứng minh
         Gọi n là chu kỳ của a. Đặt p(x) = xn + 1, thì p(a) = 0.
         Bổ đề 11.5 ⇒ p(x) chia hết cho f(x). Kết hợp điều này với định
         nghĩa của khái niệm đa thức căn bản, ⇒ n = 2m – 1.
        Định lý này gợi ý cho chúng ta cách xây dựng trường GF(2m)
         dựa trên một phần tử cơ sở có đa thức tối thiểu là một đa thức
         căn bản bậc m.



                                  Trang 250
                                Tóm tắt
   Tóm tắt
                                                 2 m −1
       a là một phần tử của trường GF(2m) thì a        =1
       Chu kỳ của một phần tử là một ước số của 2m – 1.
       Các đa thức tối thiểu của trường GF(2m) là các đa thức tối giản
        và là ước số của        m
                             x 2 −1 + 1
        Hơn nữa bậc của chúng là ước của m.
       Số phần tử liên hợp khác nhau của a, kể cả a, là ước số của m.
        Các phần tử liên hợp của nhau có cùng đa thức tối thiểu, hơn
        nữa chúng là các nghiệm của đa thức tối thiểu này và bậc của
        đa thức tối thiểu này bằng số các phần tử liên hợp khác nhau.
        Các phần tử liên hợp thì có cùng chu kỳ. k
                                                2 −1
       Các đa thức tối giản bậc k là ước của x        +1


                                Trang 251
                         Tóm tắt (tt)
   Một phần tử a có đa thức tối thiểu bậc m thì các tổ hợp tuyến
    tính (với bi ∈ GF(2))
                        b01 + b1a + … + bk - 1ak - 1
    sẽ sinh ra toàn bộ các phần tử của trường GF(2m)
   Một phần tử a có đa thức tối thiểu bậc m và cũng là đa thức
    căn bản thì các lũy thừa của nó sẽ sinh ra toàn bộ các phần tử
    của trường GF(2m).




                            Trang 252
                                Ví dụ
   Xây dựng trường GF(2m) với m = 4.
   Chúng ta kí hiệu 0 là ma trận 0, kí hiệu 1 là ma trận đơn vị (có
    kích thước là 4×4). Lấy phần tử a là ma trận sau
                              ⎡ 0 1 0 0⎤
                              ⎢ 0 0 1 0⎥
                      T4× 4 = ⎢            ⎥
                              ⎢0 0 0 1⎥
                              ⎢            ⎥
                              ⎣ 1 1  0   0 ⎦
    Chúng ta có đa thức tối thiểu của a là f(x) = 1 + x + x4
   Đây là một đa thức căn bản bậc 4. Vì vậy theo ‎Định lý 11.14,
    15 phần tử của GF(24) không tính phần tử 0 sẽ có dạng ai, i = 0,
    1, …, 14 với chú ý a0 = 1.
   Còn theo ‎Định lý 12.12 chúng sẽ có dạng b0 + b1a + b2a2 + b3a3
    trong đó các bi = 0 hoặc 1.
                             Trang 253
                                    Ví dụ (tt)
        Vậy có hai cách để xây dựng trường GF(24) như trên.
        Các bảng sau đây biểu diễn các phần tử khác 0 và khác 1 của
         trường GF(24) theo các dạng: lũy thừa của a (ai), đa thức của a,
         vectơ, dạng ma trận.
       a              a2             a3               a4              a5
       a              a2             a3              1+a            a + a2
     0100            0010           0001             1100           0110
⎡0   1 0 0⎤     ⎡0   0 1 0⎤    ⎡0    0 0 1⎤     ⎡1   1 0 0⎤    ⎡0   1 1 0⎤
⎢0              ⎢0   0 0 1⎥⎥   ⎢1    1 0 0⎥⎥    ⎢0   1 1 0⎥⎥   ⎢0   0 1 1⎥⎥
⎢    0 1 0⎥⎥    ⎢              ⎢                ⎢              ⎢
⎢0   0 0 1⎥     ⎢1   1 0 0⎥    ⎢0    1 1 0⎥     ⎢0   0 1 1⎥    ⎢1   1 0 1⎥
⎢          ⎥    ⎢          ⎥   ⎢           ⎥    ⎢          ⎥   ⎢          ⎥
⎣1   1 0 0⎦     ⎣0   1 1 0⎦    ⎣0    0 1 1⎦     ⎣1   1 0 1⎦    ⎣1   0 1 0⎦

                                    Trang 254
                                             Ví dụ (tt)


       a6                 a7                   a8                      a9               a10
     a2 + a3          1 + a + a3             1 + a2                  a + a3          1 + a + a2
      0011              1101                 1010                    0101              1110
⎡0    0   1    1⎤    ⎡1   1   0   1⎤    ⎡1    1   1      0⎤     ⎡1   0   1    0⎤    ⎡0   1   0   1⎤
⎢1    1   0    1⎥⎥   ⎢1   0   1   0⎥⎥   ⎢0    1   1      1 ⎥⎥   ⎢0   1   0    1⎥⎥   ⎢1   1   1   0 ⎥⎥
⎢                    ⎢                  ⎢                       ⎢                   ⎢
⎢1    0   1    0⎥    ⎢0   1   0   1⎥    ⎢1    1   1      1⎥     ⎢1   1   1    0⎥    ⎢0   1   1   1⎥
⎢                ⎥   ⎢              ⎥   ⎢                   ⎥   ⎢               ⎥   ⎢               ⎥
⎣0    1   0    1⎦    ⎣1   1   1   0⎦    ⎣1    0   1      1⎦     ⎣0   1   1    1⎦    ⎣1   1   1   1⎦



                                             Trang 255
                                Ví dụ (tt)
         a11              a12                a13               a14
     a + a2 + a3    1 + a + a2 + a3      1 + a2 + a3         1 + a3
        0111             1111               1011             1001
    ⎡ 0 1 1 1⎤       ⎡1 1 1 1 ⎤         ⎡1 0 1 1 ⎤      ⎡1    0 0 1⎤
    ⎢ 1 1 1 1⎥       ⎢1 0 1 1 ⎥         ⎢1 0 0 1 ⎥      ⎢1    0 0 0⎥⎥
    ⎢           ⎥    ⎢           ⎥      ⎢           ⎥   ⎢
    ⎢ 1 0 1 1⎥       ⎢1 0 0 1 ⎥         ⎢1 0 0 0⎥       ⎢0    1 0 0⎥
    ⎢           ⎥    ⎢           ⎥      ⎢           ⎥   ⎢           ⎥
    ⎣ 1 0 0 1⎦       ⎣1 0 0 0 ⎦         ⎣ 0 1 0 0⎦      ⎣0    0 1 0⎦
       Chu kỳ, đa thức tối thiểu của các phần tử liên hợp
0   1   a, a2, a4, a8 a3, a6, a12, a9     a5, a10 a7, a14, a13, a11
             15              5               3           15
x 1 + x 1 + x + x4 1 + x + x2 + x3 + x4 1 + x + x2 1 + x3 + x4
                                 Trang 256
              Bài 12 Mã khối tuyến tính
12.1 Giới thiệu
12.2 Các khái niệm và nguyên lý hoạt động
12.3 Vấn đề phát hiện sai và sửa sai
12.4 Một số giới hạn




                         Trang 257
                                Giới thiệu
        Mã khối tuyến tính được xây dựng dựa trên các kết quả của đại
         số tuyến tính là một lớp mã được dùng rất phổ biến trong việc
         chống nhiễu.
   Định nghĩa
        Một mã khối có chiều dài n gồm 2k từ mã được gọi là mã tuyến
         tính C(n, k) nếu và chỉ nếu 2k từ mã hình thành một không gian
         vectơ con k chiều của không gian vectơ n chiều gồm tất cả các
         vectơ n thành phần trên trường GF(2).
        Mã tuyến tính C(n, k) có mục đích mã hoá những khối tin (hay
         thông báo) k bit thành những từ mã n bit. Hay nói cách khác
         trong n bit của từ mã có chứa k bit thông tin.
        Qui ước viết dấu + thay cho dấu ⊕ và dấu + sẽ được hiểu theo
         ngữ cảnh.

                                 Trang 258
        Cách biểu diễn mã – Ma trận sinh
 Mã tuyến tính C(n, k) là một không gian con k chiều của không
  gian vectơ n thành phần, ⇒ ∃ k từ mã độc lập tuyến tính, chẳng
  hạn (g0, g1, ..., gk–1) sao cho mỗi từ mã trong C là một tổ hợp
  tuyến tính của k từ mã này (với ai ∈ {0, 1} ∀ i = 0, 1, ..., k–1)
                      w = a0g0 + a1g1 + ... + ak–1gk–1
 k từ mã này tạo thành một ma trận cấp k × n như sau

          ⎡ g 0 ⎤ ⎡ g 00              g 01    L       g 0( n −1) ⎤
          ⎢ g ⎥ ⎢ g                   g       L       g              ⎥
                1 ⎥ ⎢        10         11              1( n −1) ⎥
 Gk × n = ⎢          =
          ⎢ M ⎥ ⎢ M                     M                  M         ⎥
          ⎢        ⎥ ⎢                                               ⎥
                         g
          ⎣ g k −1 ⎦ ⎢⎣ ( k −1)0   g ( k −1)1 L    g ( k −1)( n −1) ⎥⎦

   Với gi = (gi0, gi1, …, gi(n–1)), với i = 0, 1, …, k–1.
                               Trang 259
                         Cách mã hóa
   Nếu u = (a0, a1, …, ak–1) là thông tin cần được mã hoá thì từ mã
    w tương ứng với u được ta bằng cách lấy u nhân với G
                      w = u × G = (a0, a1, …, ak–1)
    hay
                     w = a0g0 + a1g1 + … + ak–1gk–1
   Vì các từ mã tương ứng với các thông báo được sinh ra bởi G
    theo cách trên nên G được gọi là ma trận sinh của bộ mã.




                             Trang 260
                               Ví dụ
   Cho ma trận sinh của một mã tuyến tính C(7, 4) sau
                      ⎡ g 0 ⎤ ⎡1   1 0 1 0 0 0⎤
                      ⎢ g ⎥ ⎢1     0 1 1 1 0 0⎥⎥
              G4× 7 = ⎢ ⎥ = ⎢
                          1
                      ⎢ g 2 ⎥ ⎢0   1 0 0 0 1 1⎥
                      ⎢ ⎥ ⎢                    ⎥
                      ⎣ g 3 ⎦ ⎣1   0 1 0 0 0 1⎦
   Nếu u = (1101) là thông tin cần mã hoá thì từ mã tương ứng là
               w = 1.g0 + 1.g1 + 0.g2 + 1.g3 = (1100101)
   Bất kỳ k từ mã độc lập tuyến tính nào cũng có thể được dùng để
    làm ma trận sinh cho bộ mã.
   Một bộ mã tuyến tính (hay còn gọi là không gian mã) có thể có
    nhiều ma trận sinh khác nhau cùng biểu diễn.
   Mỗi ma trận sinh tương ứng với một cách mã hóa khác nhau.
                            Trang 261
                            Cách giải mã
    Lấy ma trận sinh như ở trong ví dụ trên.
   u = (a0, a1, a2, a3) là thông báo, w = (b0, b1, b2, b3, b4, b5, b6) là

     từ mã tương ứng.
   Chúng ta có hệ phương trình sau liên hệ giữa u và w.

                       w=u×G ⇔              b0 = a0 + a1 + a3        (1)
                                            b1 = a0 + a2             (2)
        ⎡ g 0 ⎤ ⎡1 1 0 1 0 0 0⎤             b2 = a1 + a3             (3)
        ⎢ g ⎥ ⎢1 0 1 1 1 0 0⎥
G4× 7 = ⎢ ⎥ = ⎢                    ⎥
            1                               b3 = a0 + a1             (4)
        ⎢ g 2 ⎥ ⎢0 1 0 0 0 1 1⎥
        ⎢ ⎥ ⎢                      ⎥        b4 = a1                  (5)
        ⎣ g 3 ⎦ ⎣1 0 1 0 0 0 1 ⎦            b5 = a2                  (6)
                                            b6 = a2 + a3             (7)

                                Trang 262
                    Cách giải mã (tt)
 Chọn bốn phương trình đơn giản nhất để giải các ai theo các bj.
  Chẳng hạn các phương trình (4), (5), (6), (7) chúng ta giải được
         ⎡ g 0 ⎤ ⎡1 1 0 1 0 0 0⎤          a0 = b3 + b4
         ⎢ g ⎥ ⎢1 0 1 1 1 0 0⎥
         ⎢   1⎥ ⎢                  ⎥      a1 = b4
 G4× 7 =        =
         ⎢ g 2 ⎥ ⎢0 1 0 0 0 1 1⎥          a2 = b5
         ⎢ ⎥ ⎢                     ⎥
           g
         ⎣ 3⎦ ⎣    1 0 1  0 0 0  1 ⎦      a3 = b5 + b6
 Hệ phương trình trên được gọi là hệ phương trình giải mã.

 Có thể có nhiều hệ phương trình giải mã khác nhau nhưng sẽ

  cho kết quả như nhau.
               w = 1001011    ⇒       u=?
               w = 0101110    ⇒       u=?

                           Trang 263
                Mã tuyến tính hệ thống
   Một mã tuyến tính C(n, k) được gọi là mã tuyến tính hệ thống
    nếu mỗi từ mã có một trong hai dạng sau
   Dạng 1: Từ mã bao gồm phần thông tin k bit đi trước và phần
    còn lại (gồm n – k bit) đi sau (phần này còn được gọi là phần dư
    thừa hay phần kiểm tra).

               k bit thông tin n – k bit kiểm tra

   Dạng 2: Ngược của dạng 1, từ mã bao gồm phần kiểm tra đi
    trước và phần thông tin đi sau.

               n – k bit kiểm tra k bit thông tin


                            Trang 264
                            Ma trận sinh hệ thống
                             ⎡                                                ⎤
                             ⎢1 0 L 0 P         P         L      P            ⎥
                             ⎢           00      01               0(n − k −1) ⎥

              [         ]    ⎢0 1 L 0 P10
Gk ×n = I kk | Pk (n − k ) = ⎢
                                         M
                                                P11 L P1(n − k −1) ⎥
                                                 M                    M
                                                                              ⎥
                             ⎢M M      M                                      ⎥
                             ⎢0 0 L 1P(k −1)0 P(k −1)1 L P(k −1)(n − k −1) ⎥
                             ⎢142
                                4 43  4 1444444      424444444              3⎥
                             ⎢⎣  k ×k               k × (n − k )              ⎥⎦
      Ví dụ
               ⎡1   0 0 0 1 1 0⎤                   Mã hóa
               ⎢0   1 0 0 0 1 1⎥⎥        u = 1101 ⇒ w = u × Ght = 1101000
Ght ( 4×7 )   =⎢                                   Giải mã
               ⎢0   0 1 0 1 1 1⎥
               ⎢                ⎥        w = 0110100 ⇒ u = 0110
               ⎣0   0 0 1 1 0 1⎦
                                    Trang 265
                                    Ví dụ
   Dùng các phép biến đổi sơ cấp biến đổi ma trận sinh sau thành
    ma trận sinh hệ thống:
               ⎡ g 0 ⎤ ⎡1   1 1 0 0 1 0⎤
               ⎢ g ⎥ ⎢1     0 0 1 1 1 0⎥⎥
      G4×7   = ⎢ 1⎥ = ⎢
               ⎢ g 2 ⎥ ⎢0   0 0 1 1 0 1⎥
               ⎢ ⎥ ⎢                    ⎥
               ⎣ g 3 ⎦ ⎣1   0 1 0 1 0 1⎦

                ⎡ g 0 + g1 + g 2 + g 3 ⎤ ⎡1   1 0 0 1 0 0⎤
                ⎢          g           ⎥ ⎢0   0 0 1 1 0 1 ⎥⎥
     G ' 4× 7 = ⎢            2         ⎥=⎢
                ⎢       g1 + g 2       ⎥ ⎢1   0 0 0 0 1 1⎥
                ⎢                      ⎥ ⎢                 ⎥
                ⎣          g 3         ⎦ ⎣1   0 1 0 1 0 1⎦
                                              1 4 2   3

                                 Trang 266
                                  Ví dụ
   Dùng các phép biến đổi sơ cấp biến đổi các ma trận sinh sau
    thành ma trận sinh hệ thống.

            ⎡1   1 0 1 0 0 1⎤                  ⎡1   1 0 1 0 0 1⎤
            ⎢0   1 1 0 1 0 1 ⎥⎥                ⎢1   0 1 0 1 0 1 ⎥⎥
    G4×7   =⎢                        G 4× 7   =⎢
            ⎢0   0 1 1 0 0 1⎥                  ⎢1   0 0 1 1 0 0⎥
            ⎢                 ⎥                ⎢                 ⎥
            ⎣1   0 0 1 0 1 0⎦                  ⎣1   0 0 1 0 1 1⎦

   Không phải mọi ma trận sinh đều có thể biến đổi thành ma trận
    sinh hệ thống.




                             Trang 267
                              Ví dụ (tt)
   Hãy thực hiện phép mã hóa và giải mã trên ma trận sinh sau.
                         ⎡1   1 0 0 1 0 0⎤
                         ⎢1   0 1 0 1 0 1⎥⎥
                G4 × 7 = ⎢
                         ⎢0   0 0 1 1 0 1⎥
                         ⎢                ⎥
                         ⎣1   0 0 0 0 1 1⎦

    u = a1 a2 a3 a4       thì w = b1 b2 b3 b4 b5 b6 b7



   Mã hóa           u = (1101) ⇒ w = (1110010)
   Giải mã          w = (1011000) ⇒ u = (0110)
                              Trang 268
                      Phát hiện sai và sửa sai
        Nguyên lý phát hiện sai: Kiểm tra xem tổ hợp nhận có phải là
         từ mã hay không, nếu không thì tổ hợp nhận là sai.
        Nguyên lý sửa sai: Kiểm tra xem tổ hợp nhận có khoảng cách
         Hamming gần với từ mã nào nhất, thì đó chính là từ mã đúng
         đã được phát đi.
        Nguyên lý này được gọi là nguyên lý khoảng cách Hamming
         tối thiểu.
   Không gian bù trực giao
        Cho S là một không gian con k chiều của không gian V n chiều.
         Gọi Sd là tập tất cả các vectơ v trong V sao cho ∀ u ∈ S, u × v =
         0 (phép nhân vô hướng của hai vectơ). Sd được chứng minh là
         một không gian con của V và có số chiều là n – k. Sd được gọi là
         không gian bù trực giao của S và ngược lại.

                                  Trang 269
                         Cách phát hiện sai
   Hệ quả
        Mỗi ma trận G bất kỳ kích thước k × n với k hàng độc lập tuyến
         tính luôn tồn tại ma trận H kích thước (n – k) × n với (n – k)
         hàng độc lập tuyến tính sao cho G × HT = 0, trong đó HT là ma
         trận chuyển vị của ma trận H.
        Nói cách khác các vectơ hàng của H đều trực giao với các vectơ
         hàng của G.
   Cách phát hiện sai
        Nếu v là một từ mã được sinh ra từ ma trận sinh G có ma trận
         trực giao tương ứng là H thì
                                    v × HT = 0
        Ngược lại nếu
                                    v × HT = 0
         thì v là một từ mã.
                                 Trang 270
                          Ma trận kiểm tra
   Ma trận kiểm tra
        Ma trận kiểm tra của một bộ mã có ma trận sinh Gk×n là ma trận
         H có kích thước (n – k) × n sao cho
                                    G × HT = 0
   Syndrome – vectơ sửa sai (corrector)
        v × HT được gọi là syndrome hay vectơ sửa sai của v và được kí
         hiệu là s(v). v là từ mã khi và chỉ khi s(v) = 0.
   Ví dụ
        Tìm ma trận kiểm tra ứng với ma trận sinh sau.
                           ⎡1 1 0 1 0 0 0⎤
                           ⎢1 0 1 1 1 0 0⎥
                  G 4× 7 = ⎢                    ⎥
                           ⎢0 1 0 0 0 1 1⎥
                           ⎢                    ⎥
                           ⎣ 1 0 1  0  0   0  1 ⎦
                                 Trang 271
                   Ma trận kiểm tra (tt)
   H có kích thước 3 × 7.
   Gọi h = (a0, a1, a2, a3, a4, a5, a6) là một hàng bất kỳ của H. h
    trực giao với mọi hàng của G nên chúng ta có hệ bốn phương
    trình sau
               ⎡1 1 0 1 0 0 0⎤
               ⎢1 0 1 1 1 0 0⎥             a0 + a1 + a3      =0
       G4× 7 = ⎢                    ⎥      a0 + a2 + a3 + a4 = 0
               ⎢0 1 0 0 0 1 1⎥             a1 + a5 + a6      =0
               ⎢                    ⎥
               ⎣1 0 1 0 0 0 1 ⎦            a0 + a2 + a6      =0
   Vấn đề là tìm được 3 vectơ h độc lập tuyến tính là nghiệm của
    hệ phương trình trên.
   Chú ý, hệ phương trình trên có thể cho phép chúng ta giải bốn
    biến theo ba biến còn lại. Chẳng hạn chúng ta giải a3, a4, a5, a6
    theo a0, a1, a2 như sau.


                             Trang 272
                         Ma trận kiểm tra (tt)
                              a3 = a0 + a1
                              a4 = a1 + a2
                              a5 = a0 + a1 + a2
                              a6 = a0 + a2
        Cho (a0, a1, a2) lần lượt các giá trị (1, 0, 0), (0, 1, 0), (0, 0, 1)
         (độc lập tuyến tính với nhau), ta xác định được (a3, a4, a5, a6)
         lần lượt như sau (1, 0, 1, 1), (1, 1, 1, 0), (0, 1, 1, 1).
        Vậy H là
                              ⎡1 0 0 1 0 1 1 ⎤
                    H 3× 7 = ⎢⎢0 1 0 1 1 1 0⎥⎥
                              ⎢⎣0 0 1 0 1 1 1⎥⎦
   Chú ý
        Có thể tồn tại nhiều ma trận kiểm tra khác nhau của cùng một
         bộ mã và chúng đều có khả năng kiểm tra như nhau.
                                     Trang 273
                        Ma trận kiểm tra (tt)
   Bổ đề 12.1
        Nếu ma trận sinh hệ thống của một mã tuyến tính hệ thống có
         dạng                Gk×n = [Ikk | Pk(n–k)]

         thì             H(n–k)×n = [Pk(n–k)T | I(n–k)(n–k)]
         là một ma trận kiểm tra của mã.
        Tương tự nếu ma trận sinh có dạng
                                    Gk×n = [Pk(n–k) | Ikk]
         thì ma trận kiểm tra có dạng
                               H(n–k)×n = [I(n–k)(n–k) | Pk(n–k)T]
         trong đó I(n–k)(n–k) là ma trận đơn vị kích thước (n–k)×(n–k), còn
         Pk(n–k)T là ma trận chuyển vị của ma trận Pk(n–k).


                                   Trang 274
                                   Chứng minh
                 ⎡                                                                   ⎤
                 ⎢1 0 L 0 P                    P          L       P                  ⎥
                 ⎢                        00     01                0( n − k −1) ⎥
                 ⎢0 1 L 0 P10                   P11       L       P1( n − k −1) ⎥
     Gk × n = ⎢                                                                      ⎥
                 ⎢M M              M M           M                       M           ⎥
                 ⎢0 0 L 1 P( k −1)0 P( k −1)1 L P( k −1)( n − k −1) ⎥
                 ⎢ 142 4 43     4 1444444            424444444                  3⎥
                 ⎢⎣       k ×k                      k × (n − k )                     ⎥⎦
                  ⎡                                                                   ⎤
                  ⎢ P                   P10   L       P(k −1)0 1 0 L 0⎥
                  ⎢      00                                                           ⎥
                  ⎢ P01                 P11   L        P(k −1)1 0 1 L 0⎥
H ( n − k )× n = ⎢                                                                    ⎥
                  ⎢      M               M                 M      M    M           M  ⎥
                  ⎢ P0(n − k −1) P1(n − k −1) L P(k −1)(n − k −1) 0 0 L 1⎥
                  ⎢144444444244444444                            3142  4 43    4⎥
                  ⎢⎣            ( n − k )× k                       (n − k )×(n − k ) ⎥⎦
                                        Trang 275
                          Chứng minh (tt)
   Ta chứng minh
                               G × HT = 0
   Chứng minh điều này ⇔ việc chứng minh
             gi × hj = 0 ∀ i = 0, …, k–1, j = 0, …, n–k–1
    trong đó
                 gi = (gi0, …, gi(n–1)) là hàng i của G còn
                 hj = (hj0, …, hj(n–1)) là hàng j của ma trận H.
    Thật vậy
                         n −1         k −1            n − k −1
            gi × h j =   ∑ g is h js = ∑ g is h js + ∑ g is h js
                         s=0          s=0              s=k
                    = h ji + g i ( k + j ) = Pij + Pij = 0


                                 Trang 276
                                    Ví dụ
   Tìm ma trận H cho các ma trận sinh sau
               ⎡1   0 0 0 1 1 0⎤               ⎡1   1 0 0 1 0 0⎤
               ⎢0   1 0 0 0 1 1⎥⎥              ⎢1   0 1 0 1 0 1⎥⎥
Ght ( 4×7 )   =⎢                       G4×7   =⎢
               ⎢0   0 1 0 1 1 1⎥               ⎢0   0 0 1 1 0 1⎥
               ⎢                ⎥              ⎢                ⎥
               ⎣0   0 0 1 1 0 1⎦               ⎣1   0 0 0 0 1 1⎦

               ⎡1   0 0 0 1 1 0⎤
               ⎢1   1 0 0 1 0 1⎥⎥
    G4×7      =⎢
               ⎢0   0 0 1 1 0 1⎥
               ⎢                ⎥
               ⎣1   0 1 0 0 0 1⎦


                               Trang 277
           Khả năng chống nhiễu tương đương
        Hai mã tuyến tính C(n, k) được gọi là có khả năng chống nhiễu
         tương đương nếu chúng có cùng khoảng cách Hamming.
   Bổ đề 12.2
        Nếu hoán vị hai cột của một ma trận sinh sẽ tạo ra một bộ mã
         mới có khả năng chống nhiễu tương đương với bộ mã cũ. Nói
         cách khác việc hoán vị hai cột của ma trận sinh không làm thay
         đổi khả năng chống nhiễu.
   Bổ đề 12.3
        Khoảng cách Hamming của một mã tuyến tính bằng trọng số
         nhỏ nhất khác 0 của bộ mã.



                                 Trang 278
                                    Bổ đề
   Bổ đề 12.4
        Gọi H là ma trận kiểm tra của một mã tuyến tính, nếu một từ
         mã có trọng số d thì tồn tại d cột của H có tổng bằng 0.
   Hệ quả
        Nếu trong ma trận kiểm tra H của một mã tuyến tính số cột phụ
         thuộc tuyến tính nhỏ nhất là d thì khoảng cách Hamming của bộ
         mã đó bằng d.
   Ví dụ 12.5
                         ⎡1 0 0 1 0 1 1 ⎤          d = 3 (3, 4, 6)
               H 3× 7 = ⎢⎢0 1 0 1 1 1 0⎥⎥
                         ⎢⎣0 0 1 0 1 1 1⎥⎦
                                 Trang 279
                               Cách sửa sai
   Vectơ lỗi
        Là vectơ biểu diễn các vị trí lỗi giữa từ mã truyền và tổ hợp
         nhận, mỗi vị trí lỗi được biểu diễn bằng bit 1, còn lại là 0.
        Nếu từ mã truyền là w, vectơ lỗi là e và vectơ nhận là v thì
                                      v=w+e
                                      e=v+w
                                      w=e+v
   Ví dụ
        w = 1011011, e = 0010100 ⇒ v = w + e = 1001111.
        w = 0110010, v = 0010011 ⇒ e = w + v = 0100001.
        v = 1011001, e = 0010010 ⇒ w = v + e = 1001011.
                                  Trang 280
                        Tập giải mã - coset
        Cho S là một không gian con các từ mã của không gian V, coset
         của một phần tử z ∈ V đối với S được kí hiệu là z + S và được
         định nghĩa như sau
                             z + S = {z + w: w ∈ S}
   Bổ đề 12.5
      Tập coset z + S có các tính chất sau.
     (1) z ∈ z + S.
     (2) Nếu z ∈ S thì z + S = S.
     (3) Nếu v ∈ z + S thì v + S = z + S.
     (4) Nếu v ∉ z + S thì v + S và z + S rời nhau.


                                 Trang 281
                               Sơ đồ giải mã
        Với mỗi vectơ nhận v chúng ta sẽ có một tập coset tương ứng là
         v + S.
        Trong tập này chọn phần tử có trọng số nhỏ nhất, chẳng hạn là
         z. Phần tử này thường được gọi là coset leader.
        Thông báo từ mã được truyền chính là w = v + z.
   Bổ đề 12.6
        Các phần tử của một tập coset có cùng một syndrome như nhau.
         Các tập coset khác nhau có các syndrome khác nhau.
        e = (a1, a2, ..., an), các cột của H lần lượt bằng h1, h2, ..., hn thì
                                            n
                     s (e) = e × H = ∑ ai hi = ∑ ai hi
                                   T

                                           i =1    ai ≠ 0


                                       Trang 282
                             Sơ đồ giải mã (tt)
   Nghĩa là s(e) bằng tổng những cột ở những vị trí tương ứng với
    những vị trí bằng 1 của e.
   Nếu vị trí lỗi sai là 3 thì syndrome của vectơ nhận sẽ là cột số 3
    của H.
            ⎡1   1   0   1   0   0   0⎤
            ⎢1                                         ⎡1 0 0 1 0 1 1 ⎤
                                     0⎥⎥
                                             H 3× 7 = ⎢⎢0 1 0 1 1 1 0⎥⎥
                 0   1   1   1   0
    G4× 7 = ⎢
            ⎢0   1   0   0   0   1   1⎥
            ⎢                          ⎥               ⎢⎣0 0 1 0 1 1 1⎥⎦
            ⎣1   0   1   0   0   0   1⎦

   Tìm vị trí lỗi sai của các vectơ nhận sau đây
    v = 0010011 ⇒ s(v) = ?           ⇒e=?         ⇒w=?
    v = 0101101 ⇒ s(v) = ?           ⇒e=?         ⇒w=?

                                      Trang 283
                    Mã tuyến tính Hamming
       Mã tuyến tính Hamming là mã có ma trận H có tính chất giá trị của cột hi
        bằng i (i = 1, 2, ...)

                              ⎡0 0 0 1 1 1 1⎤
                    H 3× 7 = ⎢⎢0 1 1 0 0 1 1⎥⎥
                              ⎢⎣1 0 1 0 1 0 1⎥⎦
   Bổ đề 12.7
      Các mã tuyến tính Hamming đều có khoảng cách Hamming d = 3. Vì vậy
       có thể phát hiện sai 2 bit và sửa sai 1 bit.
    Mã Hamming cho phép sửa sai 1 bit một cách đơn giản như sau:
    1. Tính syndrome s(v) của vectơ nhận.
    2. Đổi chuỗi nhị phân tương ứng ra giá trị thập phân, kết quả đổi chính là vị
       trí lỗi sai đã xảy ra.
    3. Sửa sai ở vị trí lỗi sai tương ứng.

                                    Trang 284
     Ma trận sinh của mã tuyến tính Hamming
   Xét mã tuyến tính Hamming C(7, 4) có các bit thông tin nằm ở
    các vị trí 3, 5, 6, 7. Hãy xác định ma trận sinh G của bộ mã.
   Gọi w = (a1, a2, a3, a4, a5, a6, a7) là một từ mã. Chúng ta có hệ
    phương trình sau được dẫn ra từ công thức w × HT = 0.
                            a4 + a5 + a6 + a7 = 0
                            a2 + a3 + a6 + a7 = 0
                            a1 + a3 + a5 + a7 = 0
   Từ đây suy ra công thức tính các bit kiểm tra a1, a2, a4 theo các
    bit thông báo a3, a5, a6, a7 như sau
                              a1 = a3 + a5 + a7
                              a2 = a3 + a6 + a7
                              a4 = a5 + a6 + a7
                             Trang 285
          Ma trận sinh của mã tuyến tính Hamming

       b1 b2 b3 b4                     a1 a2 a3 a4 a5 a6 a7
    u= 1 0 1 0             thì w =     1 0 1 1 0 1 0


                            ⎡1   1 1 0 0 0 0⎤
                            ⎢1   0 0 1 1 0 0⎥⎥
                    G4× 7 = ⎢
                            ⎢0   1 0 1 0 1 0⎥
                            ⎢                ⎥
                            ⎣1   1 0 1 0 0 1⎦
   Ví dụ
        Xét mã tuyến tính Hamming C(7, 4) có các bit thông tin nằm ở
         các vị trí 1, 2, 3, 4. Hãy xác định ma trận sinh G của bộ mã.
                                  Trang 286
                     Bài 13 Mã vòng
13.1 Giới thiệu
13.2 Các tính chất của mã vòng
13.3 Ma trận sinh và ma trận kiểm tra của mã
13.4 Mã BCH




                          Trang 287
                                Giới thiệu
   Định nghĩa
        Một mã tuyến tính C(n, k) được gọi là mã vòng nếu w =
         a0a1…an–2an–1 là một từ mã thì v = an–1a0a1…an–2 cũng là một
         từ mã.
        Nghĩa là dịch vòng (sang trái hay phải) một từ mã thì kết quả
         cũng là một từ mã. Ở đây qui ước dịch phải.
   Đa thức mã
        Nếu w = a0a1…an–2an–1 là một từ mã thì w(x) = a0 + a1x + … +
         an–2xn - 2 + an–1xn - 1 là đa thức mã tương ứng với từ mã w.
   Ví dụ
        Bảng sau đây trình bày một mã vòng C(7, 4).

                                 Trang 288
                                    Ví dụ
 m       w            w(x)             m     w          w(x)

0000   0000000   0                  0001   0001101
                                                 x3 + x4 + x6
1000   1101000   1 + x + x3         1001   1100101
                                                 1 + x + x4 + x6
0100   0110100   x + x2 + x4        0101   0111001
                                                 x + x2 + x3 + x6
1100   1011100   1 + x2 + x3 + x4   1101   1010001
                                                 1 + x2 + x6
0010   0011010   x2 + x3 + x5       0011   0010111
                                                 x2 + x4 + x5 + x6
1010   1110010   1 + x + x2 + x5    1011   1111111
                                                 1 + x + x2 + x3 +
                                                    x4 + x5 + x6
0110 0101110 x + x3 + x4 + x5       0111 0100011 x + x5 + x6
1110 1000110 1 + x4 + x5            1111 1001011 1 + x3 + x5 + x6

                               Trang 289
                              Giới thiệu (tt)
   w(i), w(i)(x)
        w(i) là từ mã do dịch từ mã w i bit, và w(i)(x) là đa thức mã
         tương ứng của w(i). w(0) chính là w.
           i      w(i)                    w(i)(x)
           0 1101000 1 + x + x3
           1 0110100 x + x2 + x4 = x * (1 + x + x3) = x * w(x)
           2 0011010 x2 + x3 + x5 = x2 (1 + x + x3) = x2 * w(x)
           3 0001101 x3 + x4 + x6 = x3 (1 + x + x3) = x3 * w(x)
           4 1000110 1 + x4 + x5 = x4 + x5 + x7 mod 7
           5 0100011 x + x5 + x6 = x5 + x6 + x8 mod 7
           6 1010001 1 + x2 + x6 = x6 + x7 mod 7 + x9 mod 7
                                   Trang 290
                               Giới thiệu (tt)
        w(i)(x) = xi * w(x) tuy nhiên nếu w(i)(x) có xp với p ≥ n thì xp
         được thay bằng xp mod n.
        Mặc khác trên trường GF(2) chúng ta có
                 xn + j = xj * (xn + 1) + xj hay xn + j mod (xn + 1) = xj
   Bổ đề 13.1
                         w(i)(x) = [xi * w(x)] mod (xn + 1)




                                   Trang 291
                   Các tính chất của mã vòng
   Định lý 13.1
        Đa thức mã khác 0 có bậc nhỏ nhất là duy nhất. Hay nói cách
         khác không tồn tại hai đa thức mã khác 0, khác nhau và cùng có
         bậc nhỏ nhất.
   Chứng minh
        Giả sử ∃ hai đa thức mã khác nhau, cùng có bậc nhỏ nhất là r, 0
         < r < n.
                       g(x) = g0 + g1x + … + gr–1xr - 1 + xr
                         f(x) = f0 + f1x + … + fr–1xr - 1 + xr
        Từ đây suy ra đa thức mã g(x) + f(x) có bậc nhỏ hơn r, mâu
         thuẫn. Chứng minh hoàn tất.

                                 Trang 292
                 Các tính chất của mã vòng (tt)
        Kí hiệu đa thức mã có bậc nhỏ nhất là g(x)
                       g(x) = g0 + g1x + … + gr–1xr - 1 + xr
   Định lý 13.2
        Hệ số tự do g0 của g(x) phải bằng 1.
   Chứng minh
        Giả sử g0 = 0. Suy ra
                        g(x) = x * (g1 + … + gr–1xr - 2 + xr - 1)
        Đặt f(x) = (g1 + … + gr–1xr - 2 + xr - 1), suy ra f(x) cũng là một đa
         thức mã. Vì f(x) tương ứng với từ mã được dịch trái 1 bit hay
         dịch phải (n – 1) bit từ từ mã ứng với g(x).
        Mà bậc của f(x) bằng r – 1 < r mâu thuẫn với định nghĩa của
         g(x).
                                    Trang 293
                 Các tính chất của mã vòng (tt)
   Định lý 13.3
        Một đa thức v(x) trên trường GF(2) có bậc ≤ n – 1 là đa thức
         mã nếu và chỉ nếu nó là một bội số của g(x). Tức là nó có thể
         viết v(x) = q(x) * g(x).
   Chứng minh
        Chiều thuận
        Nếu v(x) = q(x) * g(x) và có bậc ≤ n – 1 thì v(x) là đa thức mã.
                                         ⎛ p        ⎞
                                                                  (           )
                                                                   p
           v ( x ) = q ( x ) * g ( x ) = ⎜ ∑ qi x i ⎟ * g ( x ) = ∑ qi x i * g ( x )
                                         ⎜          ⎟
                                         ⎝ i = 0    ⎠             i=0
         với p là bậc của q(x) và p + r ≤ n – 1. Do xi * g(x) với 0 ≤ i ≤ p
         là đa thức mã, nên v(x) là đa thức mã vì nó là một tổ hợp tuyến
         tính của các đa thức mã.
                                      Trang 294
           Các tính chất của mã vòng (tt)
   Chiều ngược
   Nếu v(x) là đa thức mã thì chia v(x) cho g(x)
                          v(x) = q(x) * g(x) + r(x)
    trong đó r(x) là đa thức dư và có bậc nhỏ hơn bậc của g(x).
    Đối với các đa thức trên trường GF(2) chúng ta có thể suy ra
                          r(x) = q(x) * g(x) + v(x)
    Nên r(x) là một đa thức mã. Theo định nghĩa của g(x) suy ra
    r(x) = 0. Chứng minh hoàn tất.
   Từ định lý này chúng ta gọi g(x) là đa thức sinh, vì từ g(x) có
    thể sinh ra tất cả các đa thức mã khác.


                             Trang 295
                Các tính chất của mã vòng (tt)
   Định lý 13.4
        Đa thức sinh của một mã vòng C(n, k) có bậc r = n – k.
   Chứng minh
        Mỗi đa thức mã w(x) là một bội số của g(x)
                                   w(x) = q(x) * g(x)
        Có 2k từ mã nên có 2k đa thức q(x). Suy ra bậc của q(x) là ≤ k –
         1. Suy ra bậc của g(x) là n – k.
        Từ định lý này đa thức sinh g(x) có thể được biểu diễn như sau
                        g(x) = g0 + g1x + … + gn – kxn – k
         trong đó g0 = gn – k = 1.


                                  Trang 296
                Các tính chất của mã vòng (tt)
   Định lý 13.5
        Đa thức sinh của mã vòng C(n, k) là một ước số của xn + 1.
   Chứng minh
        Bổ đề 13.1 suy ra
                          g(i)(x) = [xi * g(x)] mod (xn + 1)
                        ⇔ xi * g(x) = q(x) * (xn + 1) + g(i)(x)
         Chọn i = k ⇒ q(x) = 1 tức
                             xk * g(x) = (xn + 1) + g(i)(x)
                            ⇒ xn + 1 = xk * g(x) + g(i)(x)
         Do g(i)(x) là một đa thức mã nên g(i)(x) là một bội của g(x), ⇒
         xn + 1 là một bội của g(x). Chứng minh hoàn tất.
                                  Trang 297
                Các tính chất của mã vòng (tt)
   Định lý 13.6
        Nếu g(x) là một đa thức có bậc (n – k) và là ước số của (xn + 1)
         thì g(x) sinh ra mã vòng C(n, k), hay nói cách khác g(x) là đa
         thức sinh của một mã vòng C(n, k) nào đó.
   Chứng minh
        Xét k đa thức g(x), x * g(x), …, xk – 1 * g(x).
         Các đa thức này đều có bậc ≤ n – 1.
         Gọi v(x) là một tổ hợp tuyến tính của k đa thức này với các hệ
         số ai ∈ GF(2).
                 v(x) = a0g(x) + a1x * g(x) + … + ak – 1xk – 1 * g(x)
         v(x) là một đa thức có bậc ≤ n – 1 và là bội số của g(x).

                                  Trang 298
           Các tính chất của mã vòng (tt)
   Có tất cả 2k tổ hợp tuyến tính v(x) khác nhau và tạo nên một
    không gian tuyến tính của các đa thức mã với g(x), x * g(x), …,
    xk – 1 * g(x) là các đa thức làm cơ sở.
    Chúng ta chứng minh rằng bộ mã tương ứng với không gian
    này là mã vòng.
    Gọi
                       w(x) = b0 + b1x + … + bn – 1xn – 1
    là một đa thức của không gian.
    Chúng ta chứng minh
                w(1)(x) = bn – 1 + b0x + b1x2 + … + bn – 2xn – 1
    cũng là một đa thức của không gian.

                            Trang 299
           Các tính chất của mã vòng (tt)
   Theo Bổ đề 13.1 chúng ta có
                    w(1)(x) = [x * w(x)] mod (xn + 1)
    Dựa vào biểu diễn của v(x) và w(1)(x) chúng ta suy ra
                    x * w(x) = bn – 1(xn + 1) + w(1)(x)
    Do v(x) và (xn + 1) đều là bội của g(x) nên w(1)(x) cũng là bội
    của g(x). Suy ra w(1)(x) cũng là đa thức mã. Hoàn tất chứng
    minh.




                             Trang 300
                               Ma trận sinh
                ⎡ 6444n4−7  + 14448 64444
                           k4                         k7  −4   8⎤
                                                           1 444
                ⎢g   g1 g 2 L g n −k        0         0 L      0 ⎥
                ⎢  0
                                                                  ⎥
                ⎢ 0 g 0 g1 L g n − k −1 g n − k       0 L      0 ⎥
    G k ×n   = ⎢⎢ 0  0 g 0 L g n − k − 2 g n − k −1 g n − k L  0 ⎥⎥
                ⎢M   M   M   M    M          M        M      M M ⎥
                ⎢                                                 ⎥
                ⎢0   0 L 0       g0        g1        g 2 L g n−k ⎥
                ⎢⎣                                                ⎥⎦
   Ví dụ
        Tìm một mã vòng C(7, 4).
        Theo các tính chất của mã vòng suy ra đa thức sinh của mã có
         bậc bằng 3 và là một ước số của x7 + 1. Phân tích đa thức này ra
         thừa số chúng ta được
                                  Trang 301
                                  Ví dụ
               x7 + 1 = (1 + x)(1 + x + x3)(1 + x2 + x3)
   Chọn chẳng hạn
                          g(x) = (1 + x + x3)

                          ⎡1    1 0 1 0 0 0⎤
                          ⎢0    1 1 0 1 0 0⎥⎥
                  G4×7   =⎢
                          ⎢0    0 1 1 0 1 0⎥
                          ⎢                 ⎥
                          ⎣0    0 0 1 1 0 1⎦




                               Trang 302
                        Mã vòng dạng hệ thống
           Từ dạng hệ thống loại 1 chúng ta có thể dịch vòng k bit để biến
            đổi sang dạng hệ thống loại 2 và ngược lại.

        ⎡1     1 0 1 0 0 0⎤                                ⎡1   0   0   0   1   1   0⎤
        ⎢0     1 1 0 1 0 0⎥⎥                               ⎢0   1   0   0   0   1   1⎥⎥
G4×7   =⎢                                   Ght ( 4×7 )   =⎢
        ⎢0     0 1 1 0 1 0⎥                                ⎢0   0   1   0   1   1   1⎥
        ⎢                  ⎥                               ⎢                          ⎥
        ⎣0     0 0 1 1 0 1⎦                                ⎣0   0   0   1   1   0   1⎦
      Mã hóa thành từ mã hệ thống
           u(x) là thông báo, w(x) là từ mã hệ thống loại 2 tương ứng.
                             xn–k * u(x) = q(x) * g(x) + a(x)
                        w(x) = xn–k * u(x) + a(x) = q(x) * g(x)
                                     Trang 303
                               Ví dụ
   Cho mã vòng C(7, 4) có ma trận sinh là g(x) = (1 + x + x3). Hãy
    mã hoá thông báo u = 1010 thành từ mã hệ thống dạng 2.
                               u(x) = 1 + x2.
    Nhân u(x) với xn–k = x3 rồi chia cho g(x) chúng ta được.
              x3 * (1 + x2) = x3 + x5 = x2 * (1 + x + x3) + x2
   Từ đây suy ra
                            w(x) = x2 + x3 + x5
                               w = 0011010
    là từ mã hệ thống dạng 2 tương ứng với u.




                            Trang 304
                  Ma trận kiểm tra của mã vòng
      Có một cách khác để tìm ma trận kiểm tra của mã vòng
                              xn + 1 = g(x) * h(x)
      h(x) được gọi là đa thức đối ngẫu của g(x). h(x) có bậc k
                          h(x) = h0 + h1x + … + hkxk
      Ma trận sau là một ma trận kiểm tra của mã vòng
                  ⎡ 6444    k7
                            4 + 14444        8 644 −7
                                                  n4   − 144
                                                      k4    8⎤
                   ⎢h h      h       L       h  0  0    L   0 ⎥
                   ⎢ k k −1   k −2            0
                                                              ⎥
                   ⎢ 0 hk hk −1 L h1 h0            0 L 0⎥
H ( n − k )×n   = ⎢⎢ 0 0      hk L h2 h1           h0 L 0 ⎥⎥
                   ⎢M   M      M      M M       M   M     M M⎥
                   ⎢                                          ⎥
                   ⎢0  0      L 0 hk hk −1 hk − 2 L h0 ⎥
                  ⎣⎢               Trang 305                  ⎥⎦
                                Ví dụ
   Cho mã vòng C(7, 4) có ma trận sinh là g(x) = (1 + x + x3).
    Từ đây suy ra
                        h(x) = (1 + x + x2 + x4)
   Ma trận kiểm tra của bộ mã là
                       ⎡1 0 1 1 1 0 0⎤
            H 3×7   = ⎢⎢0 1 0 1 1 1 0⎥⎥
                       ⎢⎣0 0 1 0 1 1 1⎥⎦




                             Trang 306
                      Ứng dụng trường GF(2m)
                       để xây dựng mã vòng
   Định lý 13.7
        Cho a là một phần tử khác 0 của trường GF(2m) có chu kỳ là n,
         đa thức tối thiểu f(x) của a có bậc là m. Thì mã có ma trận sau
         làm ma trận kiểm tra là một mã vòng C(n, n – m), trong đó mỗi
         phần tử trong ma trận bên dưới được thay thế bằng vectơ m
         thành phần tương ứng của nó.
                             Hm×n = [1 a a2 … an – 2 an–1]
         Hơn nữa mã vòng này có đa thức sinh chính là f(x).
   Ví dụ
        Xét trường GF(24) và a có đa thức tối thiểu là
                                f(x) = 1 + x + x4

                                  Trang 307
                   Ứng dụng trường GF(2m)
                   để xây dựng mã vòng (tt)
   Từ đây suy ra ma trận kiểm tra của mã vòng (15, 11).

          ⎡1   0   0   0   1   0   0       1   1   0   1   0   1   1   1⎤
          ⎢0   1   0   0   1   1   0       1   0   1   1   1   1   0   0⎥⎥
H 4×15   =⎢
          ⎢0   0   1   0   0   1   1       0   1   0   1   1   1   1   0⎥
          ⎢                                                              ⎥
          ⎣0   0   0   1   0   0   1       1   0   1   0   1   1   1   1⎦

   Nếu đa thức tối thiểu của a là f(x) = 1 + x + x2 + x3 + x4 thì a có
    chu kỳ là 5 và các phần tử 1, a, ..., a4 được biểu diễn như sau.
                  1 = (1000)        a3 = (0001)
                  a = (0100)        a4 = (1111)
                  a2 = (0010)

                               Trang 308
                 Ứng dụng trường GF(2m)
                 để xây dựng mã vòng (tt)
   Từ đây suy ra ma trận kiểm tra của mã vòng (5, 1)

                       ⎡1   0 0 0 1⎤
                       ⎢0   1 0 0 1⎥⎥
              H 4×5   =⎢
                       ⎢0   0 1 0 1⎥
                       ⎢            ⎥
                       ⎣0   0 0 1 1⎦




                             Trang 309
                    Mã BCH nhị phân
   Do Bose, Chaudhuri và Hocquenghem sáng lập ra.
   Là mã vòng có khả năng sửa được nhiều lỗi.
   Đối với các số nguyên dương m và t bất kỳ chúng ta sẽ xây
    dựng một mã BCH nhị phân có các thông số sau:
            Độ dài từ mã:          n = 2m – 1
            Số bit kiểm tra:       n – k ≤ mt
            Khoảng cách Hamming: dmin ≥ 2t + 1




                            Trang 310
                                          Định lý
   Định lý 13.8
        Cho a là một phần tử của trường GF(2m) có đa thức tối thiểu là
         một đa thức căn bản bậc m. Thì mã có ma trận sau làm ma trận
         kiểm tra là một mã vòng có khoảng cách Hamming ≥ 2t + 1,
         trong đó mỗi phần tử trong ma trận bên dưới được thay thế
         bằng vectơ m thành phần tương ứng của nó.
             ⎡1   a          a2           L      a n−2                a n −1          ⎤
             ⎢                                                                        ⎥
             ⎢1  a 3
                             a6           L    a 3( n − 2 )          a 3( n −1)       ⎥
         H = ⎢1 a 5          a 10         L    a 5( n − 2 )          a 5( n −1)       ⎥
             ⎢                                                                        ⎥
             ⎢M   M           M           M         M                    M            ⎥
             ⎢1 a 2t −1   a 2 ( 2t −1)    L a ( 2t −1)(( n − 2)   a ( 2t −1)(( n −1) ⎥⎦
             ⎣
                                         Trang 311
                                  Định lý (tt)
        Hơn nữa đa thức sinh g(x) của bộ mã là đa thức bội số chung
         nhỏ nhất của các đa thức tối thiểu của các phần tử a, a3, a5, …,
         a2t–1.
   Bổ đề 13.2
        Ma trận A sau có định thức bằng ∏ ( y i − y j )
                                             i> j
         với i, j ∈ {1, 2, …, r}. Định thức này được gọi là định thức
         Vandermonde.        ⎡ 1        1     L    1 ⎤
                           ⎢ y               y2        L  y r ⎥⎥
                           ⎢ 12
                       A = ⎢ y1                        L yr ⎥
                                                  2            2
                                            y2
                           ⎢                                      ⎥
                           ⎢ M                M        M    M ⎥
                           ⎢⎣ y1 r −1      y2
                                                r −1
                                                       L y r ⎥⎦
                                                             r −1


                                        Trang 312
                                  Ví dụ
     Cho m = 4, t = 2 chúng ta sẽ xây dựng một mã vòng có chiều
      dài từ mã là 24 – 1 = 15 và có khoảng cách Hamming d ≥ 5.
      Việc xây dựng sẽ dựa vào trường GF(24).
     Gọi a là phần tử có đa thức tối thiểu là đa thức căn bản bậc 4
      sau                     f1(x) = 1 + x + x4
     Đây chính là trường GF(24) trong ‎ví dụ ở slide 250.
     a có chu kỳ n = 2m – 1 = 15. Chúng ta có ma trận kiểm tra của
      bộ mã như sau.
    ⎡1 a a2 a3 a4 a5 a6 a7 a8 a9 a10 a11 a12 a12 a14⎤
H = ⎢ 3 6 9 12 15 18 21 24 27 30 33 36 39 42⎥
    ⎣1 a a a a a a a a a a a a a a ⎦

     Thay mỗi phần tử ai bằng vectơ 4 thành phần tương ứng
                               Trang 313
                Ví dụ (tt)
   ⎡1    0 0 0 1 0 0 1 1 0 1 0 1 1 1⎤
   ⎢0    1 0 0 1 1 0 1 0 1 1 1 1 0 0⎥⎥
   ⎢
   ⎢0    0 1 0 0 1 1 0 1 0 1 1 1 1 0⎥
   ⎢                                 ⎥
   ⎢ 0   0 0 1 0 0 1 1 0 1 0 1 1 1 1⎥
H=
   ⎢1    0 0 0 1 1 0 0 0 1 1 0 0 0 1⎥
   ⎢                                 ⎥
   ⎢0    0 0 1 1 0 0 0 1 1 0 0 0 1 1⎥
   ⎢0    0 1 0 1 0 0 1 0 1 0 0 1 0 1⎥
   ⎢                                 ⎥
   ⎢⎣0   1 1 1 1 0 1 1 1 1 0 1 1 1 1⎥⎦




                 Trang 314
                                 Ví dụ (tt)
        Đa thức sinh g(x) là bội số của hai đa thức tối thiểu tương ứng
         với phần tử a và a3.
        Theo ví dụ ở slide 250, đa thức tối thiểu của a3 là
                            f3(x) = 1 + x + x2 + x3 + x4.
        Từ đây suy ra
              g(x) = f1(x) * f3(x)
                   = (1 + x + x4) * (1 + x + x2 + x3 + x4)
                   = 1 + x4 + x6 + x7 + x8
   Chú ý
        Trong trường hợp đa thức tối thiểu của a không phải là đa thức
         căn bản, chúng ta sẽ tìm được mã vòng có chiều dài n ≠ 2m + 1,
         với n là chu kỳ của a.
                                  Trang 315
